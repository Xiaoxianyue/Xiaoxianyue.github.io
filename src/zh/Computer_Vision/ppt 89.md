---
title: è®¡ç®—æœºè§†è§‰ L 8 - L 9
icon: python
date: 2024-10-27 20:10:05
author: XiaoXianYue
isOriginal: true
category: 
    - å¤§ä¸‰ä¸Š
    - è®¡ç®—æœºè§†è§‰
tag:
    - å¤§ä¸‰ä¸Š
    - è®¡ç®—æœºè§†è§‰
sticky: false
star: false
article: true
timeline: true
image: false
navbar: true
sidebarIcon: true
headerDepth: 5
lastUpdated: true
editLink: false
backToTop: true
toc: true
---

## Lecture 8

### 1.1 Random Variable

Discrete :

<img src="./ppt 89.assets/image-20241027201718846.png" alt="image-20241027201718846" style="zoom:33%;" />

Continuous :

<img src="./ppt 89.assets/image-20241027201744702.png" alt="image-20241027201744702" style="zoom:33%;" />

### 1.2 Joint Probability

â€¢ Written as Pr(ğ‘¥, ğ‘¦)

â€¢ Can read Pr(ğ‘¥, ğ‘¦) as â€œprobability of x and y â€

### 1.3 Marginalization

::: details

è¿™å¼ å¹»ç¯ç‰‡ä»‹ç»äº†æ¦‚ç‡ä¸­çš„è¾¹ç¼˜åŒ–ï¼ˆMarginalizationï¼‰æ¦‚å¿µã€‚è¾¹ç¼˜åŒ–æ˜¯ä»è”åˆæ¦‚ç‡åˆ†å¸ƒä¸­è·å¾—å•ä¸€å˜é‡çš„æ¦‚ç‡åˆ†å¸ƒçš„æ–¹æ³•ã€‚

**å…·ä½“è§£é‡Šï¼š**

1. **è”åˆåˆ†å¸ƒ**ï¼š
   - åœ¨å›¾åƒä¸­å¿ƒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€ä¸ªäºŒç»´çš„è”åˆæ¦‚ç‡åˆ†å¸ƒ \( Pr(x, y) \)ï¼Œç”¨æ¥è¡¨ç¤ºå˜é‡ \( x \) å’Œ \( y \) çš„è”åˆåˆ†å¸ƒæƒ…å†µã€‚äº®åº¦è¶Šé«˜çš„åŒºåŸŸè¡¨ç¤ºè”åˆåˆ†å¸ƒçš„æ¦‚ç‡å€¼è¶Šå¤§ã€‚

2. **è¾¹ç¼˜æ¦‚ç‡**ï¼š
   - è¾¹ç¼˜åŒ–çš„è¿‡ç¨‹æ˜¯é€šè¿‡å°†è”åˆåˆ†å¸ƒ \( Pr(x, y) \) ä¸­å…¶ä»–å˜é‡ç§¯åˆ†ï¼ˆæˆ–æ±‚å’Œï¼‰ä»¥å¾—åˆ°æ„Ÿå…´è¶£å˜é‡çš„æ¦‚ç‡åˆ†å¸ƒã€‚
   - ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¹ \( Pr(x, y) \) åœ¨ \( y \) ä¸Šç§¯åˆ†æ¥è·å¾— \( x \) çš„è¾¹ç¼˜åˆ†å¸ƒ \( Pr(x) \)ï¼š
     \[
     Pr(x) = \int Pr(x, y) \, dy
     \]
   - åŒæ ·ï¼Œé€šè¿‡å¯¹ \( Pr(x, y) \) åœ¨ \( x \) ä¸Šç§¯åˆ†æ¥è·å¾— \( y \) çš„è¾¹ç¼˜åˆ†å¸ƒ \( Pr(y) \)ï¼š
     \[
     Pr(y) = \int Pr(x, y) \, dx
     \]

3. **å›¾ç¤º**ï¼š
   - ä¸‹é¢å³ä¾§çš„å›¾ç¤ºå±•ç¤ºäº†è¾¹ç¼˜åŒ–çš„æ•ˆæœã€‚æˆ‘ä»¬ä»äºŒç»´è”åˆåˆ†å¸ƒ \( Pr(x, y) \) ä¸­åˆ†åˆ«å¾—åˆ° \( Pr(x) \) å’Œ \( Pr(y) \) çš„å•ç‹¬åˆ†å¸ƒã€‚
   - åœ¨é¡¶éƒ¨å’Œå·¦ä¾§çš„æ›²çº¿åˆ†åˆ«è¡¨ç¤º \( Pr(x) \) å’Œ \( Pr(y) \) çš„åˆ†å¸ƒï¼Œå³åˆ†åˆ«å°† \( y \) å’Œ \( x \) å˜é‡â€œè¾¹ç¼˜åŒ–â€ä¹‹åçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚

4. **ç›´è§‚ç†è§£**ï¼š
   - å¯ä»¥æŠŠè¾¹ç¼˜åŒ–ç†è§£ä¸ºåœ¨äºŒç»´åˆ†å¸ƒä¸Šâ€œæŠ•å½±â€åˆ°å•ä¸ªè½´ä¸Šã€‚ä¾‹å¦‚ï¼Œè®¡ç®— \( Pr(x) \) æ—¶ï¼Œç›¸å½“äºå°† \( y \) æ–¹å‘ä¸Šçš„åˆ†å¸ƒâ€œå‹æ‰â€æˆ–â€œåˆå¹¶â€ï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªä»…ä¸ \( x \) ç›¸å…³çš„æ¦‚ç‡åˆ†å¸ƒã€‚

**åº”ç”¨ï¼š**

è¾¹ç¼˜åŒ–å¹¿æ³›åº”ç”¨äºæ¦‚ç‡å’Œç»Ÿè®¡å­¦ä¸­ï¼Œç”¨æ¥è®¡ç®—å•ä¸€å˜é‡çš„åˆ†å¸ƒï¼Œå³ä½¿åœ¨å®é™…ä¸­æˆ‘ä»¬å…³æ³¨çš„æ˜¯è”åˆåˆ†å¸ƒã€‚

<img src="./ppt 89.assets/image-20241027202909032.png" alt="image-20241027202909032" style="zoom:33%;" />

:::

åœ¨æ›´é«˜ç»´ä¹Ÿå¯ä»¥ç”¨è¾¹ç¼˜åˆ†å¸ƒâ€”â€”leaves joint distribution between whatever variables are left

### 1.4 Conditional Probability

â€¢ Conditional probability can be extracted from joint probability

â€¢ Extract appropriate slice and normalize

<img src="./ppt 89.assets/image-20241027204655653.png" alt="image-20241027204655653" style="zoom: 50%;" />

- æ±‚è§£å…¬å¼ï¼š

    ![image-20241027204805392](./ppt 89.assets/image-20241027204805392.png)

- å»¶ä¼¸è‡³é«˜é˜¶

    ![image-20241027204853946](./ppt 89.assets/image-20241027204853946.png)

### 1.5 Bayes' Rule

<img src="./ppt 89.assets/image-20241027205543522.png" alt="image-20241027205543522" style="zoom:50%;" />

<img src="./ppt 89.assets/image-20241027205602049.png" alt="image-20241027205602049" style="zoom:50%;" />



### 1.6 Independence

- When variable are independent:

    Pr(x, y) = Pr(x|y)Pr(y) = Pr(x)Pr(y)



### 1.7 Expectation

**æœŸæœ›æ˜¯ä»€ä¹ˆï¼š**

- ç¦»æ•£æ—¶ï¼š

    ![image-20241027221737039](./ppt 89.assets/image-20241027221737039.png)

- è¿ç»­æ—¶:

    ![image-20241027222233423](./ppt 89.assets/image-20241027222233423.png)

![image-20241027222244376](./ppt 89.assets/image-20241027222244376.png)



**æœŸæœ›çš„è®¡ç®—è§„åˆ™**ï¼š

- **è§„åˆ™ 1**ï¼šå¸¸æ•°çš„æœŸæœ›ç­‰äºå¸¸æ•°æœ¬èº«ã€‚ E[k] = k
- **è§„åˆ™ 2**ï¼šå¸¸æ•°ä¹˜ä»¥å‡½æ•°çš„æœŸæœ›ç­‰äºå¸¸æ•°ä¹˜ä»¥å‡½æ•°çš„æœŸæœ›å€¼ã€‚ E[k f[x]]=k E[f[x]]
- **è§„åˆ™ 3**ï¼šä¸¤ä¸ªå‡½æ•°ä¹‹å’Œçš„æœŸæœ›ç­‰äºå®ƒä»¬å„è‡ªæœŸæœ›çš„å’Œã€‚ E[f[x]+g[x]]=E[f[x]]+E[g[x]]

- **è§„åˆ™ 4ï¼š**ä¸¤ä¸ªå‡½æ•°ä¹˜ç§¯çš„å’Œçš„æœŸæœ›ç­‰äºä»–ä»¬å„è‡ªæœŸæœ›çš„ç§¯ï¼ˆå¦‚æœä»–ä»¬æ˜¯ç‹¬ç«‹çš„ï¼‰ã€‚E[f[x]g[x]]=E[f[x]]E[g[x]]



### 1.8 Bernoulli Distribution

åªæœ‰ 0 å’Œ 1 çš„æƒ…å†µ

<img src="./ppt 89.assets/image-20241027225533474.png" alt="image-20241027225533474" style="zoom:50%;" />

### 1.9 Beta Distribution

![image-20241027232323261](./ppt 89.assets/image-20241027232323261.png)

::: details Betaåˆ†å¸ƒå’Œ Bernoulli Distribution çš„å…³ç³»

**Betaåˆ†å¸ƒ**å¹¶ä¸æ˜¯ä¼¯åŠªåˆ©åˆ†å¸ƒçš„ç§¯åˆ†ï¼Œä½†å®ƒç¡®å®å’Œä¼¯åŠªåˆ©åˆ†å¸ƒå¯†åˆ‡ç›¸å…³ã€‚å…·ä½“æ¥è¯´ï¼ŒBetaåˆ†å¸ƒé€šå¸¸è¢«ç”¨ä½œä¼¯åŠªåˆ©åˆ†å¸ƒä¸­å‚æ•° \( p \) çš„**å…ˆéªŒåˆ†å¸ƒ**ï¼Œç‰¹åˆ«æ˜¯åœ¨**è´å¶æ–¯ç»Ÿè®¡**ä¸­ã€‚

1. ==**Betaåˆ†å¸ƒä¸ä¼¯åŠªåˆ©åˆ†å¸ƒçš„å…³ç³»**==

- **ä¼¯åŠªåˆ©åˆ†å¸ƒ**æè¿°äº†äºŒå…ƒéšæœºå˜é‡çš„åˆ†å¸ƒï¼Œå³äº‹ä»¶æˆåŠŸçš„æ¦‚ç‡ä¸º \( p \)ï¼ˆä¾‹å¦‚æŠ•æ·ç¡¬å¸æ­£é¢æœä¸Šçš„æ¦‚ç‡ï¼‰ï¼Œå…¶æ¦‚ç‡è´¨é‡å‡½æ•°ä¸ºï¼š
  
  ![image-20241027234909233](./ppt 89.assets/image-20241027234909233.png)
  
- **Betaåˆ†å¸ƒ**å¯ä»¥çœ‹ä½œæ˜¯å¯¹è¿™ä¸ªæˆåŠŸæ¦‚ç‡ \( p \) çš„ä¸€ä¸ªæ¦‚ç‡æ¨¡å‹ã€‚Betaåˆ†å¸ƒç”¨äºè¡¨ç¤º \( p \) çš„ä¸ç¡®å®šæ€§ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å¹¶ä¸ç›´æ¥çŸ¥é“ \( p \) çš„å€¼ï¼Œè€Œæ˜¯é€šè¿‡ Beta åˆ†å¸ƒæ¥æè¿°æˆ‘ä»¬å¯¹ \( p \) çš„ä¿¡å¿µã€‚

- **è´å¶æ–¯æ›´æ–°**ï¼šåœ¨è´å¶æ–¯æ¡†æ¶ä¸­ï¼Œå¦‚æœæˆ‘ä»¬å¯¹ä¼¯åŠªåˆ©åˆ†å¸ƒçš„å‚æ•° \( p \) è¿›è¡Œå»ºæ¨¡ï¼Œé€šå¸¸ä¼šé€‰æ‹© Beta åˆ†å¸ƒä½œä¸º \( p \) çš„å…ˆéªŒåˆ†å¸ƒã€‚è¿™æ ·ï¼Œå½“æˆ‘ä»¬è·å¾—æ–°çš„æ•°æ®ï¼ˆæˆåŠŸæˆ–å¤±è´¥çš„è§‚æµ‹ï¼‰æ—¶ï¼Œå¯ä»¥é€šè¿‡æ›´æ–° Beta åˆ†å¸ƒçš„å‚æ•°æ¥å¾—åˆ° \( p \) çš„åéªŒåˆ†å¸ƒã€‚

2. ==**ä¸ºä»€ä¹ˆä½¿ç”¨Betaåˆ†å¸ƒä½œä¸ºå…ˆéªŒ**==

Beta åˆ†å¸ƒæœ‰ä¸¤ä¸ªå‚æ•° \( \alpha \) å’Œ \( \beta \)ï¼Œå®ƒä»¬è¡¨ç¤ºæˆ‘ä»¬åœ¨äº‹å‰å¯¹ \( p \) çš„æˆåŠŸå’Œå¤±è´¥æ¬¡æ•°çš„â€œè™šæ‹Ÿè§‚æµ‹â€ã€‚ä¾‹å¦‚ï¼š

- å¦‚æœæˆ‘ä»¬é€‰æ‹© \( \alpha = 1 \), \( \beta = 1 \)ï¼Œé‚£ä¹ˆ Beta åˆ†å¸ƒæ˜¯ä¸€ä¸ªå‡åŒ€åˆ†å¸ƒï¼Œè¡¨ç¤ºæˆ‘ä»¬å¯¹ \( p \) æ²¡æœ‰åå¥½ã€‚
- å¦‚æœ \( \alpha \) å¾ˆå¤§ï¼Œè€Œ \( \beta \) å¾ˆå°ï¼Œè¡¨ç¤ºæˆ‘ä»¬è®¤ä¸ºäº‹ä»¶å¤§æ¦‚ç‡ä¼šæˆåŠŸï¼ˆ\( p \) æ¥è¿‘ 1ï¼‰ã€‚
- åä¹‹ï¼Œ\( \alpha \) å¾ˆå°ï¼Œ\( \beta \) å¾ˆå¤§æ—¶ï¼Œè¡¨ç¤ºæˆ‘ä»¬è®¤ä¸ºäº‹ä»¶å¤§æ¦‚ç‡ä¼šå¤±è´¥ï¼ˆ\( p \) æ¥è¿‘ 0ï¼‰ã€‚

3. ==**Betaåˆ†å¸ƒå¹¶ä¸ä»£è¡¨â€œä¼¯åŠªåˆ©å‚æ•°çš„å‡†ç¡®æ€§â€**==

Beta åˆ†å¸ƒæ˜¯ç”¨æ¥è¡¨ç¤ºæˆ‘ä»¬å¯¹ \( p \) çš„ä¸ç¡®å®šæ€§çš„ï¼Œè€Œä¸æ˜¯ç›´æ¥è¡¨ç¤º \( p \) çš„å‡†ç¡®æ€§ã€‚ä½†éšç€æ•°æ®çš„å¢å¤šï¼ˆæ¯”å¦‚æ›´å¤šçš„ä¼¯åŠªåˆ©å®éªŒç»“æœï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å‡†ç¡®åœ°ä¼°è®¡ \( p \)ã€‚å…·ä½“æ¥è¯´ï¼š

- æ¯å½“æˆ‘ä»¬è§‚æµ‹åˆ°ä¸€æ¬¡â€œæˆåŠŸâ€äº‹ä»¶ï¼Œå°±å¢åŠ  \( \alpha \) çš„å€¼ã€‚
- æ¯å½“è§‚æµ‹åˆ°ä¸€æ¬¡â€œå¤±è´¥â€äº‹ä»¶ï¼Œå°±å¢åŠ  \( \beta \) çš„å€¼ã€‚

éšç€ \( \alpha \) å’Œ \( \beta \) çš„å¢åŠ ï¼ŒBeta åˆ†å¸ƒä¼šé€æ¸æ”¶ç¼©åˆ°ä¸€ä¸ªè¾ƒçª„çš„èŒƒå›´ï¼Œä»è€Œæ›´ç²¾ç¡®åœ°æè¿° \( p \) çš„å¯èƒ½å€¼ã€‚è¿™å¯ä»¥ç†è§£ä¸ºï¼š**Beta åˆ†å¸ƒä¼šéšç€æ•°æ®å¢å¤šè€Œå¯¹ \( p \) çš„ä¼°è®¡å˜å¾—æ›´å‡†ç¡®**ã€‚

4. ==**æ€»ç»“**==

Betaåˆ†å¸ƒå’Œä¼¯åŠªåˆ©åˆ†å¸ƒçš„å…³ç³»åœ¨äºï¼ŒBetaåˆ†å¸ƒå¯ä»¥ä½œä¸ºä¼¯åŠªåˆ©åˆ†å¸ƒå‚æ•° \( p \) çš„å…ˆéªŒåˆ†å¸ƒã€‚é€šè¿‡è´å¶æ–¯æ›´æ–°ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è§‚æµ‹åˆ°æ›´å¤šæˆåŠŸæˆ–å¤±è´¥äº‹ä»¶åï¼Œåˆ©ç”¨ Beta åˆ†å¸ƒæ¥æ›´æ–°å¯¹ \( p \) çš„ä¿¡å¿µï¼Œä½¿å¾—å¯¹ \( p \) çš„ä¼°è®¡æ›´åŠ ç²¾ç¡®ã€‚å› æ­¤ï¼ŒBetaåˆ†å¸ƒåæ˜ äº†æˆ‘ä»¬å¯¹ \( p \) çš„ä¸ç¡®å®šæ€§ï¼Œè€Œä¸ç›´æ¥è¡¨ç¤º \( p \) çš„å‡†ç¡®æ€§ã€‚

:::

### 1.10 Categorical Distribution

åˆ†ç±»åˆ†å¸ƒï¼ˆCategorical Distributionï¼‰çš„å…¬å¼ç¡®å®æ¶‰åŠæ¦‚ç‡çš„è¡¨ç¤ºï¼Œä½†å¹¶ä¸æ˜¯å°†æ‰€æœ‰å–å€¼çš„æ¦‚ç‡ç›¸ä¹˜ï¼Œè€Œæ˜¯é€šè¿‡ä¸€ä¸ªç®€å•çš„è¡¨è¾¾å¼æ¥è¡¨æ˜æŸä¸ªç‰¹å®šç±»åˆ«å‘ç”Ÿçš„æ¦‚ç‡ã€‚

![image-20241028000705459](./ppt 89.assets/image-20241028000705459.png)

::: info

![image-20241028110307514](./ppt 89.assets/image-20241028110307514.png)

:::

::: details ä¾‹å­

å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªéª°å­ï¼Œå®ƒæœ‰6ä¸ªé¢ï¼ˆ1åˆ°6ï¼‰ï¼Œæ¯ä¸ªé¢æœä¸Šçš„æ¦‚ç‡ä¸åŒã€‚æˆ‘ä»¬ç”¨ä¸€ä¸ªåˆ†ç±»åˆ†å¸ƒæ¥æè¿°è¿™ä¸ªéª°å­æ¯ä¸€é¢çš„æ¦‚ç‡ã€‚å‡è®¾å„é¢çš„æ¦‚ç‡å¦‚ä¸‹ï¼š


lambda = [0.1, 0.2, 0.3, 0.15, 0.15, 0.1]


è¿™ä¸ªæ¦‚ç‡å‘é‡è¡¨ç¤ºï¼š

- æ·å‡º1çš„æ¦‚ç‡æ˜¯0.1
- æ·å‡º2çš„æ¦‚ç‡æ˜¯0.2
- æ·å‡º3çš„æ¦‚ç‡æ˜¯0.3
- æ·å‡º4çš„æ¦‚ç‡æ˜¯0.15
- æ·å‡º5çš„æ¦‚ç‡æ˜¯0.15
- æ·å‡º6çš„æ¦‚ç‡æ˜¯0.1

**é—®é¢˜ï¼šè®¡ç®—æ·å‡ºâ€œ3â€çš„æ¦‚ç‡**

ä¸ºäº†è¡¨ç¤ºæˆ‘ä»¬æƒ³è¦çš„ç±»åˆ«â€œ3â€ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªç‹¬çƒ­å‘é‡è¡¨ç¤ºï¼Œå…¶ä¸­åªæœ‰ç¬¬ä¸‰ä¸ªä½ç½®æ˜¯1ï¼Œå…¶ä½™ä½ç½®æ˜¯0ï¼š


e 3 = [0, 0, 1, 0, 0, 0]

åˆ†ç±»åˆ†å¸ƒå…¬å¼ä¸ºï¼š

![image-20241028000824104](./ppt 89.assets/image-20241028000824104.png)

è¿™é‡Œçš„ \( x j \) æ˜¯å‘é‡ \( e 3 \) ä¸­çš„å…ƒç´ ã€‚å› ä¸ºç‹¬çƒ­å‘é‡çš„ç¬¬ä¸‰ä¸ªä½ç½®ä¸º1ï¼Œå…¶ä»–ä½ç½®ä¸º0ï¼Œä¸Šå¼ä¼šå˜æˆï¼š

![image-20241028000906053](./ppt 89.assets/image-20241028000906053.png)

å› æ­¤ï¼Œæ·å‡ºâ€œ3â€çš„æ¦‚ç‡å°±æ˜¯0.3ã€‚

**æ€»ç»“**

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨åˆ†ç±»åˆ†å¸ƒæ¥è¡¨ç¤ºä¸€ä¸ªä¸å‡åŒ€éª°å­æ¯ä¸€é¢æœä¸Šçš„æ¦‚ç‡ã€‚é€šè¿‡ä½¿ç”¨ç‹¬çƒ­å‘é‡ \( e 3 \)ï¼Œæˆ‘ä»¬å¯ä»¥ç­›é€‰å‡ºæ·å‡º3çš„æ¦‚ç‡ï¼Œå³ 0.3ã€‚

:::

### 1.11 Dirichlet Distribution

::: tabs

@tab æ¦‚ç‡å¯†åº¦å‡½æ•°

![image-20241028111502992](./ppt 89.assets/image-20241028111502992.png)

@tab å›¾å½¢è§£é‡Š

![image-20241028112138008](./ppt 89.assets/image-20241028112138008.png)

- å›¾ä¸­å·¦ä¾§ä¸‰è§’å½¢å›¾ï¼ˆaï¼‰å±•ç¤ºäº†ä¸€ä¸ªäºŒç»´æƒ…å†µä¸‹çš„ä¸‰ç»´ç©ºé—´ï¼Œè¡¨ç¤º Î»1,Î»2,Î»3çš„æ‰€æœ‰å¯èƒ½ç»„åˆã€‚

- å­å›¾ (b) åˆ° (i) å±•ç¤ºäº†ä¸åŒå‚æ•°ç»„åˆä¸‹çš„ç‹„åˆ©å…‹é›·åˆ†å¸ƒå½¢çŠ¶ã€‚æ¯ä¸ªå­å›¾æ ‡æ³¨çš„å‚æ•°ï¼ˆå¦‚ (0.90, 0.90, 0.90)ï¼‰è¡¨ç¤ºä¸åŒçš„Î±kå€¼ï¼Œæ˜¾ç¤ºäº†åœ¨è¿™ç§æ¡ä»¶ä¸‹æ¦‚ç‡å¯†åº¦çš„åˆ†å¸ƒå½¢æ€ã€‚éšç€å‚æ•°çš„å¢å¤§ï¼Œåˆ†å¸ƒä¼šæ›´åŠ é›†ä¸­

### 1.12 Univariate Normal Distribution

åˆå«æ­£æ€åˆ†å¸ƒã€‚

::: tabs

@tab æ¦‚ç‡å¯†åº¦å‡½æ•°

![image-20241028113358468](./ppt 89.assets/image-20241028113358468.png)

æˆ–è€…åˆå¯ä»¥å†™ä½œï¼š

![image-20241028113429673](./ppt 89.assets/image-20241028113429673.png)

@tab å›¾ç¤º

<img src="./ppt 89.assets/image-20241028113955457.png" alt="image-20241028113955457" style="zoom:50%;" />

- ç»¿è‰²æ›²çº¿ï¼šå‡å€¼ Î¼=âˆ’3.4æ–¹å·® Ïƒ2=0.25ã€‚

- çº¢è‰²æ›²çº¿ï¼šå‡å€¼ Î¼=0æ–¹å·® Ïƒ2=1ã€‚
- è“è‰²æ›²çº¿ï¼šå‡å€¼ Î¼=1.5æ–¹å·® Ïƒ2=4.41ã€‚

è¿™äº›æ›²çº¿æ˜¾ç¤ºäº†ä¸åŒå‡å€¼å’Œæ–¹å·®ç»„åˆä¸‹æ­£æ€åˆ†å¸ƒçš„å½¢çŠ¶å˜åŒ–ï¼Œå‡å€¼è¶Šé«˜æ›²çº¿å‘å³ç§»åŠ¨ï¼Œæ–¹å·®è¶Šå¤§æ›²çº¿è¶Šå¹³ç¼“ã€‚

:::



### 1.13 Normal Inverse Gamma Distribution

::: tabs

@tab æ¦‚ç‡å¯†åº¦å‡½æ•°

![image-20241028115816229](./ppt 89.assets/image-20241028115816229.png)

@tab å›¾ç¤º

<img src="./ppt 89.assets/image-20241028120312355.png" alt="image-20241028120312355" style="zoom:67%;" />

ä¸‹æ–¹çš„çƒ­åŠ›å›¾å±•ç¤ºäº†åœ¨ä¸åŒå‚æ•°ç»„åˆä¸‹æ­£æ€é€†ä¼½é©¬åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦ã€‚æ¯å¼ å›¾ä¸Šæ–¹çš„æ‹¬å·å†…å®¹è¡¨ç¤ºå…·ä½“çš„å‚æ•°å€¼ç»„åˆï¼Œä¾‹å¦‚ï¼š

- a) å›¾çš„å‚æ•°ç»„åˆä¸º (1.0, 1.0, 1.0, 0.0)ï¼Œè¡¨ç¤º Î±=1ï¼ŒÎ²=1ï¼ŒÎ³=1ï¼ŒÎ´=0ã€‚
- b) å›¾çš„å‚æ•°ç»„åˆä¸º (0.5, 1.0, 1.0, 0.0)ï¼Œç­‰ç­‰ã€‚

æ¯å¼ çƒ­åŠ›å›¾æ˜¾ç¤ºäº†åœ¨ä¸åŒå‡å€¼ Î¼ å’Œæ–¹å·® Ïƒ22çš„æƒ…å†µä¸‹æ¦‚ç‡å¯†åº¦çš„åˆ†å¸ƒæƒ…å†µã€‚é¢œè‰²è¶Šäº®ï¼Œè¡¨ç¤ºåœ¨å¯¹åº”çš„ Î¼å’Œ Ïƒ2 ä½ç½®ä¸Šæ¦‚ç‡å¯†åº¦è¶Šé«˜ã€‚

:::



### 1.14 Multivariate Normal Distribution

![image-20241028120701500](./ppt 89.assets/image-20241028120701500.png)

### 1.15 Normal Inverse Wishart

![image-20241028120731059](./ppt 89.assets/image-20241028120731059.png)

![image-20241028120747482](./ppt 89.assets/image-20241028120747482.png)

### 1.16 Conjugate Distributions

::: info å¸¸è§çš„å…±è½­åˆ†å¸ƒ

 <img src="./ppt 89.assets/image-20241028121314041.png" alt="image-20241028121314041" style="zoom:33%;" />

:::

- When we take product of distribution and itâ€™s conjugate, the result has the same form as the conjugate.

::: details

è¿™å¥è¯çš„æ„æ€æ˜¯ï¼Œå½“æˆ‘ä»¬å°†ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒä¸å®ƒçš„å…±è½­åˆ†å¸ƒç›¸ä¹˜æ—¶ï¼Œæ‰€å¾—çš„ç»“æœï¼ˆå³åéªŒåˆ†å¸ƒï¼‰ä»ç„¶å…·æœ‰ä¸å…±è½­åˆ†å¸ƒç›¸åŒçš„æ•°å­¦å½¢å¼ã€‚

åœ¨è´å¶æ–¯æ¨æ–­ä¸­ï¼Œæˆ‘ä»¬å¸¸å¸¸ä¼šç”¨**å…ˆéªŒåˆ†å¸ƒ**å»æè¿°æŸä¸ªæœªçŸ¥å‚æ•°çš„åˆå§‹ä¿¡å¿µï¼Œç„¶åç»“åˆ**ä¼¼ç„¶å‡½æ•°**ï¼ˆå³è§‚æµ‹æ•°æ®çš„æ¦‚ç‡åˆ†å¸ƒï¼‰æ¥æ›´æ–°æˆ‘ä»¬çš„ä¿¡å¿µï¼Œå¾—åˆ°**åéªŒåˆ†å¸ƒ**ã€‚å¦‚æœæˆ‘ä»¬é€‰æ‹©çš„å…ˆéªŒåˆ†å¸ƒæ˜¯ä¼¼ç„¶å‡½æ•°çš„å…±è½­åˆ†å¸ƒï¼Œé‚£ä¹ˆå½“æˆ‘ä»¬å°†è¿™ä¸ªå…ˆéªŒåˆ†å¸ƒä¸ä¼¼ç„¶å‡½æ•°ç›¸ä¹˜åï¼Œå¾—åˆ°çš„åéªŒåˆ†å¸ƒå°†å’Œå…ˆéªŒåˆ†å¸ƒä¿æŒç›¸åŒçš„å½¢å¼ï¼Œåªæ˜¯åˆ†å¸ƒçš„å‚æ•°ä¼šå‘ç”Ÿå˜åŒ–ã€‚è¿™å°±æ˜¯**å…±è½­åˆ†å¸ƒçš„æ€§è´¨**ã€‚

:::

- Example:

    ä¸€ä¸ªå…ˆéªŒåˆ†å¸ƒï¼šæˆ‘ä»¬æš‚æ—¶è®¾åš beta åˆ†å¸ƒã€‚

    ä¸€ä¸ªä¼¼ç„¶å‡½æ•°ï¼šä»ä¼¯åŠªåˆ©åˆ†å¸ƒä¸­æå–ï¼Œå› ä¸º beta åˆ†å¸ƒæ˜¯ä»–çš„å…±è½­åˆ†å¸ƒã€‚è¿™æ—¶æˆ‘ä»¬ä»ä¼¯åŠªåˆ©åˆ†å¸ƒä¸­å¾—åˆ°ä¸€äº›è§‚æµ‹å‡½æ•°ï¼ˆä»–ä»¬æ»¡è¶³ä¼¯åŠªåˆ©åˆ†å¸ƒï¼‰

    æŠŠåéªŒåˆ†å¸ƒï¼šæŠŠå…ˆéªŒåˆ†å¸ƒä¸ä¼¼ç„¶å‡½æ•°ç›¸ä¹˜ï¼Œå¾—åˆ°çš„åéªŒåˆ†å¸ƒä»ç„¶æ˜¯ Beta åˆ†å¸ƒçš„å½¢å¼ã€‚

    <img src="./ppt 89.assets/image-20241028123535402.png" alt="image-20241028123535402" style="zoom:50%;" />



### 1.17 Importance of Conjugate in Bayesâ€™ Rule

å›é¡¾ä¸€ä¸‹è´å¶æ–¯å®šç†æ˜¯ä»€ä¹ˆï¼Ÿ

- åœ¨è´å¶æ–¯å…¬å¼ä¸­ï¼ŒåéªŒæ¦‚ç‡ Pr(yâˆ£x) æ˜¯é€šè¿‡ç»“åˆä¼¼ç„¶ Pr(xâˆ£y) å’Œå…ˆéªŒåˆ†å¸ƒ Pr(y)è®¡ç®—å¾—åˆ°çš„ã€‚å…±è½­åˆ†å¸ƒçš„ä¸€ä¸ªé‡è¦ç‰¹æ€§æ˜¯ï¼Œå½“æˆ‘ä»¬å°†å…ˆéªŒåˆ†å¸ƒå’Œä¼¼ç„¶ç›¸ä¹˜æ—¶ï¼Œå¾—åˆ°çš„åéªŒåˆ†å¸ƒå½¢å¼ä¸å…ˆéªŒåˆ†å¸ƒç›¸åŒï¼Œè¿™å°±æ˜¯â€œå…±è½­â€çš„å«ä¹‰ã€‚

<img src="./ppt 89.assets/image-20241028145020012.png" alt="image-20241028145020012" style="zoom:50%;" />

::: details

![image-20241028153349691](./ppt 89.assets/image-20241028153349691.png)



:::

### 1.18 Maximum Likelihood

::: tabs

@ tab PPT

ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ç»„å‚æ•° Î¸ ä½¿å¾—è§‚æµ‹åˆ°çš„æ•°æ® X1, X2,â€¦,XI åœ¨è¯¥å‚æ•°ä¸‹çš„æ¦‚ç‡æœ€å¤§åŒ–ã€‚æ¢å¥è¯è¯´ï¼ŒMLE æ—¨åœ¨æ‰¾åˆ°æœ€èƒ½è§£é‡Šæ•°æ®çš„å‚æ•°ã€‚

<img src="./ppt 89.assets/image-20241028161325093.png" alt="image-20241028161325093" style="zoom:80%;" />

We have assumed that data was independent (hence product)

- é¢„æµ‹å¯†åº¦ï¼šè®¡ç®—ä¸€ä¸ªæ–°çš„æ•°æ®çš„æ—¶å€™ x çš„æ—¶å€™æˆ‘ä»¬å°±å¯ä»¥ç”¨ä¼°è®¡å‡ºæ¥çš„æœ€å¯èƒ½çš„å‚æ•°ã€‚

@tab GPT

**ä»€ä¹ˆæ˜¯ä¼¼ç„¶ï¼ˆlikelihoodï¼‰ï¼Ÿ**

- ä¼¼ç„¶å°±æ˜¯ç»™å®šå‚æ•°æ—¶ï¼Œæ•°æ®å‡ºç°çš„å¯èƒ½æ€§ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®©è¿™ä¸ªå¯èƒ½æ€§æœ€å¤§åŒ–ï¼Œä¹Ÿå°±æ˜¯è®©æ¨¡å‹çš„å‚æ•°å°½é‡è®©æ•°æ®æ›´â€œåˆç†â€åœ°å‡ºç°ã€‚æˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°è¿™æ ·ä¸€ç»„å‚æ•°ï¼Œè®©æˆ‘ä»¬è§‚å¯Ÿåˆ°çš„æ•°æ®åœ¨è¯¥å‚æ•°ä¸‹å‡ºç°çš„å¯èƒ½æ€§æœ€é«˜ã€‚

**æ­¥éª¤**ï¼š

- æˆ‘ä»¬è¦æ‰¾åˆ°ä¸€ç»„å‚æ•°ï¼Œä½¿å¾—æ‰€æœ‰æ•°æ®åŒæ—¶å‡ºç°çš„å¯èƒ½æ€§æœ€å¤§ã€‚åœ¨æ•°å­¦ä¸Šï¼Œè¿™å¯ä»¥ç†è§£ä¸ºæ‰¾å‡ºæ¯ä¸ªæ•°æ®ç‚¹çš„å‡ºç°æ¦‚ç‡ï¼Œå¹¶æŠŠå®ƒä»¬çš„æ¦‚ç‡å€¼ç›¸ä¹˜ã€‚ä¸ºäº†ç®€åŒ–è¿™ä¸ªè¿‡ç¨‹ï¼Œæˆ‘ä»¬å‡è®¾æ•°æ®æ˜¯ç‹¬ç«‹çš„ï¼ˆå³ä¸€ä¸ªæ•°æ®ç‚¹çš„å‡ºç°ä¸å½±å“å…¶ä»–æ•°æ®ç‚¹çš„å‡ºç°ï¼‰ï¼Œè¿™æ ·å°±å¯ä»¥ç›´æ¥æŠŠæ¯ä¸ªæ•°æ®çš„æ¦‚ç‡ä¹˜èµ·æ¥ã€‚

**é¢„æµ‹æ–°æ•°æ®**ï¼š

- ä¸€æ—¦æ‰¾åˆ°è®©ç°æœ‰æ•°æ®å¯èƒ½æ€§æœ€å¤§çš„å‚æ•°ï¼ˆæœ€ä¼˜å‚æ•°ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªå‚æ•°æ¥é¢„æµ‹æ–°çš„æ•°æ®ã€‚è¿™å°±ç›¸å½“äºï¼šæˆ‘ä»¬è°ƒæ•´å¥½äº†çŒœæµ‹å™¨çš„è®¾ç½®ï¼Œç°åœ¨å®ƒå¯ä»¥æ›´å¥½åœ°é¢„æµ‹æ–°æƒ…å†µã€‚

:::



### 1.19 Maximum a posteriori (MAP)

ä¹Ÿå‡è®¾æ•°æ®éƒ½æ˜¯ç‹¬ç«‹çš„ã€‚

<img src="./ppt 89.assets/image-20241028163353111.png" alt="image-20241028163353111" style="zoom:67%;" />





### 1.20 Bayesian Approach

#### 1. Fitting

Compute the posterior distribution over possible parameter values using Bayesâ€™ rule:

![image-20241028164632595](./ppt 89.assets/image-20241028164632595.png)

è´å¶æ–¯æ–¹æ³•çš„ä¸€ä¸ªæ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å·²çŸ¥çš„æ•°æ®æ¥æ›´æ–°å…³äºå‚æ•° Î¸ çš„çŸ¥è¯†ï¼Œå¾—åˆ°å…¶åéªŒåˆ†å¸ƒã€‚

è¿™é‡Œï¼š

- P(Î¸âˆ£x1...I)è¡¨ç¤ºåœ¨ç»™å®šæ•°æ® x1...I åï¼Œå¯¹å‚æ•° Î¸çš„åéªŒåˆ†å¸ƒã€‚
- P(xiâˆ£Î¸)æ˜¯ä¼¼ç„¶å‡½æ•°ï¼Œè¡¨ç¤ºåœ¨å‚æ•° Î¸ ä¸‹ç”Ÿæˆæ•°æ®ç‚¹ xiçš„æ¦‚ç‡ã€‚
- P(Î¸)æ˜¯å…ˆéªŒåˆ†å¸ƒï¼Œè¡¨ç¤ºæˆ‘ä»¬åœ¨è§‚å¯Ÿåˆ°æ•°æ®ä¹‹å‰å¯¹å‚æ•° Î¸ çš„ä¿¡å¿µã€‚
- P(x1...I)æ˜¯æ•°æ®çš„è¾¹ç¼˜ä¼¼ç„¶ï¼Œç”¨äºå½’ä¸€åŒ–ä½¿å¾—åéªŒåˆ†å¸ƒçš„æ€»æ¦‚ç‡ä¸º1ã€‚

**åŸåˆ™**ï¼šè´å¶æ–¯æ–¹æ³•ä¸é€‰æ‹©å•ä¸€çš„æœ€ä¼˜å‚æ•°ï¼Œè€Œæ˜¯ä¿ç•™æ‰€æœ‰å¯èƒ½çš„å‚æ•°å€¼ï¼Œå¹¶è€ƒè™‘æ¯ç§æƒ…å†µçš„æ¦‚ç‡ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ•æ‰åˆ°æ‰€æœ‰å¯èƒ½çš„è§£é‡Šï¼Œè€Œä¸æ˜¯ä»…ä»…é€‰æ‹©ä¸€ä¸ªã€‚

::: note

**ä¸ºä½•P(Î¸)æ˜¯å…ˆéªŒåˆ†å¸ƒï¼Ÿå®ƒä¸åéªŒåˆ†å¸ƒå‡½æ•°å½¢å¼ä¸€æ ·å—ï¼Ÿ**

åœ¨è´å¶æ–¯ç»Ÿè®¡ä¸­ï¼Œå…ˆéªŒåˆ†å¸ƒ \( P(\theta) \) å’ŒåéªŒåˆ†å¸ƒ \( P(Î¸ | x_{1...I}) \) æ˜¯ä¸¤ä¸ªä¸åŒçš„æ¦‚å¿µï¼Œå°½ç®¡å®ƒä»¬çš„å½¢å¼å¯ä»¥åœ¨æŸäº›æƒ…å†µä¸‹ç›¸ä¼¼ã€‚æˆ‘ä»¬æ¥è¯¦ç»†æ¢è®¨ä¸€ä¸‹ï¼š

1. å…ˆéªŒåˆ†å¸ƒ \( P(Î¸) \)

å…ˆéªŒåˆ†å¸ƒ \( P(Î¸) \) è¡¨ç¤ºæˆ‘ä»¬åœ¨è§‚å¯Ÿåˆ°æ•°æ®ä¹‹å‰ï¼Œå¯¹å‚æ•° \( Î¸ \) çš„ä¿¡å¿µã€‚å®ƒåæ˜ äº†åœ¨æ²¡æœ‰ä»»ä½•æ•°æ®çš„æƒ…å†µä¸‹ï¼Œå…³äº \( Î¸\) çš„ä¸ç¡®å®šæ€§ã€‚é€‰æ‹©å…ˆéªŒåˆ†å¸ƒé€šå¸¸ä¾èµ–äºå…ˆéªŒçŸ¥è¯†ã€ç»éªŒæˆ–å‡è®¾ã€‚åœ¨è´å¶æ–¯åˆ†æä¸­ï¼Œå…ˆéªŒåˆ†å¸ƒçš„é€‰æ‹©å¯¹ç»“æœæœ‰å¾ˆå¤§å½±å“ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®é‡å°‘çš„æƒ…å†µä¸‹ã€‚

2. åéªŒåˆ†å¸ƒ \( P(Î¸ | x_{1...I}) \)

åéªŒåˆ†å¸ƒ \( P(Î¸ | x_{1...I}) \) è¡¨ç¤ºåœ¨è§‚å¯Ÿäº†æ•°æ® \( x_{1...I} \) åï¼Œæˆ‘ä»¬å¯¹å‚æ•° \( Î¸ \) çš„æ›´æ–°åçš„ä¿¡å¿µã€‚æ ¹æ®è´å¶æ–¯å®šç†ï¼ŒåéªŒåˆ†å¸ƒçš„è®¡ç®—å…¬å¼ä¸ºï¼š

<img src="./ppt 89.assets/image-20241028165938691.png" alt="image-20241028165938691" style="zoom: 50%;" />

è¿™é‡Œï¼š
- \( P(x_{1...I} |Î¸) \) æ˜¯ä¼¼ç„¶å‡½æ•°ï¼Œè¡¨ç¤ºåœ¨ç»™å®šå‚æ•° \( Î¸ \) çš„æ¡ä»¶ä¸‹è§‚æµ‹åˆ°æ•°æ® \( x_{1...I} \) çš„æ¦‚ç‡ã€‚
- \( P(x_{1...I}) \) æ˜¯è¾¹ç¼˜ä¼¼ç„¶ï¼Œç”¨äºå½’ä¸€åŒ–ï¼Œä½¿å¾—åéªŒåˆ†å¸ƒçš„æ€»æ¦‚ç‡ä¸º 1ã€‚

å› æ­¤ï¼ŒåéªŒåˆ†å¸ƒæ˜¯åŸºäºå…ˆéªŒåˆ†å¸ƒå’Œæ•°æ®çš„ä¼¼ç„¶å‡½æ•°å…±åŒå†³å®šçš„ã€‚

3. å…ˆéªŒåˆ†å¸ƒä¸åéªŒåˆ†å¸ƒçš„å½¢å¼å…³ç³»

åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå…ˆéªŒåˆ†å¸ƒå’ŒåéªŒåˆ†å¸ƒçš„å½¢å¼å¯ä»¥ç›¸ä¼¼ã€‚ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªå…±è½­å…ˆéªŒï¼ˆconjugate priorï¼‰æ—¶ï¼ŒåéªŒåˆ†å¸ƒä¼šä¸å…ˆéªŒåˆ†å¸ƒå…·æœ‰ç›¸åŒçš„åˆ†å¸ƒæ—å½¢å¼ã€‚å…±è½­å…ˆéªŒæ˜¯ä¸€ç§ç‰¹æ®Šçš„å…ˆéªŒåˆ†å¸ƒå½¢å¼ï¼Œä½¿å¾—åéªŒåˆ†å¸ƒçš„å½¢å¼ä¿æŒä¸å…ˆéªŒåˆ†å¸ƒç›¸åŒï¼Œè¿™åœ¨è®¡ç®—ä¸Šéå¸¸æ–¹ä¾¿ã€‚ä¾‹å¦‚ï¼š

- å¯¹äºäºŒé¡¹åˆ†å¸ƒçš„å‚æ•°ï¼ˆå¦‚ä¼¯åŠªåˆ©åˆ†å¸ƒä¸­çš„æˆåŠŸæ¦‚ç‡ï¼‰ï¼Œé€‰æ‹© Beta åˆ†å¸ƒä½œä¸ºå…ˆéªŒåˆ†å¸ƒã€‚æ›´æ–°åçš„åéªŒåˆ†å¸ƒä»ç„¶æ˜¯ Beta åˆ†å¸ƒã€‚
- å¯¹äºæ­£æ€åˆ†å¸ƒçš„å‡å€¼ï¼Œé€‰æ‹©æ­£æ€åˆ†å¸ƒä½œä¸ºå…ˆéªŒåˆ†å¸ƒï¼ŒåéªŒåˆ†å¸ƒä¹Ÿä¿æŒæ­£æ€åˆ†å¸ƒå½¢å¼ã€‚

ç„¶è€Œï¼Œ**ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå…ˆéªŒåˆ†å¸ƒå’ŒåéªŒåˆ†å¸ƒçš„å½¢å¼å¹¶ä¸ä¸€å®šç›¸åŒ**ã€‚åœ¨æ²¡æœ‰é€‰æ‹©å…±è½­å…ˆéªŒçš„æƒ…å†µä¸‹ï¼ŒåéªŒåˆ†å¸ƒå¯èƒ½æ˜¯å¤æ‚çš„ã€éæ ‡å‡†çš„åˆ†å¸ƒï¼Œç”šè‡³å¯èƒ½éœ€è¦ä½¿ç”¨æ•°å€¼æ–¹æ³•ï¼ˆå¦‚é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›æ–¹æ³•ï¼‰æ¥ä¼°è®¡ã€‚

:::

#### 2. Predictive Density

â€¢ Each possible parameter value makes a prediction

â€¢ Some parameters more probable than others

<img src="./ppt 89.assets/image-20241028170307868.png" alt="image-20241028170307868" style="zoom:80%;" />

Make a prediction that is an infinite weighted sum (integral) of the predictions for each parameter value, where weights are the probabilities.

è¿™å¥è¯æ˜¯è¯´ï¼Œé¢„æµ‹å¯†åº¦æ˜¯ä¸€ä¸ªåŠ æƒå¹³å‡ï¼Œå…¶ä¸­æ¯ä¸ªå¯èƒ½çš„å‚æ•°å€¼ Î¸å¯¹é¢„æµ‹ xâˆ—çš„è´¡çŒ®æ ¹æ®å…¶åéªŒæ¦‚ç‡ P(Î¸âˆ£x1...I)è¿›è¡ŒåŠ æƒã€‚







### 1.21 ä¸‰ç§é¢„æµ‹å¯†åº¦çš„æ–¹æ³•

**1. Maximum likelihood:**

Evaluate new data point under probability distribution with ML parameters

![image-20241028172139566](./ppt 89.assets/image-20241028172139566.png)

**2. Maximum a posteriori:**

Evaluate new data point under probability distribution with MAP parameters

![image-20241028172155352](./ppt 89.assets/image-20241028172155352.png)

**3. Bayesian:**

Calculate weighted sum of predictions from all possible values of parameters

![image-20241028172212701](./ppt 89.assets/image-20241028172212701.png)



## Lecture 8 Review Question

### 1. **What are random variables? How many types of random variables?**

::: tabs

@tab GPT

A **random variable** is a variable whose possible values are outcomes of a random phenomenon. It's a way to quantify uncertainty by assigning numerical values to different outcomes of a random process. 

1. **Discrete Random Variables**
    - **Definition**: A discrete random variable takes on a countable number of distinct values. These values are often integers, such as 0, 1, 2, etc., but can also be any distinct set of outcomes.
    - **Probability Distribution**: Discrete random variables have a probability mass function (PMF), which provides the probability of each possible outcome.

2. **Continuous Random Variables**
    - **Definition**: A continuous random variable can take on an infinite number of values within a given range. These values are typically real numbers and can vary continuously without jumps.
    - **Probability Distribution**: Continuous random variables have a probability density function (PDF), which describes the probability of the variable falling within a specific range of values. For continuous random variables, the probability of taking any exact value is zero, but we can calculate the probability over an interval.

@tab PPT

- May be result of experiment (flipping a coin) or a real world measurements (measuring temperature)
- If observe several instances of x we get different values.
- A random variable x denotes a quantity that is **uncertain**
- Some values occur more than others and this information is captured by a **probability distribution**

![image-20241030151834269](./ppt 89.assets/image-20241030151834269.png)

:::

### 2. The definition of Conditional Probability

ç»™å®š y=y1 çš„æ¡ä»¶æ¦‚ç‡ P(xâˆ£y = y1)æ˜¯æŒ‡åœ¨ y å›ºå®šä¸º y1 æ—¶ï¼Œå˜é‡ x å–ä¸åŒç»“æœçš„ç›¸å¯¹å€¾å‘ã€‚

Conditional probability of x given that y=y1 is relative propensity of variable x to take different outcomes given that y is fixed to be equal to y1 .

In another way â€¦

The conditional probability \( P(x | y = y_1) \) represents the probability of event \( x \) occurring given that event \( y = y_1 \) has already occurred.

<img src="./ppt 89.assets/image-20241028201747950.png" alt="image-20241028201747950" style="zoom:50%;" />

### 3. **The definition of Bayesian Rule**

é¦–å…ˆæˆ‘ä»¬å¾—åˆ°ï¼š

<img src="./ppt 89.assets/image-20241028202519998.png" alt="image-20241028202519998" style="zoom: 50%;" />

ç„¶åæˆ‘ä»¬å¯ä»¥è¿›è¡Œå˜æ¢ï¼Œå¾—åˆ° Bayesâ€™ Ruleï¼š

<img src="./ppt 89.assets/image-20241028202639040.png" alt="image-20241028202639040" style="zoom:50%;" />

è§£æ Bayesâ€˜ Ruleï¼š

<img src="./ppt 89.assets/image-20241028194942381.png" alt="image-20241028194942381" style="zoom:50%;" />



### 4. Three Fitting probability distributions

**1. Maximum likelihood:**

Evaluate new data point x* under probability distribution with ML parameters

![image-20241028172139566](./ppt 89.assets/image-20241028172139566.png)

**2. Maximum a posteriori:**

Evaluate new data point x* under probability distribution with MAP parameters

![image-20241028172155352](./ppt 89.assets/image-20241028172155352.png)

**3. Bayesian:**

Calculate weighted sum of predictions from all possible values of parameters

![image-20241028172212701](./ppt 89.assets/image-20241028172212701.png)



### 5. é»˜å†™ä¸€äº›åˆ†å¸ƒ



#### 5.1 Bernoulli likelihood

Probability Mass Function (PMF)ï¼š

<img src="./ppt 89.assets/image-20241028211328059.png" alt="image-20241028211328059" style="zoom: 33%;" />

å†™ä½œï¼š

<img src="./ppt 89.assets/image-20241028211356956.png" alt="image-20241028211356956" style="zoom:50%;" />



#### 5.2 Categorical Distribution

The **Categorical distribution** generalizes the Bernoulli distribution to handle more than two possible outcomes. It describes the probabilities of each category in a set of k categories.

Probability Mass Functionï¼š

<img src="./ppt 89.assets/image-20241028211906427.png" alt="image-20241028211906427" style="zoom: 33%;" />

â€‹                                            <img src="./ppt 89.assets/image-20241028212025558.png" alt="image-20241028212025558" style="zoom:50%;" />   



![image-20241028213137862](./ppt 89.assets/image-20241028213137862.png)



#### 5.3 Univariate Normal Distribution

Probability Density Function (PDF)ï¼š

<img src="./ppt 89.assets/image-20241028213430962.png" alt="image-20241028213430962" style="zoom:33%;" />

<img src="./ppt 89.assets/image-20241028213441225.png" alt="image-20241028213441225" style="zoom:50%;" />

#### 5.4 Multivariate Normal Distribution

The **Multivariate Normal distribution** generalizes the univariate normal distribution to multiple dimensions. It is defined by a mean vector Î¼\muÎ¼ and a covariance matrix Î£.

![image-20241028214510342](./ppt 89.assets/image-20241028214510342.png)

- Î¼ is the d-dimensional mean vector.

- Î£ is the dÃ—d covariance matrix, which must be positive definite.

Multivariate normal distribution describes multiple continuous variables. Takes 2 parameters 







## Lecture 9

è¿™å‡ é¡µå¹»ç¯ç‰‡ä»‹ç»äº†è§†è§‰ä¸–ç•Œä¸­çš„ä¸ç¡®å®šæ€§ã€è®¡ç®—æœºè§†è§‰çš„ç›®æ ‡ï¼Œä»¥åŠè§£å†³è¿™ä¸ªé—®é¢˜çš„æ¨¡å‹è®¾è®¡ã€‚

1. **è§†è§‰ä¸–ç•Œçš„æ¨¡ç³Šæ€§**ï¼šè§†è§‰æµ‹é‡å¾€å¾€æ— æ³•å”¯ä¸€ç¡®å®šä¸–ç•ŒçŠ¶æ€ï¼Œå› ä¸ºè§‚æµ‹æ•°æ®ï¼ˆå¦‚å›¾åƒï¼‰å¯èƒ½å«æœ‰å™ªå£°æˆ–å†…åœ¨çš„ä¸ç¡®å®šæ€§ã€‚è¿™å¯¼è‡´åŒä¸€ä¸ªè§‚æµ‹å€¼å¯èƒ½å¯¹åº”å¤šä¸ªå¯èƒ½çš„ä¸–ç•ŒçŠ¶æ€ã€‚ä¸ºäº†åº”å¯¹è¿™ç§æ¨¡ç³Šæ€§ï¼Œæœ€å¥½çš„æ–¹æ³•æ˜¯è®¡ç®—è§‚æµ‹æ•°æ®ä¸‹å¯èƒ½çš„ä¸–ç•ŒçŠ¶æ€çš„åéªŒæ¦‚ç‡åˆ†å¸ƒã€‚

2. **è®¡ç®—æœºè§†è§‰çš„ç›®æ ‡**ï¼šè®¡ç®—æœºè§†è§‰çš„ç›®æ ‡æ˜¯åŸºäºè§‚æµ‹å€¼ï¼ˆå¦‚å›¾åƒæ•°æ®ï¼‰è¾“å‡ºä¸€ä¸ªå…³äºä¸–ç•ŒçŠ¶æ€çš„æ¦‚ç‡åˆ†å¸ƒã€‚ç”±äºç›´æ¥æ±‚è§£å¯èƒ½éå¸¸å¤æ‚ï¼Œé€šå¸¸å¯ä»¥ä½¿ç”¨è¿‘ä¼¼æ–¹æ³•æˆ–é€‰æ‹©æœ€å¤§åéªŒï¼ˆMAPï¼‰ä¼°è®¡æ¥ä»£è¡¨æœ€å¯èƒ½çš„ä¸–ç•ŒçŠ¶æ€ã€‚

3. **è§£å†³æ–¹æ¡ˆçš„ç»„æˆéƒ¨åˆ†**ï¼šè¦è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œéœ€è¦è®¾è®¡ä¸€ä¸ªæ¨¡å‹æ¥å°†è§†è§‰æ•°æ®å’Œä¸–ç•ŒçŠ¶æ€è”ç³»èµ·æ¥ï¼Œå¹¶é€šè¿‡å­¦ä¹ ç®—æ³•æ‹Ÿåˆæ¨¡å‹å‚æ•°ã€‚æœ€åé€šè¿‡æ¨ç†ç®—æ³•åœ¨æ–°çš„è§‚æµ‹æ•°æ®ä¸‹ä¼°è®¡å¯èƒ½çš„ä¸–ç•ŒçŠ¶æ€çš„æ¦‚ç‡ã€‚

4. ==**æ¨¡å‹çš„ç±»å‹**ï¼šä¸»è¦æœ‰ä¸¤ç±»æ¨¡å‹ï¼š==
   - åŸºäºè§‚æµ‹æ•°æ®é¢„æµ‹ä¸–ç•ŒçŠ¶æ€çš„æ¨¡å‹ \( Pr(w|x) \)ã€‚Discriminative
   - åŸºäºä¸–ç•ŒçŠ¶æ€é¢„æµ‹è§‚æµ‹æ•°æ®çš„æ¨¡å‹ \( Pr(x|w) \)ã€‚Generative

5. ä¸åŒçš„ä¸–ç•ŒçŠ¶æ€çš„è¾“å‡ºå¯¹åº”çš„æ¨¡å‹ç±»å‹ï¼š

    ![image-20241029120131551](./ppt 89.assets/image-20241029120131551.png)

### 1. Model

#### 1.1 Discriminative â€” Model contingency of the world on the data

é€šè¿‡è§‚æµ‹æ•°æ®è§‚æµ‹ä¸–ç•ŒçŠ¶æ€çš„æ¦‚ç‡ Pr(w|x)

**åˆ¤åˆ«æ¨¡å‹**æ—¨åœ¨ç›´æ¥ä¼°è®¡ç»™å®šè§‚æµ‹æ•°æ® x æ—¶ï¼ŒæŸä¸€ç‰¹å®šä¸–ç•ŒçŠ¶æ€ w å‘ç”Ÿçš„æ¦‚ç‡Pr(wâˆ£x)ã€‚

1. Choose an appropriate form for Pr(**w**)

2. Make parameters a function of **x**

3. Function takes parameters Î¸ that define its shape

å­¦ä¹ ç®—æ³•ï¼šï¼ˆLearning algorithmï¼‰ learn parameters Î¸ from training data.

æ¨ç†ç®—æ³•ï¼šï¼ˆInference algorithmï¼‰åœ¨æ¨¡å‹å­¦ä¹ å®Œæˆåï¼Œç›´æ¥è®¡ç®— Pr(wâˆ£x)ï¼Œå³åœ¨ç»™å®šè§‚æµ‹æ•°æ®æ—¶é¢„æµ‹ç‰¹å®šçŠ¶æ€çš„å¯èƒ½æ€§ã€‚just evaluate Pr(w|x)ã€‚



#### 1.2 Generative â€” Model contingency of data on world

é€šè¿‡è§‚æµ‹ä¸–ç•ŒçŠ¶æ€è§‚æµ‹æ•°æ®çš„æ¦‚ç‡ Pr(x|w)ã€‚

**ç”Ÿæˆæ¨¡å‹**ä¸ç›´æ¥ä¼°è®¡ Pr(wâˆ£x)ï¼Œè€Œæ˜¯é€šè¿‡å…ˆä¼°è®¡åœ¨æŸä¸ªä¸–ç•ŒçŠ¶æ€ w ä¸‹è§‚æµ‹æ•°æ® x çš„æ¦‚ç‡ Pr(xâˆ£w)ï¼Œå†ä½¿ç”¨è´å¶æ–¯å…¬å¼è®¡ç®— Pr(wâˆ£x)ã€‚

1. Choose an appropriate form for Pr(**x**)
2. Make parameters a function of **w**
3. Function takes parameters Î¸ that define its shape

Learning algorithm: learn parameters Î¸ from training data.

Inference algorithm: Define prior Pr(**w**) and then compute Pr(**w**|**x**) using Bayesâ€™ rule.

<img src="./ppt 89.assets/ttt8.png" alt="image-20241029111612208" style="zoom:50%;" />

### 2. Linear Regression

Consider:

- we make a univariate(å•å˜é‡çš„) continuous measurement **x**
- use this to predict a univariate continuous state **w**

**regression as world state is continuous**



#### 2.1 Discriminative

è¿™äº›å¹»ç¯ç‰‡è®²è§£äº†å¦‚ä½•åœ¨åˆ¤åˆ«æ¨¡å‹ä¸­ä½¿ç”¨çº¿æ€§å›å½’æ¥å»ºæ¨¡å’Œé¢„æµ‹å˜é‡ w ä¸è§‚æµ‹å˜é‡ x ä¹‹é—´çš„å…³ç³»ã€‚

- How to model Pr(**w**|**x**)?
    - Choose an appropriate form for Pr(**w**)
    - Make parameters a function of **x**
    - Function takes parameters **ï±** that define its shape

- **æ¨¡å‹é€‰æ‹©**ï¼šé€‰æ‹©ä¸€ä¸ªé€‚å½“çš„æ¦‚ç‡åˆ†å¸ƒæ¥æè¿° Pr(wâˆ£x)ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€‰æ‹©äº†æ­£æ€åˆ†å¸ƒ (Normal distribution) ä½œä¸ºåˆ†å¸ƒå½¢å¼ã€‚

    - Choose normal distribution over w
    - Assume that the mean value Î¼ of w is a linear function of x, i.e. Î¼ = Ï•0 + Ï•1 .
    - The variance Ïƒ2 is assumed to be constant and not varying with x.

- æ•´ä¸ªå‡½æ•°å¯ä»¥å’Œç®€å†™æˆï¼š

    ![image-20241029121022435](./ppt 89.assets/image-20241029121022435.png)

- Learning algorithm

    E.g. MAP

    <img src="./ppt 89.assets/image-20241029121122770.png" alt="image-20241029121122770" style="zoom:50%;" />

- Inference algorithm: just evaluate Pr(**w**|**x,**ğœƒ) for new data **x**

    

### 3. Logistics regression

ç¦»æ•£çš„ï¼ŒåŒä¸Šæ‰€è¿°ã€‚

#### 3.1 Discriminative

è¿™äº›é¡µé¢è¯¦ç»†è¯´æ˜äº†ç”Ÿæˆæ¨¡å‹ (Generative Model) çš„æ„å»ºæ–¹æ³•åŠå…¶è¿ä½œåŸç†ã€‚

1. **å¦‚ä½•æ„å»º \( P(x|w) \)**

- é€‰æ‹©ä¸€ä¸ªé€‚å½“çš„å½¢å¼ï¼šåœ¨è¿™é‡Œï¼Œä¸ºäº†æ¨¡å‹ \( P(x|w) \)ï¼Œæˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒã€‚
- ä½¿å‚æ•°æˆä¸º \( w \) çš„å‡½æ•°ï¼šå› ä¸ºæˆ‘ä»¬å¸Œæœ›æ•°æ® \( x \) çš„åˆ†å¸ƒä¾èµ–äºåˆ†ç±» \( w \) çš„å€¼ï¼ˆä¾‹å¦‚ï¼ŒäºŒåˆ†ç±»æƒ…å†µä¸‹ \( w \) ä¸º 0 æˆ– 1ï¼‰ã€‚
- å®šä¹‰æ¨¡å‹çš„å‚æ•°ï¼šæ¨¡å‹æœ‰å‚æ•°Î¸ï¼ˆæ¯”å¦‚ Î¼0ã€ Î¼1ã€ Ïƒ0 å’Œ Ïƒ1ï¼‰ï¼Œè¿™äº›å‚æ•°å†³å®šäº† \( P(x|w) \) çš„å½¢çŠ¶ã€‚

2. **å­¦ä¹ ç®—æ³•**

åœ¨å­¦ä¹ ç®—æ³•éƒ¨åˆ†ï¼Œé€šè¿‡ä½¿ç”¨è®­ç»ƒæ•°æ®é›† { \( x_i \), \( w_i \) } æ¥ä¼°è®¡å‚æ•° \(Î¸ \)ã€‚è¿™äº›å‚æ•°è¢«æ‹Ÿåˆåˆ°æ•°æ®ä¸­ï¼Œä½¿å¾—å¯¹äºå·²çŸ¥ \( w \) çš„æƒ…å†µä¸‹ \( x \) çš„æ¦‚ç‡æœ€å¤§åŒ–ã€‚

3. **æ¨ç†ç®—æ³•**

æ¨ç†ç®—æ³•çš„ç›®æ ‡æ˜¯é€šè¿‡è´å¶æ–¯è§„åˆ™è®¡ç®—åéªŒåˆ†å¸ƒ \( P(w|x) \)ã€‚è®¡ç®—åéªŒåˆ†å¸ƒæ—¶ï¼Œæˆ‘ä»¬ä¼šå®šä¹‰ \( P(w) \) çš„å…ˆéªŒåˆ†å¸ƒï¼ˆè¿™é‡Œä½¿ç”¨ä¼¯åŠªåˆ©åˆ†å¸ƒè¡¨ç¤ºäºŒåˆ†ç±»çš„å…ˆéªŒæ¦‚ç‡ï¼‰ï¼Œç„¶åé€šè¿‡è´å¶æ–¯å…¬å¼ï¼š

![image-20241029123211634](./ppt 89.assets/image-20241029123211634.png)

åœ¨ç¦»æ•£æƒ…å†µä¸‹ï¼Œè¿™å¯ä»¥ç®€åŒ–ä¸ºæ±‚å’Œå½¢å¼ã€‚

**ç”Ÿæˆæ¨¡å‹ä¸­çš„ä¾‹å­**

å›¾ä¸­å±•ç¤ºäº†ç”Ÿæˆæ¨¡å‹çš„å…¸å‹æƒ…å†µï¼šä¸¤ç±» \( w = 0 \) å’Œ \( w = 1 \) çš„æ•°æ®åˆ†å¸ƒï¼ˆåˆ†åˆ«ç”¨è“è‰²å’Œçº¢è‰²è¡¨ç¤ºï¼‰ã€‚ä¸åŒç±»åˆ«çš„ \( x \) åˆ†å¸ƒåœ¨ä¸åŒçš„å‡å€¼ Î¼0 å’Œ Î¼1å‘¨å›´ï¼Œå¹¶å…·æœ‰ä¸åŒçš„æ–¹å·® Ïƒ0 å’Œ Ïƒ1ã€‚



### 4. Review Questions

![image-20241029124224566](./ppt 89.assets/image-20241029124224566.png)

#### 4.1 

è¿™å¼ å›¾è¡¨å¯¹æ¯”äº† **çº¿æ€§å›å½’** å’Œ **é€»è¾‘å›å½’** çš„ä¸»è¦åŒºåˆ«ã€‚ä»¥ä¸‹æ˜¯æ€»ç»“å’Œè¡¥å……ï¼š

1. ==**å“åº”å˜é‡çš„ç±»å‹**==

- **çº¿æ€§å›å½’**ï¼šé€‚ç”¨äº **è¿ç»­å€¼** å“åº”å˜é‡ï¼Œä¾‹å¦‚ä»·æ ¼ã€é«˜åº¦ã€å¹´é¾„ã€è·ç¦»ç­‰ã€‚
- **é€»è¾‘å›å½’**ï¼šé€‚ç”¨äº **åˆ†ç±»å€¼** å“åº”å˜é‡ï¼Œä¾‹å¦‚äºŒå…ƒåˆ†ç±» (yes/no, win/loss)ã€‚

2. ==**æ‹Ÿåˆæ–¹æ³•**==

- **çº¿æ€§å›å½’**ï¼šä½¿ç”¨ **æœ€å°äºŒä¹˜æ³•** æ¥æ‰¾åˆ°æœ€ä½³æ‹Ÿåˆç›´çº¿ï¼Œä»¥æœ€å°åŒ–é¢„æµ‹å€¼å’Œå®é™…å€¼ä¹‹é—´çš„è¯¯å·®ã€‚
- **é€»è¾‘å›å½’**ï¼šä½¿ç”¨ **æœ€å¤§ä¼¼ç„¶ä¼°è®¡** æ¥æ‰¾åˆ°æœ€ä½³å‚æ•°ï¼Œä»è€Œæœ€å¤§åŒ–è§‚æµ‹æ•°æ®çš„æ¦‚ç‡ã€‚

3. ==**ç›‘ç£å­¦ä¹ ç±»å‹**==

- **çº¿æ€§å›å½’**ï¼šç”¨äº **å›å½’ä»»åŠ¡**ï¼Œç›®æ ‡æ˜¯é¢„æµ‹ä¸€ä¸ªè¿ç»­çš„æ•°å€¼ã€‚
- **é€»è¾‘å›å½’**ï¼šç”¨äº **åˆ†ç±»ä»»åŠ¡**ï¼Œç›®æ ‡æ˜¯é¢„æµ‹ç±»åˆ«æ ‡ç­¾ã€‚

4. ==**è¾“å‡º**==

- **çº¿æ€§å›å½’**ï¼šç›´æ¥é¢„æµ‹æ•°å€¼è¾“å‡ºï¼Œå¦‚ $150ã€14 inchesã€2 monthsã€1.23 milesã€‚
- **é€»è¾‘å›å½’**ï¼šè¾“å‡ºçš„æ˜¯å±äºæŸä¸ªç±»åˆ«çš„ **æ¦‚ç‡å€¼**ï¼Œå¦‚ 40.3% æˆ– 90%ï¼Œå¹¶æ ¹æ®æ¦‚ç‡è¿›è¡Œåˆ†ç±»

