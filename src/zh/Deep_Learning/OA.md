---
title: Optimization objectives and challenges
icon: alias
date: 2025-06-01 23:03:32
author: XiaoXianYue
isOriginal: true
category: 
    - æ·±åº¦å­¦ä¹ 
tag:
    - æ·±åº¦å­¦ä¹ 
sticky: false
star: false
article: true
timeline: true
image: false
navbar: true
sidebarIcon: true
headerDepth: 5
lastUpdated: true
editLink: false
backToTop: true
toc: true
---

## 1. Introduction

### 1.1 ä¼˜åŒ–å­¦ä¹ ç›®æ ‡

>  Distinguish between the objectives of optimization and those of deep learning (DL)

In the context of DL problems, after defining the loss function, we can utilize an optimization algorithm, also known as an optimizer, to minimize this loss function.
 ğŸ‘‰ åœ¨æ·±åº¦å­¦ä¹ é—®é¢˜ä¸­ï¼Œåœ¨å®šä¹‰å¥½æŸå¤±å‡½æ•°åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¼˜åŒ–ç®—æ³•ï¼ˆä¹Ÿç§°ä¸ºä¼˜åŒ–å™¨ï¼‰æ¥æœ€å°åŒ–è¿™ä¸ªæŸå¤±å‡½æ•°ã€‚

**==The goal of optimization== is to reduce the training error by minimizing the loss function based on the training dataset.**
 ğŸ‘‰ ä¼˜åŒ–çš„ç›®æ ‡æ˜¯é€šè¿‡åœ¨è®­ç»ƒé›†ä¸Šæœ€å°åŒ–æŸå¤±å‡½æ•°ï¼Œä»è€Œå‡å°è®­ç»ƒè¯¯å·®ã€‚

<img src="./OA.assets/image-20250610163517978.png" alt="image-20250610163517978" style="zoom:50%;" />

The general form of the optimization problem can be expressed by this formula: **minimize f(x)**, where f is the loss function, representing **the difference between** the ground truth value of the real prediction label and the predicted value.
 ğŸ‘‰ ä¼˜åŒ–é—®é¢˜çš„ä¸€èˆ¬å½¢å¼å¯ä»¥é€šè¿‡è¿™ä¸ªå…¬å¼è¡¨è¾¾ï¼šæœ€å°åŒ– $f(x)$ï¼Œå…¶ä¸­ $f$ æ˜¯æŸå¤±å‡½æ•°ï¼Œç”¨äºè¡¨ç¤ºçœŸå®æ ‡ç­¾ä¸é¢„æµ‹æ ‡ç­¾ä¹‹é—´çš„å·®å¼‚ã€‚



ğŸ‘‰ åœ¨æ»¡è¶³çº¦æŸæ¡ä»¶ $x \in C$ çš„å‰æä¸‹ï¼Œæœ€å°åŒ–æŸå¤±å‡½æ•° $f(x)$ ï¼ˆå³ä¼˜åŒ–é—®é¢˜çš„ä¸€èˆ¬å½¢å¼ï¼‰ã€‚

- x represents the features used to obtain the predicted value and the model parameters, which are restricted by the set C.
     ğŸ‘‰ x ä»£è¡¨ç”¨äºè·å¾—é¢„æµ‹å€¼çš„ç‰¹å¾ï¼Œä»¥åŠæ¨¡å‹çš„å‚æ•°ï¼Œè¿™äº›å‚æ•°å—é›†åˆ C çš„é™åˆ¶ã€‚
- Regarding this set C, there are two situations.
     ğŸ‘‰ å…³äºé›†åˆ Cï¼Œé€šå¸¸æœ‰ä¸¤ç§æƒ…å†µï¼š
     1ï¸âƒ£ One is that the set is restricted. For example, **we specify that the weights must all be greater than 0 as a constraint**.
     ğŸ‘‰ ä¸€ç§æƒ…å†µæ˜¯ C å—é™ã€‚ä¾‹å¦‚ï¼šæˆ‘ä»¬è§„å®šæ‰€æœ‰æƒé‡å¿…é¡»å¤§äº 0ï¼ˆå³åŠ ä¸€ä¸ªçº¦æŸæ¡ä»¶ï¼‰ã€‚
     2ï¸âƒ£ However, usually, we can **leave C unrestricted, which can make the training a bit faster**.
     ğŸ‘‰ ä½†é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ä¸å¯¹ C è¿›è¡Œçº¦æŸï¼Œè¿™æ ·å¯ä»¥è®©è®­ç»ƒæ›´å¿«ä¸€äº›ã€‚

- **The goal of deep learning (DL)** focuses on finding a suitable model and **reducing generalization error** given a limited amount of data.
     ğŸ‘‰ æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„æ¨¡å‹ï¼Œå¹¶ä¸”åœ¨æœ‰é™æ•°æ®çš„æƒ…å†µä¸‹ï¼Œé™ä½æ³›åŒ–è¯¯å·®ã€‚

- To achieve DL goals, in addition to using optimization algorithms to reduce training error, we **also need to be mindful of overfitting.**
     ğŸ‘‰ ä¸ºäº†å®ç°æ·±åº¦å­¦ä¹ çš„ç›®æ ‡ï¼Œé™¤äº†ä½¿ç”¨ä¼˜åŒ–ç®—æ³•æ¥å‡å°‘è®­ç»ƒè¯¯å·®å¤–ï¼Œæˆ‘ä»¬è¿˜å¿…é¡»æ³¨æ„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚
- Techniques like weight decay and dropout, which we previously discussed, are primarily used to prevent overfitting.
     ğŸ‘‰ ä¾‹å¦‚æƒé‡è¡°å‡å’Œ dropoutï¼ˆæˆ‘ä»¬ä¹‹å‰è®¨è®ºè¿‡ï¼‰ä¸»è¦ç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
- **In this chapter, we will specifically focus on the performance of optimization algorithms in minimizing the objective function, rather than the generalization error of the model.**
     ğŸ‘‰ åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨ä¼˜åŒ–ç®—æ³•åœ¨æœ€å°åŒ–ç›®æ ‡å‡½æ•°ï¼ˆæŸå¤±å‡½æ•°ï¼‰æ–¹é¢çš„è¡¨ç°ï¼Œè€Œä¸æ˜¯æ¨¡å‹çš„æ³›åŒ–è¯¯å·®ã€‚



### 1.2 Challenges of optimization

#### 1. local minimum

![image-20250610170003859](./OA.assets/image-20250610170003859.png)

- In this graph, the horizontal axis represents x, and the vertical axis represents the function values obtained from the function of x.
    åœ¨è¿™å¼ å›¾ä¸­ï¼Œæ¨ªåæ ‡è¡¨ç¤º xï¼Œçºµåæ ‡è¡¨ç¤ºç”± x å‡½æ•°å¾—åˆ°çš„å‡½æ•°å€¼ã€‚
- This blue curve represents the function values that change with x.
    - è¿™æ¡è“è‰²æ›²çº¿è¡¨ç¤ºå‡½æ•°å€¼éš x çš„å˜åŒ–ã€‚

- The green point is called the global minimum. Its definition is: ==the minimum value of the objective function over the entire domain==. If we can obtain the value of the global minimum of the objective function, it is definitely the most ==ideal situation==, which ==satisfies the optimization objective==.
    - ç»¿è‰²ç‚¹è¢«ç§°ä¸ºå…¨å±€æœ€å°å€¼ã€‚å®ƒçš„å®šä¹‰æ˜¯ï¼šåœ¨æ•´ä¸ªå®šä¹‰åŸŸå†…ç›®æ ‡å‡½æ•°çš„æœ€å°å€¼ã€‚å¦‚æœæˆ‘ä»¬èƒ½å¤Ÿå¾—åˆ°ç›®æ ‡å‡½æ•°çš„å…¨å±€æœ€å°å€¼ï¼Œé‚£ä¹ˆè¿™æ— ç–‘æ˜¯æœ€ç†æƒ³çš„æƒ…å†µï¼Œæ»¡è¶³ä¼˜åŒ–ç›®æ ‡ã€‚

- The purple point is a ==local minimum==. Its definition is: If the function value is the smallest ==within the region with a radius of Îµ (epsilon) around x\*==, in simple terms, if this point is the smallest within the range from x - Îµ to x + Îµ, then this value is the local minimum value of the objective function.
    - ç´«è‰²ç‚¹æ˜¯ä¸€ä¸ªå±€éƒ¨æœ€å°å€¼ã€‚å®ƒçš„å®šä¹‰æ˜¯ï¼šå¦‚æœåœ¨ä»¥ x* ä¸ºä¸­å¿ƒã€åŠå¾„ä¸º Îµï¼ˆepsilonï¼‰çš„åŒºåŸŸå†…ï¼Œå‡½æ•°å€¼æ˜¯æœ€å°çš„ã€‚ç®€å•æ¥è¯´ï¼Œå¦‚æœåœ¨ x - Îµ åˆ° x + Îµ çš„èŒƒå›´å†…ï¼Œè¯¥ç‚¹çš„å‡½æ•°å€¼æ˜¯æœ€å°çš„ï¼Œé‚£ä¹ˆè¯¥å€¼å°±æ˜¯ç›®æ ‡å‡½æ•°çš„å±€éƒ¨æœ€å°å€¼ã€‚



#### 2. saddle point

![image-20250610171745704](./OA.assets/image-20250610171745704.png)

åœ¨å·¦è¾¹çš„å›¾ä¸­ï¼Œæ˜¯ä¸€ç»´å‡½æ•° $f(x) = x^3$ çš„å›¾åƒã€‚å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ $x=0$ å¤„ï¼Œå‡½æ•°çš„æ–œç‡ï¼ˆä¸€é˜¶å¯¼æ•°ï¼‰ä¸ºé›¶ï¼ˆæ°´å¹³ï¼‰ï¼Œä½†è¿™ä¸ªç‚¹æ—¢ä¸æ˜¯å±€éƒ¨æœ€å°å€¼ä¹Ÿä¸æ˜¯å…¨å±€æœ€å°å€¼ã€‚è¿™ä¸ªç‚¹å°±æ˜¯æ‰€è°“çš„â€œéç‚¹â€ï¼Œåœ¨ä¼˜åŒ–ç®—æ³•ä¸­å¯èƒ½å¯¼è‡´ç®—æ³•é™·å…¥åœæ»ã€‚

å³è¾¹çš„å›¾ä¸­å±•ç¤ºäº†äºŒç»´å‡½æ•° $f(x,y)=x^2-y^2$ çš„ä¸‰ç»´æ›²é¢å›¾åƒã€‚å¯ä»¥çœ‹åˆ°åœ¨åŸç‚¹ (0,0) é™„è¿‘å‡½æ•°æ—¢æ²¡æœ‰å®Œå…¨å¾€ä¸‹ä¹Ÿæ²¡æœ‰å®Œå…¨å¾€ä¸Šï¼Œè€Œæ˜¯åƒé©¬éå½¢çŠ¶ï¼Œæ—¢æœ‰å‘ä¸Šçš„æ–¹å‘ï¼ˆxè½´æ–¹å‘ï¼‰åˆæœ‰å‘ä¸‹çš„æ–¹å‘ï¼ˆyè½´æ–¹å‘ï¼‰ã€‚è¿™å°±è§£é‡Šäº†éç‚¹çš„å«ä¹‰ï¼šå‡½æ•°çš„æ¢¯åº¦ï¼ˆä¸€é˜¶å¯¼æ•°ï¼‰ä¸ºé›¶ï¼Œä½†å®ƒæ—¢ä¸æ˜¯å±€éƒ¨æœ€å°å€¼ä¹Ÿä¸æ˜¯å±€éƒ¨æœ€å¤§å€¼ï¼Œè€Œæ˜¯â€œéå½¢â€å½¢æ€ã€‚

**å·¦è¾¹çš„å›¾**ï¼š

- The first derivative of this function is (3xÂ²), and the second derivative is 6x.
     è¯¥å‡½æ•°çš„ä¸€é˜¶å¯¼æ•°æ˜¯ (3xÂ²)ï¼ŒäºŒé˜¶å¯¼æ•°æ˜¯6xã€‚
- Therefore, both the first and second derivatives equal zero when x = 0.
     å› æ­¤ï¼Œå½“x=0æ—¶ï¼Œä¸€é˜¶å¯¼æ•°å’ŒäºŒé˜¶å¯¼æ•°éƒ½ç­‰äº0ã€‚
- As a result, optimization may halt at x = 0.
     å› æ­¤ï¼Œä¼˜åŒ–å¯èƒ½ä¼šåœæ»åœ¨x=0çš„ä½ç½®ã€‚
- ==However, as we can see, this point is neither a global minimum nor a local minimum.==
     ä½†æ˜¯æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œè¿™ä¸ªç‚¹æ—¢ä¸æ˜¯å…¨å±€æœ€å°å€¼ä¹Ÿä¸æ˜¯å±€éƒ¨æœ€å°å€¼ã€‚
- This type of point is called a saddle point.
     è¿™ç§ç‚¹è¢«ç§°ä¸ºéç‚¹ã€‚

**å³è¾¹çš„å›¾**ï¼š

- This is a two-dimensional function because the function is related to two variables.
     è¿™æ˜¯ä¸€ä¸ªäºŒç»´å‡½æ•°ï¼Œå› ä¸ºè¯¥å‡½æ•°ä¸ä¸¤ä¸ªå˜é‡æœ‰å…³ã€‚
- First, we find the partial derivative with respect to x, which is equal to 2x.
     é¦–å…ˆï¼Œå¯¹xæ±‚åå¯¼æ•°ï¼Œç»“æœæ˜¯2xã€‚
- When x = 0, the partial derivative is equal to 0.
     å½“x=0æ—¶ï¼Œåå¯¼æ•°ç­‰äº0ã€‚

- If we find the partial derivative with respect to y, it is equal to -2y.
 å¯¹yæ±‚åå¯¼æ•°æ—¶ï¼Œç»“æœæ˜¯-2yã€‚

- When y = 0, the partial derivative is also equal to 0.
     å½“y=0æ—¶ï¼Œåå¯¼æ•°ä¹Ÿç­‰äº0ã€‚

- Therefore, the saddle point is (0,0).
     å› æ­¤ï¼Œéç‚¹åœ¨(0,0)å¤„ã€‚

**å¯¹æ¯”**ï¼š

- By comparing the saddle points in low dimensions and high dimensions, we can find that ==as the dimension gets higher, the position of the saddle point becomes more concealed==.
     é€šè¿‡æ¯”è¾ƒä½ç»´å’Œé«˜ç»´ä¸­çš„éç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°ï¼šéšç€ç»´åº¦çš„å¢åŠ ï¼Œéç‚¹çš„ä½ç½®ä¼šå˜å¾—æ›´åŠ éšè”½ã€‚

- At the saddle point, the result of the derivative calculation is 0, which will cause the optimization of the algorithm to stop in advance.
     åœ¨éç‚¹å¤„ï¼Œå¯¼æ•°çš„è®¡ç®—ç»“æœä¸º0ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´ç®—æ³•æå‰åœæ­¢ä¼˜åŒ–ã€‚
- However, in fact, ==this point may be neither the global minimum value nor the local minimum value==.
     ç„¶è€Œå®é™…ä¸Šï¼Œè¿™ä¸ªç‚¹å¯èƒ½æ—¢ä¸æ˜¯å…¨å±€æœ€å°å€¼ï¼Œä¹Ÿä¸æ˜¯å±€éƒ¨æœ€å°å€¼ã€‚



#### 3. vanishing gradient

![image-20250610173205832](./OA.assets/image-20250610173205832.png)

1ï¸âƒ£ **è¿™å¹…å›¾å±•ç¤ºçš„æ˜¯ tanh(x) å‡½æ•°**

- å·¦è¾¹çš„è“è‰²æ›²çº¿æ˜¯å‡½æ•° $f(x) = \tanh(x)$ã€‚
- çºµåæ ‡è¡¨ç¤º $f(x)$ï¼Œæ¨ªåæ ‡æ˜¯ $x$ã€‚

2ï¸âƒ£ **æ¢¯åº¦æ¶ˆå¤±ï¼ˆVanishing Gradientï¼‰**

- å½“ $x$ è¶‹å‘äºè¾ƒå¤§çš„å€¼ï¼ˆæ¯”å¦‚ $x=4$ï¼‰æ—¶ï¼Œ$\tanh(x)$ å‡½æ•°çš„å¯¼æ•°è¶‹è¿‘äº0ï¼ˆå¤§æ¦‚åªæœ‰0.0013ï¼‰ï¼Œè¿™å°±æ˜¯æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚
- å³è¾¹çš„æ•°å­¦è¡¨è¾¾å¼å†™å‡ºäº†ï¼š
    - å‡½æ•°ï¼š$f(x) = \tanh(x)$
    - ä¸€é˜¶å¯¼æ•°ï¼š$f'(x) = 1 - \tanh^2(x)$
    - ç‰¹åˆ«åœ¨ $x=4$ å¤„ï¼Œ$f'(4) = 0.0013$ã€‚

3ï¸âƒ£ **ä¸ºä»€ä¹ˆæ¢¯åº¦æ¶ˆå¤±æ˜¯é—®é¢˜ï¼Ÿ**

- åœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­ï¼Œä¼˜åŒ–å™¨é€šè¿‡åå‘ä¼ æ’­åˆ©ç”¨æ¢¯åº¦æ›´æ–°æƒé‡ã€‚
- å¦‚æœæ¢¯åº¦è¿‡å°ï¼ˆè¶‹è¿‘äº0ï¼‰ï¼Œå‚æ•°æ›´æ–°å°±éå¸¸ç¼“æ…¢ï¼Œå¯¼è‡´è®­ç»ƒåœæ»ã€‚
- è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨æ·±å±‚ç¥ç»ç½‘ç»œä¸­å¸¸å¸¸éœ€è¦ç‰¹åˆ«çš„æŠ€å·§ï¼ˆæ¯”å¦‚ä½¿ç”¨ReLUã€Batch Normalizationç­‰ï¼‰æ¥é¿å…æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚



- The third challenge of optimization algorithms is the vanishing gradient problem, which is the most **insidious** issue among the three challenges.
     ğŸ‘‰ ä¼˜åŒ–ç®—æ³•çš„ç¬¬ä¸‰ä¸ªæŒ‘æˆ˜æ˜¯æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå®ƒæ˜¯è¿™ä¸‰å¤§æŒ‘æˆ˜ä¸­æœ€éšè”½çš„é—®é¢˜ã€‚

- In this graph, the horizontal axis is still x, and the vertical axis represents the loss function to be minimized.
     ğŸ‘‰ åœ¨è¿™å¼ å›¾ä¸­ï¼Œæ¨ªåæ ‡ä»ç„¶æ˜¯xï¼Œçºµåæ ‡è¡¨ç¤ºéœ€è¦æœ€å°åŒ–çš„æŸå¤±å‡½æ•°ã€‚
- Assuming f(x) = tanh(x) represented by this curve, the first derivative with respect to x is (1 - tanhÂ²(x)).
     ğŸ‘‰ å‡è®¾è¿™æ¡æ›²çº¿è¡¨ç¤º $f(x) = \tanh(x)$ï¼Œé‚£ä¹ˆå®ƒå¯¹xçš„ä¸€é˜¶å¯¼æ•°å°±æ˜¯ $1 - \tanh^2(x)$ã€‚
- When x = 4, the gradient of f is approximately 0.0013, which is ==very close to zero==.
     ğŸ‘‰ å½“x=4æ—¶ï¼Œ$f$ çš„æ¢¯åº¦å¤§çº¦æ˜¯0.0013ï¼Œéå¸¸æ¥è¿‘äº0ã€‚
- Therefore, the optimization process may stall for a long time after x = 4.
     ğŸ‘‰ å› æ­¤ï¼Œåœ¨x=4ä»¥åï¼Œä¼˜åŒ–è¿‡ç¨‹å¯èƒ½ä¼šé•¿æ—¶é—´åœæ»ã€‚

![image-20250610173611496](./OA.assets/image-20250610173611496.png)

- We have found that for the ==ReLU== activation function, when the input is greater than 0, ==there is no problem of vanishing gradient==.
     æˆ‘ä»¬å‘ç°ï¼Œå½“è¾“å…¥å¤§äº0æ—¶ï¼Œå¯¹äºReLUæ¿€æ´»å‡½æ•°ï¼Œå¹¶ä¸å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚
- However, for the other two activation functions, the sigmoid function and the tanh function, there exists the problem of vanishing gradient.
     ç„¶è€Œï¼Œå¯¹äºå¦å¤–ä¸¤ç§æ¿€æ´»å‡½æ•°â€”â€”sigmoidå‡½æ•°å’Œtanhå‡½æ•°â€”â€”åˆ™å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚

- The ReLU function was later introduced into the DL (deep learning) model.
     ä¹‹åï¼ŒReLUå‡½æ•°è¢«å¼•å…¥åˆ°æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰æ¨¡å‹ä¸­ã€‚
- For a certain period of time before, during the optimization process of training DL models, the vanishing gradient was a rather big challenge.
     åœ¨æ­¤ä¹‹å‰ï¼Œåœ¨è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹çš„ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œæ¢¯åº¦æ¶ˆå¤±æ›¾ç»æ˜¯ä¸€ä¸ªç›¸å½“å¤§çš„æŒ‘æˆ˜ã€‚

### 1.4 Convexity

#### å›¾è§£

![image-20250610173807555](./OA.assets/image-20250610173807555.png)

âœ… å…¬å¼ï¼š
$$
\forall x, y \in C, \quad \alpha x + (1-\alpha)y \in C, \quad \forall \alpha \in [0,1]
$$
è¡¨ç¤ºåœ¨å‡¸é›†ä¸­ï¼Œä»»æ„ä¸¤ç‚¹è¿çº¿ä¸Šçš„æ‰€æœ‰ç‚¹éƒ½åœ¨é›†åˆCå†…ã€‚

- å¦‚æœå›¾å½¢ä¸­çš„ä»»æ„ä¸¤ç‚¹è¿çº¿éƒ½åœ¨é›†åˆå†…ï¼Œé‚£ä¹ˆè¯¥é›†åˆå°±æ˜¯ **å‡¸é›†**ã€‚
- å¦‚æœå­˜åœ¨æŸæ¡è¿çº¿ä¸åœ¨é›†åˆå†…éƒ¨ï¼Œé‚£ä¹ˆè¯¥é›†åˆå°±æ˜¯ **éå‡¸é›†**ã€‚



If we **randomly select** two points within the blue shape and connect them to form a line, and **this line lies entirely within** the blue shape, it indicates that the blue shape is a convex set.
 ğŸ‘‰ å¦‚æœæˆ‘ä»¬åœ¨è“è‰²å½¢çŠ¶å†…éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹å¹¶å°†å®ƒä»¬è¿æ¥æˆä¸€æ¡çº¿ï¼Œå¹¶ä¸”è¿™æ¡çº¿å®Œå…¨ä½äºè“è‰²å½¢çŠ¶å†…ï¼Œé‚£ä¹ˆè¿™è¡¨ç¤ºè“è‰²å½¢çŠ¶æ˜¯ä¸€ä¸ªå‡¸é›†ã€‚

Select two points in the blue shape and connect them to form a line. **This line does not lie within** the blue shape. Therefore, this is a non-convex set.
 ğŸ‘‰ åœ¨è“è‰²å½¢çŠ¶ä¸­é€‰æ‹©ä¸¤ç‚¹å¹¶å°†å®ƒä»¬è¿æ¥æˆä¸€æ¡çº¿ã€‚è¿™æ¡çº¿æ²¡æœ‰å®Œå…¨ä½äºè“è‰²å½¢çŠ¶å†…ã€‚å› æ­¤ï¼Œè¿™æ˜¯ä¸€ä¸ªéå‡¸é›†ã€‚

Corresponding to our optimization formula, **C** is still the set to which x in the objective function f(x) belongs, and it corresponds to **this blue shape**.
 ğŸ‘‰ å¯¹åº”äºæˆ‘ä»¬çš„ä¼˜åŒ–å…¬å¼ï¼ŒC ä¾ç„¶æ˜¯ç›®æ ‡å‡½æ•° f(x) ä¸­ x æ‰€åœ¨çš„é›†åˆï¼Œå®ƒå¯¹åº”äºè¿™ä¸ªè“è‰²å½¢çŠ¶ã€‚

The **two points** are **x** and **y** respectively, and this **line** is represented by **Î±x + (1 - Î±)y**.
 ğŸ‘‰ è¿™ä¸¤ä¸ªç‚¹åˆ†åˆ«æ˜¯ x å’Œ yï¼Œè¿™æ¡çº¿è¡¨ç¤ºä¸º Î±x + (1 - Î±)yã€‚

Then Î± belongs to the interval from 0 to 1, that is, for any two points x and y in the set C.
 ğŸ‘‰ é‚£ä¹ˆ Î± å±äº [0,1] åŒºé—´ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹äºé›†åˆ C ä¸­çš„ä»»æ„ä¸¤ä¸ªç‚¹ x å’Œ yã€‚

==If the connected line also lies within this set, it indicates that C is a convex set; otherwise, it is a non-convex set==.
 ğŸ‘‰ å¦‚æœè¿æ¥çš„ç›´çº¿ä¹Ÿåœ¨é›†åˆå†…éƒ¨ï¼Œé‚£ä¹ˆè¯´æ˜ C æ˜¯å‡¸é›†ï¼›å¦åˆ™å°±æ˜¯éå‡¸é›†ã€‚

#### Concept of a convex function

![image-20250610195018746](./OA.assets/image-20250610195018746.png)

è¿™æ˜¯ä¸€ä¸ªæŠ›ç‰©çº¿å‡½æ•°ã€‚å¦‚æœåœ¨å‡½æ•°ä¸Šéšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹å¹¶å°†å®ƒä»¬è¿æˆä¸€æ¡ç›´çº¿ï¼Œå¹¶ä¸”åœ¨çº¿æ®µä¸¤ç«¯ç‚¹ä¹‹é—´çš„æ¨ªåæ ‡åŒºé—´å†…ï¼Œ**å‡½æ•°æ›²çº¿å®Œå…¨ä½äºè¿™æ¡ç›´çº¿çš„ä¸‹æ–¹**ï¼Œ é‚£ä¹ˆè¿™ä¸ªå‡½æ•°å°±è¢«è®¤ä¸ºæ˜¯å‡¸å‡½æ•°ã€‚

![image-20250610195232151](./OA.assets/image-20250610195232151.png)

è¿™æ˜¯ä¸€ä¸ªä½™å¼¦å‡½æ•°ã€‚åœ¨è¯¥åŒºé—´å†…ï¼Œç¡®å®æœ‰éƒ¨åˆ†å‡½æ•°æ›²çº¿åœ¨è¿çº¿çš„ä¸‹æ–¹ã€‚ç„¶è€Œï¼Œä¹Ÿæœ‰ **éƒ¨åˆ†å‡½æ•°æ›²çº¿åœ¨è¿æ¥ä¸¤ç‚¹çš„ç›´çº¿ä¸Šæ–¹ã€‚** å› æ­¤ï¼Œè¿™æ˜¯ä¸€ä¸ªéå‡¸å‡½æ•°ã€‚æ›²çº¿ä¸­é«˜äºç›´çº¿çš„éƒ¨åˆ†ç”¨äº®ç»¿è‰²çº¿è¡¨ç¤ºã€‚

![image-20250610195434592](./OA.assets/image-20250610195434592.png)

è¿™æ˜¯ä¸€ä¸ªæŒ‡æ•°å‡½æ•°ã€‚å®ƒæ»¡è¶³è¿™æ ·çš„æ¡ä»¶ï¼šå¦‚æœåœ¨å‡½æ•°ä¸Šéšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹å¹¶å°†å®ƒä»¬è¿æˆä¸€æ¡ç›´çº¿ï¼Œä¸”åœ¨è¿™ä¸¤ä¸ªç‚¹çš„æ¨ªåæ ‡åŒºé—´å†…ï¼Œ**å¯¹åº”çš„å‡½æ•°æ›²çº¿éƒ½ä½äºè¿™æ¡ç›´çº¿çš„ä¸‹æ–¹**ã€‚å› æ­¤ï¼Œè¿™æ˜¯ä¸€ä¸ªå‡¸å‡½æ•°ã€‚

![image-20250610195654968](./OA.assets/image-20250610195654968.png)

 å‡¸å‡½æ•°æˆ–éå‡¸å‡½æ•°ä¸­çš„å‡½æ•°å¯¹åº”äºæˆ‘ä»¬ä¼˜åŒ–å…¬å¼ä¸­çš„ **f**ï¼Œä¹Ÿå°±æ˜¯ç›®æ ‡å‡½æ•°æˆ–æŸå¤±å‡½æ•°ã€‚

![image-20250610195736638](./OA.assets/image-20250610195736638.png)

åæ ‡è½´ä¸Šçš„ **ä¸¤ä¸ªç‚¹** åˆ†åˆ«æ˜¯ **x å’Œ y**ï¼Œå®ƒä»¬å±äºå‡¸é›† **C**ã€‚ å‡½æ•° **f** å¯¹åº”**çº¢è‰²æ›²çº¿**ã€‚è¿™é‡Œï¼ŒÎ± å–å€¼èŒƒå›´æ˜¯ [0,1]ã€‚Î±f(x) + (1 - Î±)f(y) å¯¹åº”äºå›¾ä¸­çš„ **å“çº¢è‰²** è¿çº¿ã€‚

![image-20250610200017037](./OA.assets/image-20250610200017037.png)

å¦‚æœçº¢è‰²éƒ¨åˆ†çš„å€¼éƒ½æ¯”å“çº¢è‰²éƒ¨åˆ†çš„å€¼è¦å°ï¼Œé‚£ä¹ˆ f æ»¡è¶³æˆä¸º **å‡¸å‡½æ•°** çš„æ¡ä»¶ã€‚å¦åˆ™ï¼Œå®ƒå°±æ˜¯ä¸€ä¸ªéå‡¸å‡½æ•°ã€‚

![image-20250610200548759](./OA.assets/image-20250610200548759.png)

å¦‚æœæ»¡è¶³ **x â‰  y**ï¼Œå¹¶ä¸”çº¢è‰²æ›²çº¿**å®Œå…¨ä½äº**å“çº¢è‰²ç›´çº¿çš„ä¸‹æ–¹ã€‚å’Œå‰é¢çš„å…¬å¼ç›¸æ¯”ï¼ŒåŒºåˆ«æ˜¯**ä¸åŒ…å«ç­‰å·æ¡ä»¶**ã€‚ é‚£ä¹ˆè¿™ä¸ªå‡½æ•°æ˜¯**ä¸¥æ ¼å‡¸å‡½æ•°**ã€‚

![image-20250610200748156](./OA.assets/image-20250610200748156.png)

å®ƒæ»¡è¶³å‡¸å‡½æ•°çš„æ‰€æœ‰æ¡ä»¶ï¼Œä½†**è¿æ¥çº¿å®Œå…¨ä¸å‡½æ•°é‡åˆ**ã€‚å› æ­¤ï¼Œè¿™æ˜¯ä¸€ä¸ª**éä¸¥æ ¼å‡¸å‡½æ•°**ã€‚

![image-20250610200848004](./OA.assets/image-20250610200848004.png)



ä¸¥æ ¼å‡¸ä¼˜åŒ–é—®é¢˜æœ‰**å”¯ä¸€çš„å…¨å±€æœ€å°å€¼**ï¼Œè€Œéä¸¥æ ¼å‡¸å‡½æ•°å¯èƒ½æœ‰**å¤šä¸ªå±€éƒ¨æå°å€¼**ã€‚è¿™æ˜¯å› ä¸ºå¦‚æœ $f$ æ˜¯ä¸€ä¸ªä¸¥æ ¼å‡¸å‡½æ•°å¹¶ä¸”é›†åˆ $C$ æ˜¯å‡¸çš„ï¼Œé‚£ä¹ˆå®ƒå°±å½¢æˆäº†**å‡¸ä¼˜åŒ–é—®é¢˜**ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ**ä»»ä½•å±€éƒ¨æœ€å°å€¼ä¹Ÿå¿…é¡»æ˜¯å…¨å±€æœ€å°å€¼**ï¼Œå¹¶ä¸”ä¿è¯æ˜¯å”¯ä¸€çš„ã€‚





## 2. Gradient Descent  Optimization Methods

### 2.1 æ¢¯åº¦ä¸‹é™åŸç†

"By using the ==Taylor expansion of the objective function==, we can obtain the ==approximation== formula of the first derivative."
 é€šè¿‡ä½¿ç”¨ç›®æ ‡å‡½æ•°çš„æ³°å‹’å±•å¼€å¼ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€é˜¶å¯¼æ•°çš„è¿‘ä¼¼å…¬å¼ã€‚

"Optimizing the objective function actually means ==minimizing the loss function== f(x) until it reaches the minimum value of 0."
 ä¼˜åŒ–ç›®æ ‡å‡½æ•°å®é™…ä¸Šæ„å‘³ç€æœ€å°åŒ–æŸå¤±å‡½æ•° f(x)ï¼Œç›´åˆ°å…¶è¾¾åˆ°æœ€å°å€¼ 0ã€‚

"Therefore, we move in the direction of the ==negative gradient== of f(x), that is, ==the direction of the negative first derivative==, to ==reduce f==."
 å› æ­¤ï¼Œæˆ‘ä»¬æ²¿ç€ f(x) çš„è´Ÿæ¢¯åº¦æ–¹å‘ï¼ˆå³è´Ÿçš„ä¸€é˜¶å¯¼æ•°çš„æ–¹å‘ï¼‰ç§»åŠ¨ï¼Œä»¥å‡å°‘ fã€‚

![image-20250610205250099](./OA.assets/image-20250610205250099.png)

ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªå›ºå®šçš„æ­¥é•¿ Î·ï¼Œå¹¶ä»¤ Îµ = âˆ’Î· â‹… fâ€²(x)ï¼Œä»è€Œå¾—åˆ°ç¬¬äºŒä¸ªå…¬å¼ã€‚è¿™é‡Œï¼ŒÎ· å¤§äº 0ã€‚

![image-20250610205329582](./OA.assets/image-20250610205329582.png)

æˆ‘ä»¬æ€»å¯ä»¥é€‰æ‹©ä¸€ä¸ªè¶³å¤Ÿå°çš„ Î·ï¼Œä½¿å¾—è¿™ä¸ªè¡¨è¾¾å¼ç‹¬ç«‹äºé«˜é˜¶é¡¹ã€‚å› æ­¤ï¼Œè¿™ä¸ªè¡¨è¾¾å¼å°äºæˆ–è¿‘ä¼¼ç­‰äº f(x)ã€‚

 $x \leftarrow x - \eta f'(x)$

**è®²è§£ï¼š**
 è¿™å°±æ˜¯æ¢¯åº¦ä¸‹é™çš„æ›´æ–°å…¬å¼ï¼šä½¿ç”¨å­¦ä¹ ç‡ $\eta$ å’Œæ¢¯åº¦ $f'(x)$ æ¥æ›´æ–° $x$ çš„å€¼ï¼Œé€æ­¥é€¼è¿‘å‡½æ•°çš„æœ€å°å€¼ã€‚

- Through these three steps, we can observe that by updating $x$ with $x - \eta \cdot f'(x)$, the value of $f(x)$ may **decrease**.

    é€šè¿‡è¿™ä¸‰ä¸ªæ­¥éª¤ï¼Œæˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œé€šè¿‡å°† $x$ æ›´æ–°ä¸º $x - \eta \cdot f'(x)$ï¼Œ$f(x)$ çš„å€¼å¯èƒ½ä¼š**å‡å°**ã€‚

- What is gradient descent? As shown in the update formula, the first derivative (i.e., the gradient) decreases step by step. During this process, ==$x$, which might represent the model parameters, is continuously updated. As long as the gradient does not equal zero (since $\eta > 0$), the value of $f$ (i.e., the loss function) will keep **decreasing**==.

    â‘  ä»€ä¹ˆæ˜¯æ¢¯åº¦ä¸‹é™ï¼Ÿæ­£å¦‚æ›´æ–°å…¬å¼ä¸­æ‰€ç¤ºï¼Œå‡½æ•°çš„ä¸€é˜¶å¯¼æ•°ï¼ˆå³æ¢¯åº¦ï¼‰ä¸€æ­¥æ­¥åœ°å‡å°‘ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œ$x$ï¼ˆå¯ä»¥è¡¨ç¤ºæ¨¡å‹å‚æ•°ï¼‰ä¼šä¸æ–­åœ°è¢«æ›´æ–°ã€‚åªè¦æ¢¯åº¦ä¸ä¸ºé›¶ï¼ˆå› ä¸º $\eta > 0$ï¼‰ï¼Œ$f$ çš„å€¼ï¼ˆå³æŸå¤±å‡½æ•°ï¼‰å°±ä¼šä¸æ–­**å‡å°**ã€‚

![image-20250610211017195](./OA.assets/image-20250610211017195.png)

è¿™ä¸ªè¿‡ç¨‹ä½•æ—¶åœæ­¢ï¼Ÿå½“æ¢¯åº¦æ¥è¿‘çº¦ç­‰äºé›¶æ—¶åœæ­¢ã€‚æ­¤æ—¶ï¼Œã€‚ã€‚ã€‚ï¼Œå› æ­¤ x ä¸å†æ›´æ–°ï¼Œä¼˜åŒ–è¿‡ç¨‹ç»“æŸã€‚

å¦å¤–ï¼Œä¼˜åŒ–ä¹Ÿå¯ä»¥åœ¨è®¾å®šçš„è¿­ä»£æ¬¡æ•°ï¼ˆepochsï¼‰è¾¾åˆ°é¢„å®šä¹‰å€¼æ—¶ç»ˆæ­¢ã€‚

#### ä¾‹å­

![image-20250610211420765](./OA.assets/image-20250610211420765.png)

å‡è®¾ç›®æ ‡å‡½æ•°æ˜¯ $f(x) = x^2$ã€‚æˆ‘ä»¬é¦–å…ˆå°† $x = 10$ è®¾ä¸ºæ›´æ–°çš„åˆå§‹å€¼ï¼ˆå³åˆå§‹åŒ–æ¨¡å‹å‚æ•°ï¼‰ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰è¶…å‚æ•° $\eta$ï¼ˆå­¦ä¹ ç‡ï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è¿­ä»£æ¬¡æ•°ï¼ˆepochï¼‰è®¾ç½®ä¸º 10ã€‚

![image-20250610211804032](./OA.assets/image-20250610211804032.png)

åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹å‚æ•° $x$ ä¼šéšç€æ¢¯åº¦çš„å‡å°è€Œä¸æ–­æ›´æ–°ã€‚åŒæ—¶ï¼Œç›®æ ‡å‡½æ•°çš„å€¼ä¹Ÿä¼šé€æ¸å˜å°ã€‚å½“è¿­ä»£æ¬¡æ•°ï¼ˆepochï¼‰è¾¾åˆ° 10 æ¬¡æ—¶ï¼Œæ¨¡å‹æ¥è¿‘æœ€ä¼˜è§£ï¼Œå³å…¨å±€æœ€å°å€¼ã€‚

![image-20250610211929152](./OA.assets/image-20250610211929152.png)

#### Learning rate

![image-20250610212023550](./OA.assets/image-20250610212023550.png)

å­¦ä¹ ç‡ Î· å†³å®šäº†ç›®æ ‡å‡½æ•°èƒ½å¦æ”¶æ•›åˆ°å±€éƒ¨æœ€å°å€¼ï¼Œä»¥åŠæ”¶æ•›çš„é€Ÿåº¦ã€‚

![image-20250610212204812](./OA.assets/image-20250610212204812.png)

åœ¨å·¦è¾¹çš„å›¾ä¸­ï¼Œå­¦ä¹ ç‡ Î· è¢«è®¾ç½®ä¸ºå›ºå®šå€¼ 0.05ã€‚å› æ­¤ï¼Œå‚æ•° x çš„æ›´æ–°é€Ÿåº¦ç›¸å¯¹è¾ƒæ…¢ï¼Œåœ¨ç»è¿‡ 10 æ¬¡è¿­ä»£åï¼Œf(x) ä»ç„¶è·ç¦»æœ€ä¼˜è§£è¾ƒè¿œã€‚

å¦‚æœå­¦ä¹ ç‡è®¾ç½®ä¸º 1.1ï¼Œå¦‚å…¬å¼æ‰€ç¤ºï¼Œé«˜é˜¶é¡¹ï¼ˆè®°ä½œ O(Â·)ï¼‰å¯èƒ½ä¼šå˜å¾—æ˜¾è‘—ã€‚å› æ­¤ï¼Œæ›´æ–° x ä¸å†ä¿è¯ f(x) ä¼šå‡å°‘ï¼Œè¿™æ„å‘³ç€æŸå¤±å‡½æ•°çš„å€¼å¯èƒ½ä¸ä¼šå•è°ƒä¸‹é™ã€‚å›¾ä¸­ä¹Ÿæ˜¾ç¤ºäº†ï¼ŒæŸå¤±å‡½æ•°çš„å€¼ä¸‹é™ä¸ç¨³å®šï¼Œå¹¶ä¸”éš¾ä»¥æ”¶æ•›åˆ° x = 0ã€‚

- **ç¬¬ä¸€é¡¹ f(x)**ï¼šå½“å‰ç‚¹çš„å‡½æ•°å€¼
- **ç¬¬äºŒé¡¹ -Î·[f'(x)]Â²**ï¼šä¸‹é™çš„ä¸»è¦éƒ¨åˆ†ï¼ˆé€šå¸¸æœŸæœ›è¿™é¡¹æ˜¯è´Ÿçš„ï¼Œå®ç°ç›®æ ‡å‡½æ•°å‡å°ï¼‰
- **ç¬¬ä¸‰é¡¹ O(Î·Â²[f'(x)]Â²)**ï¼šé«˜é˜¶é¡¹ï¼Œå¦‚æœå­¦ä¹ ç‡å¤§ï¼Œè¿™ä¸€é¡¹å¯èƒ½å˜å¾—æ˜¾è‘—ï¼Œå½±å“æ•´ä½“çš„å•è°ƒæ”¶æ•›æ€§ã€‚

![image-20250610212856661](./OA.assets/image-20250610212856661.png)

è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹éå‡¸å‡½æ•°ã€‚å¯¹äºéå‡¸å‡½æ•°ï¼Œå…¶å‡½æ•°å€¼ä¸æ»¡è¶³æ‰€æœ‰ç‚¹éƒ½åœ¨è¿æ¥ä»»æ„ä¸¤ç‚¹çš„ç›´çº¿ä»¥ä¸‹çš„æ¡ä»¶ã€‚è¿™é‡Œçš„å‡½æ•°æ˜¯ $x \cdot \cos(cx)$ï¼Œåœ¨è´Ÿæ— ç©·åˆ°æ­£æ— ç©·çš„èŒƒå›´å†…ï¼Œå®ƒæœ‰æ— æ•°ä¸ªå±€éƒ¨æœ€å°å€¼ã€‚

![image-20250610213118319](./OA.assets/image-20250610213118319.png)

è¿™é‡Œçš„å­¦ä¹ ç‡è¢«è®¾ç½®ä¸ºä¸€ä¸ªå›ºå®šå€¼ 2ï¼Œè¿™ä¸ªå€¼ç›¸å½“å¤§ã€‚å› æ­¤ï¼Œå½“å¼€å§‹ä»åˆå§‹å€¼ $x = 10$ æ›´æ–°å‚æ•°æ—¶ï¼Œä¸‹ä¸€æ¬¡æ›´æ–°ç›´æ¥è·³è¿‡äº†è¿™ä¸ªæ›´å¥½çš„å±€éƒ¨æœ€å°å€¼ã€‚æœ€ç»ˆï¼Œå½“è¿­ä»£æ¬¡æ•°ï¼ˆepochï¼‰è¾¾åˆ° 10 æ¬¡æ—¶ï¼Œæ¨¡å‹æ‰æ¥è¿‘è¿™ä¸ªå±€éƒ¨æœ€å°å€¼ã€‚æ˜¾ç„¶ï¼Œè¿™ä¸ªæ¨¡å‹å¹¶æ²¡æœ‰è¢«å¾ˆå¥½åœ°ä¼˜åŒ–ã€‚æ¢¯åº¦ä¸‹é™å¯èƒ½ä¼šé™·å…¥å±€éƒ¨æœ€å°å€¼ï¼Œæ— æ³•è·å¾—å…¨å±€æœ€å°å€¼ã€‚



## 3.  Gradient Descent Optimization Methods 01

### 3.1 Multi-dimensional


 **x = [xâ‚, xâ‚‚, ..., x_d]áµ€**

In the multi-dimensional case, x refers to a d-dimensional vector.

åœ¨å¤šç»´æƒ…å½¢ä¸‹ï¼Œx è¡¨ç¤ºä¸€ä¸ª d ç»´å‘é‡ã€‚

![image-20250621180034035](./OA.assets/image-20250621180034035.png)

![image-20250621180045686](./OA.assets/image-20250621180045686.png)

<img src="./OA.assets/image-20250621180713252.png" alt="image-20250621180713252" style="zoom:50%;" />

The computational cost per iteration for each variable when using gradient descent.
 When using the gradient descent method, **the computational cost** of each independent variable iteration **increases linearly with the number of samples $n$.**
 Therefore, when the **number of training samples is extremely large**, the computational cost of each gradient descent iteration becomes relatively high.
 Gradient descent requires computing the derivative **over the entire complete sample set**, so this cost is too high.

ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ—¶ï¼Œæ¯ä¸ªå˜é‡æ¯æ¬¡è¿­ä»£çš„è®¡ç®—æˆæœ¬ã€‚
ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ—¶ï¼Œæ¯æ¬¡ç‹¬ç«‹å˜é‡è¿­ä»£çš„è®¡ç®—æˆæœ¬ä¼šéšç€æ ·æœ¬æ•°é‡ ğ‘› çš„å¢åŠ è€Œçº¿æ€§å¢åŠ ã€‚
å› æ­¤ï¼Œå½“è®­ç»ƒæ ·æœ¬æ•°é‡éå¸¸å¤§æ—¶ï¼Œæ¯æ¬¡æ¢¯åº¦ä¸‹é™è¿­ä»£çš„è®¡ç®—æˆæœ¬ä¼šç›¸å¯¹è¾ƒé«˜ã€‚
æ¢¯åº¦ä¸‹é™æ³•éœ€è¦è®¡ç®—æ•´ä¸ªæ ·æœ¬é›†çš„å¯¼æ•°ï¼Œå› æ­¤è¿™ä¸ªæˆæœ¬è¿‡é«˜ã€‚

### 3.2 Stochastic Gradient Descent

> **The role of SGD is: to reduce the computational cost of each iteration.**

![image-20250621204717568](./OA.assets/image-20250621204717568.png)

> **Randomly and uniformly sample** a data sample $t_i$ from the data samples, where $i$ ranges from 1 to $n$.

O(1)

**The computational cost per iteration decreases** from $O(n)$ in gradient descent to $O(1)$ in SGD (a constant).
 In computer science, **big O** notation is commonly used to describe the **complexity or performance** of algorithms. It primarily **measures the time and space (memory or disk usage)** required by an algorithm as the input size grows.

- ç”¨æ¥æè¿°ç®—æ³•çš„æ—¶é—´æˆ–ç©ºé—´å¤æ‚åº¦ã€‚

![image-20250621204944999](./OA.assets/image-20250621204944999.png)

![image-20250621214013020](./OA.assets/image-20250621214013020.png)

> Since $i$ is randomly selected, the **expected value of this gradient equals the mean**.
>  Therefore, despite using stochastic sampling, the expected value of the gradient **still approximates that of the full dataset.**

- è™½ç„¶æ¯æ¬¡åªæ˜¯ä½¿ç”¨ä¸€ä¸ªæ ·æœ¬çš„æ¢¯åº¦è¿›è¡Œæ›´æ–°ï¼Œä½†**ä»æ•°å­¦æœŸæœ›æ¥çœ‹**ï¼š
    - SGD çš„æœŸæœ›æ¢¯åº¦ â‰ˆ æ€»ä½“æ¢¯åº¦ï¼›
    - æ‰€ä»¥åœ¨å¤šæ¬¡è¿­ä»£åï¼Œå®ƒä»èƒ½é€¼è¿‘æœ€ä¼˜è§£ã€‚



## 4. Momentum

### 4.1 Why to introduce?

![image-20250621215409223](./OA.assets/image-20250621215409223.png)

During the mini-batch stochastic gradient descent process, there is still **a relatively large fluctuation** in the change of this gradient.

Especially when the objective function is relatively complex, **in real life, the actual data we face is full of noise**, rather than the clean data in the experimental environment.

åœ¨å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™çš„è¿‡ç¨‹ä¸­ï¼Œ**æ¢¯åº¦çš„å˜åŒ–ä»ç„¶å­˜åœ¨è¾ƒå¤§çš„æ³¢åŠ¨**ã€‚

å°¤å…¶å½“ç›®æ ‡å‡½æ•°æ¯”è¾ƒå¤æ‚æ—¶ï¼Œ**åœ¨çœŸå®ç”Ÿæ´»ä¸­ï¼Œæˆ‘ä»¬é¢å¯¹çš„æ•°æ®å¾€å¾€å……æ»¡å™ªå£°**ï¼Œè€Œä¸æ˜¯åƒå®éªŒç¯å¢ƒä¸­é‚£ç§å¹²å‡€çš„æ•°æ®ã€‚

At this moment, we need a downward inertia to firmly choose Yuping Peak.

### 4.2 Whatâ€™s momentum

![image-20250621220832132](./OA.assets/image-20250621220832132.png)

Since beta is a value less than 1, as time progresses, it undergoes an exponential decay. **By the final item, it will become extremely small**.

ç”±äº $\beta < 1$ï¼Œæ‰€ä»¥æ¯ä¸€é¡¹å†å²æ¢¯åº¦åœ¨åŠ¨é‡ä¸­çš„è´¡çŒ®ä¼š**å‘ˆæŒ‡æ•°çº§è¡°å‡**ï¼Œåé¢çš„é¡¹å‡ ä¹ä¸º 0ã€‚

 The update of the weights at the current time step is not solely based on $g_t$. We also **need to consider the gradients from past time steps**.
 å½“å‰æ—¶åˆ»çš„æƒé‡æ›´æ–°ä¸ä»…ä»…ä¾èµ–äºå½“å‰çš„æ¢¯åº¦ $g_t$ï¼Œæˆ‘ä»¬è¿˜**éœ€è¦è€ƒè™‘è¿‡å»æ—¶é—´æ­¥çš„æ¢¯åº¦**ã€‚

**Suppose the gradients at the current and previous time steps differ significantly**.
The former is a large positive-valued quantity, while the latter is a large negative-valued quantity.
Then, when calculating the momentum, part of the values will cancel each other out, resulting in a much smaller value.
Therefore, **the parameter update will not be drastic**.

å‡è®¾å½“å‰ä¸ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„æ¢¯åº¦**å·®å¼‚å¾ˆå¤§**ï¼Œ
 å½“å‰çš„æ˜¯ä¸€ä¸ªè¾ƒå¤§çš„æ­£å€¼ï¼Œè€Œå‰ä¸€ä¸ªæ˜¯ä¸€ä¸ªè¾ƒå¤§çš„è´Ÿå€¼ã€‚
 é‚£ä¹ˆåœ¨è®¡ç®—åŠ¨é‡æ—¶ï¼Œ**å®ƒä»¬çš„ä¸€éƒ¨åˆ†ä¼šäº’ç›¸æŠµæ¶ˆ**ï¼Œå¯¼è‡´æ•´ä½“ç»“æœå˜å°ï¼Œ
 å› æ­¤ï¼Œ**å‚æ•°çš„æ›´æ–°å¹…åº¦ä¸ä¼šå‰§çƒˆè·³åŠ¨**ã€‚

This demonstrates that the momentum method can buffer gradient fluctuations to a certain extent,**preventing the model update from being unstable** due to drastic gradient changes.

è¿™è¡¨æ˜**åŠ¨é‡æ³•èƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“å†²æ¢¯åº¦çš„æ³¢åŠ¨**ï¼Œ
 **é¿å…ç”±äºæ¢¯åº¦å‰§çƒˆå˜åŒ–å¯¼è‡´æ¨¡å‹æ›´æ–°ä¸ç¨³å®š**ã€‚



### 4.3 Whatâ€™s the effect?

![image-20250621223814370](./OA.assets/image-20250621223814370.png)

The convergence speed in the x1-direction accelerates, but the x2-direction diverges completely, and the training is unstable.
 â†’ xâ‚æ–¹å‘æ”¶æ•›é€Ÿåº¦åŠ å¿«ï¼Œä½†xâ‚‚æ–¹å‘å®Œå…¨å‘æ•£ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸ç¨³å®šã€‚

The gradient change in the x2-direction is stable, but the convergence in the x1-direction is very slow.
 â†’ xâ‚‚æ–¹å‘çš„æ¢¯åº¦å˜åŒ–ç¨³å®šï¼Œä½†xâ‚æ–¹å‘çš„æ”¶æ•›é€Ÿåº¦éå¸¸æ…¢ã€‚

Such an objective function will lead to difficulties in selecting the learning rate, making it difficult to balance the convergence speed and stability in two different dimensions.
 â†’ è¿™ç§ç›®æ ‡å‡½æ•°ä¼šå¯¼è‡´å­¦ä¹ ç‡éš¾ä»¥é€‰æ‹©ï¼Œéš¾ä»¥åœ¨ä¸¤ä¸ªä¸åŒç»´åº¦é—´å¹³è¡¡æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§ã€‚

Look at the bright red line.
 â†’ çœ‹é‚£æ¡äº®çº¢è‰²çš„çº¿ã€‚

Compared with the case before the momentum method was added, **its slope is smaller**, it **tends more toward the general direction of convergence**.
 â†’ ä¸æ·»åŠ åŠ¨é‡æ³•ä¹‹å‰çš„æƒ…å†µç›¸æ¯”ï¼Œè¿™æ¡çº¿çš„æ–œç‡æ›´å°ï¼Œæ›´è¶‹å‘äºæ”¶æ•›çš„å¤§è‡´æ–¹å‘ã€‚

Finally, the overall convergence effect is also very good, very close to the (0, 0) point.
 â†’ æœ€ç»ˆæ•´ä½“æ”¶æ•›æ•ˆæœä¹Ÿéå¸¸å¥½ï¼Œè·ç¦» (0, 0) ç‚¹éå¸¸æ¥è¿‘ã€‚

This is because it **calculates the average gradient over the past**.
 â†’ è¿™æ˜¯å› ä¸ºå®ƒè®¡ç®—äº†è¿‡å»çš„å¹³å‡æ¢¯åº¦ã€‚

Specifically, **the conflicts in the green and purple directions over the past two steps are neutralized and offset**.
 â†’ å…·ä½“æ¥è¯´ï¼Œå‰ä¸¤æ­¥ä¸­ç»¿è‰²å’Œç´«è‰²æ–¹å‘ä¸Šçš„å†²çªè¢«ä¸­å’Œå¹¶æŠµæ¶ˆäº†ã€‚

- When the beta value is increased to 0.25, we find that convergence is not achieved in the end.
     â†’ å½“ Î² å€¼å¢åŠ åˆ° 0.25 æ—¶ï¼Œæˆ‘ä»¬å‘ç°æœ€ç»ˆæ²¡æœ‰æ”¶æ•›ã€‚
- However, when we compare it with where no momentum is applied and the learning rate is equally 0.6, we can see that the divergence situation is much improved.
     â†’ ç„¶è€Œï¼Œä¸æœªä½¿ç”¨åŠ¨é‡ã€å­¦ä¹ ç‡åŒæ ·ä¸º 0.6 çš„æƒ…å†µç›¸æ¯”ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°**å‘æ•£æƒ…å†µæœ‰äº†æ˜æ˜¾æ”¹å–„**ã€‚



| ç»´åº¦           | GANï¼ˆç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼‰             | CNNï¼ˆå·ç§¯ç¥ç»ç½‘ç»œï¼‰                  | LSTMï¼ˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼‰               | Transformerï¼ˆå˜æ¢å™¨ï¼‰              |
| -------------- | ------------------------------- | ------------------------------------ | ------------------------------------ | ---------------------------------- |
| **æ ¸å¿ƒç›®æ ‡**   | ç”Ÿæˆé€¼çœŸçš„æ•°æ®                  | æå–ç©ºé—´ç‰¹å¾ï¼ˆå¦‚å›¾åƒã€è§†é¢‘ï¼‰         | æ•æ‰æ—¶é—´åºåˆ—ä¾èµ–å…³ç³»ï¼ˆå¦‚æ–‡æœ¬ã€è¯­éŸ³ï¼‰ | å»ºæ¨¡é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼ˆå¹¶è¡Œå¤„ç†åºåˆ—ï¼‰ |
| **ç½‘ç»œç»“æ„**   | åŒç½‘ç»œå¯¹æŠ—ç»“æ„ï¼ˆç”Ÿæˆå™¨+åˆ¤åˆ«å™¨ï¼‰ | å·ç§¯å±‚ + æ± åŒ–å±‚ + å…¨è¿æ¥å±‚           | é—¨æ§ç»“æ„ï¼ˆè¾“å…¥é—¨ã€é—å¿˜é—¨ã€è¾“å‡ºé—¨ï¼‰   | è‡ªæ³¨æ„åŠ›æœºåˆ¶ + ä½ç½®ç¼–ç  + å‰é¦ˆç½‘ç»œ |
| **å…¸å‹é—®é¢˜**   | è®­ç»ƒä¸ç¨³å®š                      | åªèƒ½æå–å±€éƒ¨ç‰¹å¾                     | æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸                        | è®¡ç®—èµ„æºæ¶ˆè€—å¤§                     |
| **ä»£è¡¨åº”ç”¨**   | äººè„¸ç”Ÿæˆã€Deepfake              | ResNet å›¾åƒåˆ†ç±»ã€YOLO ç›®æ ‡æ£€æµ‹       | è¯­éŸ³è½¬æ–‡å­—ï¼ˆå¦‚ Siriï¼‰ã€è‚¡ä»·é¢„æµ‹      | ChatGPTã€ViT å›¾åƒåˆ†ç±»              |
| **æŠ€æœ¯å…³è”æ€§** | ç”Ÿæˆå™¨å¸¸ç”¨ CNN æˆ– Transformer   | å¸¸ä½œä¸º LSTM/Transformer çš„ç‰¹å¾æå–å™¨ | åœ¨é•¿åºåˆ—ä»»åŠ¡ä¸­è¢« Transformer æ›¿ä»£    | å·²æ›¿ä»£ LSTM æˆä¸º NLP ä¸»æµ          |

![image-20250625191530786](./OA.assets/image-20250625191530786.png)
