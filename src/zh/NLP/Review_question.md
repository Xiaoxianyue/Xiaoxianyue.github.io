---
title: å¤ä¹ é—®é¢˜
icon: alias
date: 2025-6-22 12:22:43
author: XiaoXianYue
isOriginal: true
category: 
    - å¤§ä¸‰ä¸‹
    - NLP
tag:
    - å¤§ä¸‰ä¸‹
    - NLP
sticky: false
star: false
article: true
timeline: true
image: false
navbar: true
sidebarIcon: true
headerDepth: 5
lastUpdated: true
editLink: false
backToTop: true
toc: true
---

## Introduction

### Q1

> The developmental history of natural language processing technologies ï¼ˆFocus on mastering the three major tasks of natural language processing, as well as the earliest natural language processing task.**ï¼‰**

- Rule-based (symbolic) approach
- Statistical approach (traditional machine learning)
- Connectionist approach
- Pre-Training

major tasks:

- Computational Linguistic Tasks
- Information Extraction Tasks
- Natural Language Generation

the earliest natural language processing taskï¼š

- Machine Translation

### Q2

> Various levels of linguistic analysis

| å±‚çº§                    | å†…å®¹                           |
| ----------------------- | ------------------------------ |
| **éŸ³ç³»å­¦ (Phonology)**  | å£°éŸ³ç³»ç»Ÿçš„ç»“æž„åˆ†æž             |
| **å½¢æ€å­¦ (Morphology)** | è¯çš„å†…éƒ¨ç»“æž„ï¼Œå¦‚è¯ç¼€ã€è¯æ ¹ç­‰   |
| **å¥æ³•å­¦ (Syntax)**     | åˆ†æžè¯çš„ç»“æž„ä¸Žå¥æ³•è§„åˆ™ï¼ŒåŒ…å«ï¼š |

åˆ†è¯ï¼ˆTokenizationï¼‰

è¯æ€§æ ‡æ³¨ï¼ˆPOS Taggingï¼‰

æˆåˆ†å¥æ³•åˆ†æžï¼ˆConstituent Parsingï¼‰

ä¾å­˜å¥æ³•åˆ†æžï¼ˆDependency Parsingï¼‰ 

- **è¯­ä¹‰å­¦ (Semantics)**  ç†è§£è¯ä¸Žå¥å­çš„æ„ä¹‰ï¼Œå¦‚ï¼š

    - è¯­ä¹‰è§’è‰²æ ‡æ³¨

    - æŒ‡ä»£æ¶ˆè§£

    - æ–‡æœ¬è•´å«ï¼ˆTextual Entailmentï¼‰ 

-  **è¯­ç”¨å­¦ (Pragmatics)** ä¸Šä¸‹æ–‡å’Œæ„å›¾ç†è§£
     **ç¯‡ç« åˆ†æž (Discourse)** å¤šå¥ä¹‹é—´çš„ç»“æž„å…³ç³»ï¼Œå¦‚ï¼š

    - ç¯‡ç« åˆ†æ®µ

    - ç¯‡ç« è¿žè´¯æ€§åˆ†æžï¼ˆRhetorical Structure Theoryï¼‰ |

### Q3

> Current research status and related applications of natural language processing

è‡ªç„¶è¯­è¨€å¤„ç†çš„ç ”ç©¶çŽ°çŠ¶åŠç›¸å…³åº”ç”¨

![image-20250622191618177](./Review_question.assets/image-20250622191618177.png)

![image-20250622191642744](./Review_question.assets/image-20250622191642744.png)

![image-20250622191656878](./Review_question.assets/image-20250622191656878.png)

## 2. Formal Languages and Automata

Key examination content, focusing on formal grammars and automata. Key focus on relevant calculations and derivations.

è€ƒè¯•å†…å®¹é‡ç‚¹ï¼šå½¢å¼è¯­æ³•å’Œè‡ªåŠ¨æœºã€‚é‡ç‚¹å…³æ³¨ç›¸å…³è®¡ç®—å’ŒæŽ¨å¯¼ã€‚

### é¢˜ç›®

#### Q1

> Definition and types of formal grammars (key examination content)

![image-20250622123746772](./Review_question.assets/image-20250622123746772.png)

![image-20250622123815494](./Review_question.assets/image-20250622123815494.png)

![image-20250622123823003](./Review_question.assets/image-20250622123823003.png)

![image-20250622123829053](./Review_question.assets/image-20250622123829053.png)

![image-20250622123834145](./Review_question.assets/image-20250622123834145.png)

#### Q2

> Relationship between regular grammars and automata (key examination content)

![image-20250622123916986](./Review_question.assets/image-20250622123916986.png)

![image-20250622123936839](./Review_question.assets/image-20250622123936839.png)

![image-20250622123945600](./Review_question.assets/image-20250622123945600.png)

![image-20250622124228480](./Review_question.assets/image-20250622124228480.png)



### é‡ç‚¹

- æœ€å·¦æŽ¨å¯¼æœ€å³æŽ¨å¯¼
- CFGçš„å®šä¹‰ï¼ˆä¸Šé¢æœ‰ï¼‰
- CSGçš„å®šä¹‰
- Ambiguity of Context-Free Grammars A grammar G is said to be ambiguous if there exists at least one sentence that corresponds to more than one parse tree. Draw the derivation tree of phrases and sentences.
    - ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•çš„æ­§ä¹‰æ€§ï¼šå¦‚æžœæ–‡æ³•Gä¸­è‡³å°‘æœ‰ä¸€ä¸ªå¥å­å¯¹åº”å¤šæ£µè§£æžæ ‘ï¼Œåˆ™ç§°è¯¥æ–‡æ³•ä¸ºæ­§ä¹‰æ–‡æ³•ã€‚è¯·ç”»å‡ºçŸ­è¯­å’Œå¥å­çš„æ´¾ç”Ÿæ ‘ã€‚

- æ­£åˆ™æ–‡æ³•æž„å»ºè‡ªåŠ¨æœº



## Language model

### Q1

> N-gram models (key examination contentï¼ŒKey focus on probability calculations utilizing 2-gram and 3-gram modelsï¼‰

N-gram æ¨¡åž‹ï¼ˆé‡ç‚¹è€ƒè¯•å†…å®¹ï¼Œé‡ç‚¹å…³æ³¨åˆ©ç”¨ 2-gram å’Œ 3-gram æ¨¡åž‹è¿›è¡Œçš„æ¦‚çŽ‡è®¡ç®—ï¼‰

![image-20250622125908783](./Review_question.assets/image-20250622125908783.png)

### Q2

> Performance evaluation of language models (key examination content, conceptual memorization

è¯­è¨€æ¨¡åž‹ç»©æ•ˆè¯„ä¼°ï¼ˆé‡ç‚¹è€ƒè¯•å†…å®¹ã€æ¦‚å¿µè®°å¿†ï¼‰

![image-20250622130301542](./Review_question.assets/image-20250622130301542.png)

![image-20250622130325680](./Review_question.assets/image-20250622130325680.png)

### Q3

> Data smoothing methods (focusing on major data smoothing calculations)

![image-20250622130641174](./Review_question.assets/image-20250622130641174.png)

### Q4

> Language model adaptation methods (for classroom explanation only)

è¯­è¨€æ¨¡åž‹è‡ªé€‚åº”æ–¹æ³•ï¼ˆä»…ä¾›è¯¾å ‚è®²è§£ï¼‰

## éšé©¬å°”ç§‘å¤«å’Œæ¡ä»¶éšæœºåœº

### é¢˜ç›®

#### Q1

> Basic methods of probabilistic graphical models (including Hidden Markov Models)

æ¦‚çŽ‡å›¾æ¨¡åž‹ï¼ˆåŒ…æ‹¬éšé©¬å°”å¯å¤«æ¨¡åž‹ï¼‰çš„åŸºæœ¬æ–¹æ³•

![image-20250622133119741](./Review_question.assets/image-20250622133119741.png)

#### Q2

> Conditional random field models (for theoretical comprehension only

![image-20250624121312718](./Review_question.assets/image-20250624121312718.png)



| é¡¹ç›®     | HMM                                         | CRF                                            |
| -------- | ------------------------------------------- | ---------------------------------------------- |
| æ¨¡åž‹å…³æ³¨ | æ¨¡æ‹Ÿçƒçš„ç”Ÿæˆè¿‡ç¨‹ï¼ˆçŠ¶æ€è½¬ç§» + ç”Ÿæˆè¾“å‡ºï¼‰     | ç»™å®šçƒçš„é¢œè‰²åºåˆ—ï¼Œåˆ¤æ–­è¢‹å­çš„é€‰æ‹©               |
| ç»“æž„     | ( p(x, y) = p(y)p(x                         | y) )                                           |
| ç‰¹å¾å»ºæ¨¡ | åªå…è®¸çŠ¶æ€ä¹‹é—´å’ŒçŠ¶æ€-è§‚æµ‹ä¹‹é—´çš„ç®€å•æ¦‚çŽ‡å…³ç³» | å…è®¸å®šä¹‰ä»»æ„ç‰¹å¾å‡½æ•°ï¼Œçµæ´»ç»„åˆåŽ†å²å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ |
| æŽ¨ç†æ–¹å¼ | ç”Ÿæˆæ¦‚çŽ‡æœ€å¤§è·¯å¾„                            | æ¡ä»¶æ¦‚çŽ‡æœ€å¤§è·¯å¾„                               |

### é‡ç‚¹

ðŸ”¹ Forward Algorithmï¼ˆå‰å‘ç®—æ³•ï¼‰

**å®šä¹‰ï¼š**
 å‰å‘ç®—æ³•æ˜¯**éšé©¬å°”å¯å¤«æ¨¡åž‹ï¼ˆHidden Markov Model, HMMï¼‰ä¸­çš„æ ¸å¿ƒç®—æ³•ä¹‹ä¸€ï¼Œä¸»è¦ç”¨äºŽè®¡ç®—ä¸€ä¸ªè§‚æµ‹åºåˆ—å‡ºçŽ°çš„æ¦‚çŽ‡**ã€‚

**ç®—æ³•æ­¥éª¤ï¼š**

1. **åˆå§‹åŒ–ï¼ˆInitializationï¼‰ï¼š**
     è®¡ç®—åˆå§‹æ—¶åˆ»æ¯ä¸ªéšè—çŠ¶æ€çš„å‰å‘æ¦‚çŽ‡ã€‚
2. **é€’æŽ¨ï¼ˆRecursionï¼‰ï¼š**
     å¯¹äºŽåŽç»­çš„æ¯ä¸ªæ—¶åˆ»ï¼Œé€’å½’åœ°è®¡ç®—æ¯ä¸ªéšè—çŠ¶æ€çš„å‰å‘æ¦‚çŽ‡ã€‚
3. **ç»ˆæ­¢ï¼ˆTerminationï¼‰ï¼š**
     æ‰€æœ‰å‰å‘æ¦‚çŽ‡çš„åŠ å’Œå³ä¸ºæ•´ä¸ªè§‚æµ‹åºåˆ—çš„æ€»æ¦‚çŽ‡ã€‚

------

ðŸ”¹ Backward Algorithmï¼ˆåŽå‘ç®—æ³•ï¼‰

**æ³¨æ„ï¼š**è¯¥æœ¯è¯­åœ¨ä¸¤ä¸ªä¸åŒé¢†åŸŸä¸­æœ‰ä¸åŒå«ä¹‰ï¼š

------

âœ… 1. åœ¨**ç¥žç»ç½‘ç»œ**ä¸­ï¼š

**Backpropagation Algorithmï¼ˆåå‘ä¼ æ’­ç®—æ³•ï¼‰ï¼š**

- æ˜¯ä¸€ç§è®¡ç®—æŸå¤±å‡½æ•°å…³äºŽç¥žç»ç½‘ç»œå‚æ•°çš„**æ¢¯åº¦**çš„ç®—æ³•ã€‚
- å®ƒåŸºäºŽé“¾å¼æ³•åˆ™ï¼Œä»Žè¾“å‡ºå±‚å¼€å§‹**é€å±‚å‘åŽè®¡ç®—æ¢¯åº¦**ï¼Œä»Žè€Œä¼˜åŒ–æ¨¡åž‹å‚æ•°ã€‚
- è¿™æ˜¯æ·±åº¦å­¦ä¹ ä¸­æœ€æ ¸å¿ƒçš„æŠ€æœ¯ä¹‹ä¸€ï¼Œå¹¿æ³›ç”¨äºŽå„ç§ç¥žç»ç½‘ç»œçš„è®­ç»ƒä¸­ã€‚

------

âœ… 2. åœ¨**æ¦‚çŽ‡å›¾æ¨¡åž‹ / HMM** ä¸­ï¼š

**Backward Algorithmï¼ˆåŽå‘ç®—æ³•ï¼‰ï¼š**

- æ˜¯éšé©¬å°”å¯å¤«æ¨¡åž‹ä¸­çš„**åŠ¨æ€è§„åˆ’ç®—æ³•**ï¼Œç”¨äºŽ**è®¡ç®—ç»™å®šè§‚æµ‹åºåˆ—çš„æ¡ä»¶ä¸‹ï¼ŒæŸä¸€æ—¶åˆ»å¤„äºŽç‰¹å®šéšè—çŠ¶æ€çš„æ¦‚çŽ‡**ã€‚
- é€šå¸¸ä¸Žå‰å‘ç®—æ³•ç»“åˆä½¿ç”¨ï¼Œèƒ½æœ‰æ•ˆæ±‚è§£ HMM ä¸­çš„å¤šä¸ªæ¦‚çŽ‡è®¡ç®—ä»»åŠ¡ï¼ŒåŒ…æ‹¬ï¼š
    - åºåˆ—æ¦‚çŽ‡è¯„ä¼°
    - æœ€ä¼˜çŠ¶æ€è·¯å¾„è§£ç 
    - æ¨¡åž‹å‚æ•°å­¦ä¹ 



## Automatic Word Segmentation, Named Entity Recognition, and Part-of-Speech Tagging

æ¦‚å¿µè®°å¿†ã€‚é‡ç‚¹æŽ¢è®¨ä¸­æ–‡åˆ†è¯å’Œå‘½åå®žä½“è¯†åˆ«ç­‰æ¦‚å¿µã€å®ƒä»¬çš„ä»»åŠ¡ä»¥åŠä¸»è¦çš„ç ”ç©¶æŒ‘æˆ˜ã€‚

### Q1

==Automatic word segmentation, named entity recognition, and part-of-speech tagging==. These tasks form the foundation of text processing and language understanding, with wide applications in machine translation, information retrieval, question-answering systems, and other scenarios.

è‡ªç„¶è¯­è¨€å¤„ç† (NLP) é¢†åŸŸçš„ä¸‰å¤§å…³é”®ä»»åŠ¡ï¼šè‡ªåŠ¨åˆ†è¯ã€å‘½åå®žä½“è¯†åˆ«å’Œè¯æ€§æ ‡æ³¨ã€‚è¿™äº›ä»»åŠ¡æž„æˆäº†æ–‡æœ¬å¤„ç†å’Œè¯­è¨€ç†è§£çš„åŸºç¡€ï¼Œå¹¿æ³›åº”ç”¨äºŽæœºå™¨ç¿»è¯‘ã€ä¿¡æ¯æ£€ç´¢ã€é—®ç­”ç³»ç»Ÿç­‰åœºæ™¯ã€‚

> Fundamental issues in Chinese automatic word segmentation

1. Word standardization Problem: Key issue: Whatâ€™s a â€œwordâ€?
    - Morphemes or phrases
2. Recognition of Unknown words
3. Ambiguity in Segmentation:
    - Overlapping ambiguity
    - Combination ambiguity

Automatic word segmentation refers to the process of ==dividing continuous character sequences into meaningful word units==, which is particularly ==crucial for languages like Chinese that lack clear word boundaries==. For example, segmenting "æˆ‘å–œæ¬¢å­¦ä¹ " into "æˆ‘/å–œæ¬¢/å­¦ä¹ â€œ

è‡ªåŠ¨åˆ†è¯æ˜¯æŒ‡å°†è¿žç»­çš„å­—ç¬¦åºåˆ—åˆ’åˆ†æˆæœ‰æ„ä¹‰çš„è¯å•å…ƒçš„è¿‡ç¨‹ï¼Œè¿™å¯¹äºŽåƒä¸­æ–‡è¿™æ ·ç¼ºä¹æ˜Žç¡®è¯æ±‡ç•Œé™çš„è¯­è¨€å°¤ä¸ºé‡è¦ã€‚ä¾‹å¦‚ï¼Œå°†â€œæˆ‘å–œæ¬¢å­¦ä¹ â€åˆ†å‰²æˆâ€œæˆ‘/å–œæ¬¢/å­¦ä¹ â€

Automatic word segmentation: This is a crucial step in natural language processing for dividing unsegmented text into independent word units. It is particularly important for languages like Chinese where words aren't separated by spaces.

è‡ªåŠ¨åˆ†è¯ï¼šè¿™æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å…³é”®æ­¥éª¤ï¼Œç”¨äºŽå°†æœªåˆ†æ®µçš„æ–‡æœ¬åˆ’åˆ†ä¸ºç‹¬ç«‹çš„è¯å•å…ƒã€‚å¯¹äºŽåƒä¸­æ–‡è¿™æ ·è¯ä¸Žè¯ä¹‹é—´ä¸å¸¦ç©ºæ ¼åˆ†éš”çš„è¯­è¨€æ¥è¯´ï¼Œè¿™ä¸€ç‚¹å°¤ä¸ºé‡è¦ã€‚



>  Methods for Chinese word segmentation

1. æœ€å¤§åŒ¹é…æ³•ï¼ˆMaximum Matchingï¼Œ MMï¼‰
2. æœ€å°‘åˆ†è¯æ³•ï¼ˆæœ€çŸ­è·¯å¾„æ³•ï¼‰ï¼ˆShort Path Methodï¼‰
3. åŸºäºŽè¯­è¨€æ¨¡åž‹çš„åˆ†è¯æ–¹æ³•ï¼ˆLanguage Model-based Word Segmentationï¼‰
4. åŸºäºŽéšé©¬å°”ç§‘å¤«æ¨¡åž‹çš„åˆ†è¯æ–¹æ³•ï¼ˆHidden Markov model-based word segmentationï¼‰
5.  ç”±å­—æž„è¯ï¼ˆåŸºäºŽå­—æ ‡æ³¨ï¼‰çš„åˆ†è¯æ–¹æ³•ï¼ˆCharacter-based Tagging Method)
6. ç”Ÿæˆå¼æ–¹æ³•å’ŒåŒºåˆ†å¼æ–¹æ³•çš„ç»“åˆï¼ˆCombination of Generative and Discriminative Modelï¼‰

> Named entity recognition

1. å…³äºŽä¸­å›½å§“åï¼š
    - å§“ååº“åŒ¹é…
    - è®¡ç®—æ½œåœ¨å§“åçš„æ¦‚çŽ‡ä¼°å€¼
2. åœ°åï¼š
    - å»ºç«‹åœ°åèµ„æºçŸ¥è¯†åº“
    - å»ºç«‹è¯†åˆ«è§„åˆ™åº“
    - **ç»Ÿè®¡æ¨¡åž‹** 
    -  **é€šè¿‡è®­ç»ƒè¯­æ–™é€‰å–é˜ˆå€¼** 
    -  **åœ°ååˆç­›é€‰** 
    -  **å¯»æ‰¾å¯ä»¥åˆ©ç”¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯** 
    -  **åˆ©ç”¨è§„åˆ™è¿›ä¸€æ­¥ç¡®å®šåœ°å**

==Named entity recognition aims to identify specific types of entity names from text, such as person names, location names, and organization names==. For instance, identifying " æŽ åŽ " as a person name and "åŒ—äº¬" as a location name from the sentence "æŽåŽåœ¨åŒ—äº¬ å·¥ä½œ".

å‘½åå®žä½“è¯†åˆ«æ—¨åœ¨ä»Žæ–‡æœ¬ä¸­è¯†åˆ«ç‰¹å®šç±»åž‹çš„å®žä½“åç§°ï¼Œä¾‹å¦‚äººåã€åœ°åã€æœºæž„åç§°ç­‰ã€‚ä¾‹å¦‚ï¼Œä»Žâ€œæŽåŽåœ¨åŒ—äº¬å·¥ä½œâ€è¿™å¥è¯ä¸­è¯†åˆ«å‡ºâ€œæŽåŽâ€ä¸ºäººåï¼Œè¯†åˆ«å‡ºâ€œåŒ—äº¬â€ä¸ºåœ°åã€‚

Named entity recognition: Abbreviated as NER (Named Entity Recognition), it's a subtask of information extraction that identifies specific meaningful entities in text, such as person names, locations, organizations, dates, etc. It plays a key role in many applications like search engine optimization and knowledge graph construction.

å‘½åå®žä½“è¯†åˆ«ï¼šç®€ç§°NERï¼ˆNamed Entity Recognitionï¼‰ï¼Œå®ƒæ˜¯ä¿¡æ¯æå–çš„ä¸€ä¸ªå­ä»»åŠ¡ï¼Œç”¨äºŽè¯†åˆ«æ–‡æœ¬ä¸­ç‰¹å®šçš„ã€æœ‰æ„ä¹‰çš„å®žä½“ï¼Œä¾‹å¦‚äººåã€åœ°ç‚¹ã€ç»„ç»‡ã€æ—¥æœŸç­‰ã€‚å®ƒåœ¨æœç´¢å¼•æ“Žä¼˜åŒ–å’ŒçŸ¥è¯†å›¾è°±æž„å»ºç­‰è®¸å¤šåº”ç”¨ä¸­å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚

> Part-of-speech tagging

==Part-of-speech tagging involves assigning grammatical attributes (such as noun, verb, adjective, etc.) to each word==. For example, in the sentence "çŒ«æ‰äº†è€é¼ ","çŒ«" is tagged as a noun and "æ‰" as a verb. ==These three tasks collectively constitute fundamental modules of
language processing, enabling computers to better understand and process human language==.

è¯æ€§æ ‡æ³¨æ˜¯æŒ‡ä¸ºæ¯ä¸ªè¯åˆ†é…è¯­æ³•å±žæ€§ï¼ˆä¾‹å¦‚åè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ç­‰ï¼‰ã€‚ä¾‹å¦‚ï¼Œåœ¨â€œçŒ«æ‰äº†è€é¼ â€è¿™å¥è¯ä¸­ï¼Œâ€œçŒ«â€è¢«æ ‡æ³¨ä¸ºåè¯ï¼Œâ€œæ‰â€è¢«æ ‡æ³¨ä¸ºåŠ¨è¯ã€‚**è¿™ä¸‰ä¸ªä»»åŠ¡å…±åŒæž„æˆäº†è¯­è¨€å¤„ç†çš„åŸºæœ¬æ¨¡å—ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œå¤„ç†äººç±»è¯­è¨€ã€‚**

Part-of-speech tagging: This fundamental NLP task involves assigning a part-of-speech label (e.g., noun, verb, adjective) to each word in a sentence. It provides essential grammatical information for subsequent syntactic analysis and semantic understanding.

è¯æ€§æ ‡æ³¨ï¼šè¿™é¡¹åŸºç¡€çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡æ¶‰åŠä¸ºå¥å­ä¸­çš„æ¯ä¸ªå•è¯åˆ†é…è¯æ€§æ ‡ç­¾ï¼ˆä¾‹å¦‚ï¼Œåè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ï¼‰ã€‚å®ƒä¸ºåŽç»­çš„å¥æ³•åˆ†æžå’Œè¯­ä¹‰ç†è§£æä¾›å¿…è¦çš„è¯­æ³•ä¿¡æ¯ã€‚



## Syntactic Parsing

> æ³¨é‡æ¦‚å¿µè®°å¿†ä¸Žç†è§£ï¼Œä¸è¦æ±‚ç®—æ³•è®¡ç®—ã€‚é‡ç‚¹è€ƒæŸ¥å¥æ³•ç»“æž„åˆ†æžåº”ç”¨çš„æ¦‚å¿µã€ä»»åŠ¡å’Œä¸»è¦æ¦‚æ‹¬å†…å®¹ã€‚

![image-20250623011126090](./Review_question.assets/image-20250623011126090.png)

### Q1

> Basic parsing methods based on PCFG

**Probabilistic Context-Free Grammar æ¦‚çŽ‡ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•**

![image-20250622164217188](./Review_question.assets/image-20250622164217188.png)

### Q2

> Lexicalized phrase structure parser

è¿™ä¿©æ˜¯æ–¹æ³•



### Q3

> Unlexicalized syntactic parsers





## Semantic Analysis

> **Supervised word sense disambiguation methods**

![image-20250622172555655](./Review_question.assets/image-20250622172555655.png)

> **Dictionary-based semantic disambiguation methods**

- åŸºäºŽè¯­ä¹‰å®šä¹‰çš„æ¶ˆæ­§
- åŸºäºŽä¹‰ç±»è¾žå…¸ (thesaurus) çš„æ¶ˆæ­§
- åŸºäºŽåŒè¯­è¯å…¸çš„æ¶ˆæ­§
- Yarowsky æ¶ˆæ­§ç®—æ³•

> **Unsupervised word sense disambiguation methods**

![image-20250622172723224](./Review_question.assets/image-20250622172723224.png)

