import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,b as l,o as p}from"./app-COYsNQIt.js";const o="/assets/image-20250320005059601-B_YTEezA.png",e="/assets/image-20250320005023673-B66Tf6Qe.png",F={};function c(t,s){return p(),a("div",null,s[0]||(s[0]=[l(`<h3 id="task-01" tabindex="-1"><a class="header-anchor" href="#task-01"><span>Task 01</span></a></h3><blockquote><p>替换平均池化（AvgPool）为最大池化（MaxPool），并输出结果。</p></blockquote><h4 id="代码" tabindex="-1"><a class="header-anchor" href="#代码"><span>代码</span></a></h4><div class="language-python line-numbers-mode has-collapsed-lines collapsed" data-highlighter="shiki" data-ext="python" style="--vp-collapsed-lines:15;background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torch</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torch.nn </span><span style="color:#F92672;">as</span><span style="color:#F8F8F2;"> nn</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torch.optim </span><span style="color:#F92672;">as</span><span style="color:#F8F8F2;"> optim</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torchvision</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torchvision.transforms </span><span style="color:#F92672;">as</span><span style="color:#F8F8F2;"> transforms</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 1. 定义 LeNet 网络 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">class</span><span> </span><span style="color:#A6E22E;text-decoration:underline;">LeNet</span><span style="color:#F8F8F2;">(</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline;">nn</span><span style="color:#F8F8F2;">.</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline;">Module</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">    def</span><span style="color:#66D9EF;"> __init__</span><span style="color:#F8F8F2;">(</span><span style="color:#FD971F;font-style:italic;">self</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">use_maxpool</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">        super</span><span style="color:#F8F8F2;">(LeNet, </span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">).</span><span style="color:#66D9EF;">__init__</span><span style="color:#F8F8F2;">()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;">        # 卷积层</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.conv1 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Conv2d(</span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">6</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">padding</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">)  </span><span style="color:#88846F;"># 28x28 -&gt; 28x28</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.conv2 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Conv2d(</span><span style="color:#AE81FF;">6</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">16</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">)  </span><span style="color:#88846F;"># 14x14 -&gt; 10x10</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;">        # 选择池化方式（默认使用 MaxPool）</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.pool </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.MaxPool2d(</span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">stride</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">) </span><span style="color:#F92672;">if</span><span style="color:#F8F8F2;"> use_maxpool </span><span style="color:#F92672;">else</span><span style="color:#F8F8F2;"> nn.AvgPool2d(</span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">stride</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;">        # 全连接层</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.fc1 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Linear(</span><span style="color:#AE81FF;">16</span><span style="color:#F92672;"> *</span><span style="color:#AE81FF;"> 5</span><span style="color:#F92672;"> *</span><span style="color:#AE81FF;"> 5</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">120</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.fc2 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Linear(</span><span style="color:#AE81FF;">120</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">84</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.fc3 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Linear(</span><span style="color:#AE81FF;">84</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">10</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">    def</span><span style="color:#A6E22E;"> forward</span><span style="color:#F8F8F2;">(</span><span style="color:#FD971F;font-style:italic;">self</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">x</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#FD971F;"> self</span><span style="color:#F8F8F2;">.pool(torch.relu(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.conv1(x)))  </span><span style="color:#88846F;"># 第一层卷积 + ReLU + 池化</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#FD971F;"> self</span><span style="color:#F8F8F2;">.pool(torch.relu(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.conv2(x)))  </span><span style="color:#88846F;"># 第二层卷积 + ReLU + 池化</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.flatten(x, </span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">)  </span><span style="color:#88846F;"># 展平</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.relu(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.fc1(x))</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.relu(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.fc2(x))</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#FD971F;"> self</span><span style="color:#F8F8F2;">.fc3(x)  </span><span style="color:#88846F;"># 最终输出 10 维</span></span>
<span class="line"><span style="color:#F92672;">        return</span><span style="color:#F8F8F2;"> x</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 2. 载入 MNIST 数据集 ---------------------</span></span>
<span class="line"><span style="color:#F8F8F2;">mnist_data_path </span><span style="color:#F92672;">=</span><span style="color:#E6DB74;"> &quot;D:/603/pythonProject/data/MNIST/&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">transform </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> transforms.Compose([</span></span>
<span class="line"><span style="color:#F8F8F2;">    transforms.Grayscale(),</span></span>
<span class="line"><span style="color:#F8F8F2;">    transforms.ToTensor(),</span></span>
<span class="line"><span style="color:#F8F8F2;">    transforms.Normalize((</span><span style="color:#AE81FF;">0.5</span><span style="color:#F8F8F2;">,), (</span><span style="color:#AE81FF;">0.5</span><span style="color:#F8F8F2;">,))  </span><span style="color:#88846F;"># 归一化到 [-1, 1]</span></span>
<span class="line"><span style="color:#F8F8F2;">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># 加载训练和测试数据</span></span>
<span class="line"><span style="color:#F8F8F2;">trainset </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torchvision.datasets.MNIST(</span><span style="color:#FD971F;font-style:italic;">root</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">mnist_data_path, </span><span style="color:#FD971F;font-style:italic;">train</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">download</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">False</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">transform</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">transform)</span></span>
<span class="line"><span style="color:#F8F8F2;">testset </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torchvision.datasets.MNIST(</span><span style="color:#FD971F;font-style:italic;">root</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">mnist_data_path, </span><span style="color:#FD971F;font-style:italic;">train</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">False</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">download</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">False</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">transform</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">transform)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">train_loader </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.utils.data.DataLoader(trainset, </span><span style="color:#FD971F;font-style:italic;">batch_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">64</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">shuffle</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">test_loader </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.utils.data.DataLoader(testset, </span><span style="color:#FD971F;font-style:italic;">batch_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">64</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">shuffle</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">False</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 3. 训练模型 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">def</span><span style="color:#A6E22E;"> train_model</span><span style="color:#F8F8F2;">(</span><span style="color:#FD971F;font-style:italic;">model</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">train_loader</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">epochs</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">learning_rate</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">0.001</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#F8F8F2;">    device </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.device(</span><span style="color:#E6DB74;">&quot;cuda&quot;</span><span style="color:#F92672;"> if</span><span style="color:#F8F8F2;"> torch.cuda.is_available() </span><span style="color:#F92672;">else</span><span style="color:#E6DB74;"> &quot;cpu&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">    model.to(device)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">    criterion </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.CrossEntropyLoss()</span></span>
<span class="line"><span style="color:#F8F8F2;">    optimizer </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> optim.Adam(model.parameters(), </span><span style="color:#FD971F;font-style:italic;">lr</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">learning_rate)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F92672;">    for</span><span style="color:#F8F8F2;"> epoch </span><span style="color:#F92672;">in</span><span style="color:#66D9EF;"> range</span><span style="color:#F8F8F2;">(epochs):</span></span>
<span class="line"><span style="color:#F8F8F2;">        model.train()</span></span>
<span class="line"><span style="color:#F8F8F2;">        running_loss </span><span style="color:#F92672;">=</span><span style="color:#AE81FF;"> 0.0</span></span>
<span class="line"><span style="color:#F92672;">        for</span><span style="color:#F8F8F2;"> images, labels </span><span style="color:#F92672;">in</span><span style="color:#F8F8F2;"> train_loader:</span></span>
<span class="line"><span style="color:#F8F8F2;">            images, labels </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> images.to(device), labels.to(device)</span></span>
<span class="line"><span style="color:#F8F8F2;">            optimizer.zero_grad()</span></span>
<span class="line"><span style="color:#F8F8F2;">            outputs </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> model(images)</span></span>
<span class="line"><span style="color:#F8F8F2;">            loss </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> criterion(outputs, labels)</span></span>
<span class="line"><span style="color:#F8F8F2;">            loss.backward()</span></span>
<span class="line"><span style="color:#F8F8F2;">            optimizer.step()</span></span>
<span class="line"><span style="color:#F8F8F2;">            running_loss </span><span style="color:#F92672;">+=</span><span style="color:#F8F8F2;"> loss.item()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF;">        print</span><span style="color:#F8F8F2;">(</span><span style="color:#66D9EF;font-style:italic;">f</span><span style="color:#E6DB74;">&quot;Epoch </span><span style="color:#AE81FF;">{</span><span style="color:#F8F8F2;">epoch </span><span style="color:#F92672;">+</span><span style="color:#AE81FF;"> 1}</span><span style="color:#E6DB74;">, Loss: </span><span style="color:#AE81FF;">{</span><span style="color:#F8F8F2;">running_loss </span><span style="color:#F92672;">/</span><span style="color:#66D9EF;"> len</span><span style="color:#F8F8F2;">(train_loader)</span><span style="color:#66D9EF;font-style:italic;">:.4f</span><span style="color:#AE81FF;">}</span><span style="color:#E6DB74;">&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 4. 评估模型 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">def</span><span style="color:#A6E22E;"> evaluate_model</span><span style="color:#F8F8F2;">(</span><span style="color:#FD971F;font-style:italic;">model</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">test_loader</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#F8F8F2;">    device </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.device(</span><span style="color:#E6DB74;">&quot;cuda&quot;</span><span style="color:#F92672;"> if</span><span style="color:#F8F8F2;"> torch.cuda.is_available() </span><span style="color:#F92672;">else</span><span style="color:#E6DB74;"> &quot;cpu&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">    model.to(device)</span></span>
<span class="line"><span style="color:#F8F8F2;">    model.eval()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">    correct, total </span><span style="color:#F92672;">=</span><span style="color:#AE81FF;"> 0</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">0</span></span>
<span class="line"><span style="color:#F92672;">    with</span><span style="color:#F8F8F2;"> torch.no_grad():</span></span>
<span class="line"><span style="color:#F92672;">        for</span><span style="color:#F8F8F2;"> images, labels </span><span style="color:#F92672;">in</span><span style="color:#F8F8F2;"> test_loader:</span></span>
<span class="line"><span style="color:#F8F8F2;">            images, labels </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> images.to(device), labels.to(device)</span></span>
<span class="line"><span style="color:#F8F8F2;">            outputs </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> model(images)</span></span>
<span class="line"><span style="color:#F8F8F2;">            _, predicted </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.max(outputs, </span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">            total </span><span style="color:#F92672;">+=</span><span style="color:#F8F8F2;"> labels.size(</span><span style="color:#AE81FF;">0</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">            correct </span><span style="color:#F92672;">+=</span><span style="color:#F8F8F2;"> (predicted </span><span style="color:#F92672;">==</span><span style="color:#F8F8F2;"> labels).sum().item()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF;">    print</span><span style="color:#F8F8F2;">(</span><span style="color:#66D9EF;font-style:italic;">f</span><span style="color:#E6DB74;">&quot;Test Accuracy: </span><span style="color:#AE81FF;">{100</span><span style="color:#F92672;"> *</span><span style="color:#F8F8F2;"> correct </span><span style="color:#F92672;">/</span><span style="color:#F8F8F2;"> total</span><span style="color:#66D9EF;font-style:italic;">:.2f</span><span style="color:#AE81FF;">}</span><span style="color:#E6DB74;">%&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 5. 运行实验 ---------------------</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># 训练并评估使用平均池化的 LeNet</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#E6DB74;">&quot;</span><span style="color:#AE81FF;">\\n</span><span style="color:#E6DB74;">Training LeNet with Average Pooling...&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">lenet_avg </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> LeNet(</span><span style="color:#FD971F;font-style:italic;">use_maxpool</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">False</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">train_model(lenet_avg, train_loader, </span><span style="color:#FD971F;font-style:italic;">epochs</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">learning_rate</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">0.001</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#E6DB74;">&quot;</span><span style="color:#AE81FF;">\\n</span><span style="color:#E6DB74;">Evaluating LeNet with Average Pooling...&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">evaluate_model(lenet_avg, test_loader)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># 训练并评估使用最大池化的 LeNet</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#E6DB74;">&quot;</span><span style="color:#AE81FF;">\\n</span><span style="color:#E6DB74;">Training LeNet with Max Pooling...&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">lenet_max </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> LeNet(</span><span style="color:#FD971F;font-style:italic;">use_maxpool</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">train_model(lenet_max, train_loader, </span><span style="color:#FD971F;font-style:italic;">epochs</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">learning_rate</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">0.001</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#E6DB74;">&quot;</span><span style="color:#AE81FF;">\\n</span><span style="color:#E6DB74;">Evaluating LeNet with Max Pooling...&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">evaluate_model(lenet_max, test_loader)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div><div class="collapsed-lines"></div></div><h4 id="运行结果" tabindex="-1"><a class="header-anchor" href="#运行结果"><span>运行结果</span></a></h4><div class="language-python line-numbers-mode has-collapsed-lines collapsed" data-highlighter="shiki" data-ext="python" style="--vp-collapsed-lines:15;background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#F8F8F2;">D:\\</span><span style="color:#F44747;">603\\pythonProject\\.venv\\Scripts\\python.exe D:\\603\\pythonProject\\.venv\\LeNet.py </span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">Training LeNet </span><span style="color:#F92672;">with</span><span style="color:#F8F8F2;"> Average Pooling</span><span style="color:#AE81FF;">...</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.2898</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0815</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">3</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0575</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">4</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0469</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0387</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">Evaluating LeNet </span><span style="color:#F92672;">with</span><span style="color:#F8F8F2;"> Average Pooling</span><span style="color:#AE81FF;">...</span></span>
<span class="line"><span style="color:#F8F8F2;">Test Accuracy: </span><span style="color:#AE81FF;">98.58</span><span style="color:#F92672;">%</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">Training LeNet </span><span style="color:#F92672;">with</span><span style="color:#F8F8F2;"> Max Pooling</span><span style="color:#AE81FF;">...</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.2749</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0715</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">3</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0515</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">4</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0398</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0324</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">Evaluating LeNet </span><span style="color:#F92672;">with</span><span style="color:#F8F8F2;"> Max Pooling</span><span style="color:#AE81FF;">...</span></span>
<span class="line"><span style="color:#F8F8F2;">Test Accuracy: </span><span style="color:#AE81FF;">98.77</span><span style="color:#F92672;">%</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">进程已结束，退出代码为 </span><span style="color:#AE81FF;">0</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div><div class="collapsed-lines"></div></div><p>最大池化确实比平均池化的正确率提高了一点点。</p><h3 id="task-02" tabindex="-1"><a class="header-anchor" href="#task-02"><span>Task 02</span></a></h3><blockquote><p>改变卷积窗口大小</p><p>修改输出通道数</p><p>更改激活函数（ReLU）</p><p>调整卷积层和全连接层的数量</p><p>修改学习率和训练轮数（epochs）</p></blockquote><h4 id="代码-1" tabindex="-1"><a class="header-anchor" href="#代码-1"><span>代码</span></a></h4><div class="language-python line-numbers-mode has-collapsed-lines collapsed" data-highlighter="shiki" data-ext="python" style="--vp-collapsed-lines:15;background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torch</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torch.nn </span><span style="color:#F92672;">as</span><span style="color:#F8F8F2;"> nn</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torch.optim </span><span style="color:#F92672;">as</span><span style="color:#F8F8F2;"> optim</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torchvision</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torchvision.transforms </span><span style="color:#F92672;">as</span><span style="color:#F8F8F2;"> transforms</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 1. 定义 LeNet 网络 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">class</span><span> </span><span style="color:#A6E22E;text-decoration:underline;">LeNet</span><span style="color:#F8F8F2;">(</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline;">nn</span><span style="color:#F8F8F2;">.</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline;">Module</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">    def</span><span style="color:#66D9EF;"> __init__</span><span style="color:#F8F8F2;">(</span><span style="color:#FD971F;font-style:italic;">self</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">use_maxpool</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">conv_channels</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">(</span><span style="color:#AE81FF;">6</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">16</span><span style="color:#F8F8F2;">), </span><span style="color:#FD971F;font-style:italic;">activation</span><span style="color:#F92672;">=</span><span style="color:#E6DB74;">&quot;relu&quot;</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">(</span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">), </span><span style="color:#FD971F;font-style:italic;">fc_sizes</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">(</span><span style="color:#AE81FF;">120</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">84</span><span style="color:#F8F8F2;">)):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">        super</span><span style="color:#F8F8F2;">(LeNet, </span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">).</span><span style="color:#66D9EF;">__init__</span><span style="color:#F8F8F2;">()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;">        # 选择激活函数</span></span>
<span class="line"><span style="color:#F92672;">        if</span><span style="color:#F8F8F2;"> activation </span><span style="color:#F92672;">==</span><span style="color:#E6DB74;"> &quot;relu&quot;</span><span style="color:#F8F8F2;">:</span></span>
<span class="line"><span style="color:#FD971F;">            self</span><span style="color:#F8F8F2;">.activation </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.ReLU()</span></span>
<span class="line"><span style="color:#F92672;">        elif</span><span style="color:#F8F8F2;"> activation </span><span style="color:#F92672;">==</span><span style="color:#E6DB74;"> &quot;sigmoid&quot;</span><span style="color:#F8F8F2;">:</span></span>
<span class="line"><span style="color:#FD971F;">            self</span><span style="color:#F8F8F2;">.activation </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Sigmoid()</span></span>
<span class="line"><span style="color:#F92672;">        else</span><span style="color:#F8F8F2;">:</span></span>
<span class="line"><span style="color:#FD971F;">            self</span><span style="color:#F8F8F2;">.activation </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Tanh()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;">        # 卷积层</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.conv1 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Conv2d(</span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">, conv_channels[</span><span style="color:#AE81FF;">0</span><span style="color:#F8F8F2;">], </span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">kernel_size[</span><span style="color:#AE81FF;">0</span><span style="color:#F8F8F2;">], </span><span style="color:#FD971F;font-style:italic;">padding</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">)  </span><span style="color:#88846F;"># 28x28 -&gt; 28x28</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.conv2 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Conv2d(conv_channels[</span><span style="color:#AE81FF;">0</span><span style="color:#F8F8F2;">], conv_channels[</span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">], </span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">kernel_size[</span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">])  </span><span style="color:#88846F;"># 14x14 -&gt; 10x10</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;">        # 选择池化方式（默认使用 MaxPool）</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.pool </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.MaxPool2d(</span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">stride</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">) </span><span style="color:#F92672;">if</span><span style="color:#F8F8F2;"> use_maxpool </span><span style="color:#F92672;">else</span><span style="color:#F8F8F2;"> nn.AvgPool2d(</span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">stride</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;">        # 计算展平后的特征图尺寸</span></span>
<span class="line"><span style="color:#F8F8F2;">        fc_input_size </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> conv_channels[</span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">] </span><span style="color:#F92672;">*</span><span style="color:#AE81FF;"> 5</span><span style="color:#F92672;"> *</span><span style="color:#AE81FF;"> 5</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;">        # 全连接层（可调整大小）</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.fc1 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Linear(fc_input_size, fc_sizes[</span><span style="color:#AE81FF;">0</span><span style="color:#F8F8F2;">])</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.fc2 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Linear(fc_sizes[</span><span style="color:#AE81FF;">0</span><span style="color:#F8F8F2;">], fc_sizes[</span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">])</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.fc3 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Linear(fc_sizes[</span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">], </span><span style="color:#AE81FF;">10</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">    def</span><span style="color:#A6E22E;"> forward</span><span style="color:#F8F8F2;">(</span><span style="color:#FD971F;font-style:italic;">self</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">x</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#FD971F;"> self</span><span style="color:#F8F8F2;">.pool(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.activation(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.conv1(x)))  </span><span style="color:#88846F;"># 第一层卷积 + 激活 + 池化</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#FD971F;"> self</span><span style="color:#F8F8F2;">.pool(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.activation(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.conv2(x)))  </span><span style="color:#88846F;"># 第二层卷积 + 激活 + 池化</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.flatten(x, </span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">)  </span><span style="color:#88846F;"># 展平</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#FD971F;"> self</span><span style="color:#F8F8F2;">.activation(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.fc1(x))</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#FD971F;"> self</span><span style="color:#F8F8F2;">.activation(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.fc2(x))</span></span>
<span class="line"><span style="color:#F8F8F2;">        x </span><span style="color:#F92672;">=</span><span style="color:#FD971F;"> self</span><span style="color:#F8F8F2;">.fc3(x)  </span><span style="color:#88846F;"># 最终输出 10 维</span></span>
<span class="line"><span style="color:#F92672;">        return</span><span style="color:#F8F8F2;"> x</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 2. 训练模型 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">def</span><span style="color:#A6E22E;"> train_model</span><span style="color:#F8F8F2;">(</span><span style="color:#FD971F;font-style:italic;">model</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">train_loader</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">test_loader</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">epochs</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">10</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">learning_rate</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">0.001</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#F8F8F2;">    device </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.device(</span><span style="color:#E6DB74;">&quot;cuda&quot;</span><span style="color:#F92672;"> if</span><span style="color:#F8F8F2;"> torch.cuda.is_available() </span><span style="color:#F92672;">else</span><span style="color:#E6DB74;"> &quot;cpu&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">    model.to(device)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">    criterion </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.CrossEntropyLoss()</span></span>
<span class="line"><span style="color:#F8F8F2;">    optimizer </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> optim.Adam(model.parameters(), </span><span style="color:#FD971F;font-style:italic;">lr</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">learning_rate)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F92672;">    for</span><span style="color:#F8F8F2;"> epoch </span><span style="color:#F92672;">in</span><span style="color:#66D9EF;"> range</span><span style="color:#F8F8F2;">(epochs):</span></span>
<span class="line"><span style="color:#F8F8F2;">        model.train()</span></span>
<span class="line"><span style="color:#F8F8F2;">        running_loss </span><span style="color:#F92672;">=</span><span style="color:#AE81FF;"> 0.0</span></span>
<span class="line"><span style="color:#F92672;">        for</span><span style="color:#F8F8F2;"> images, labels </span><span style="color:#F92672;">in</span><span style="color:#F8F8F2;"> train_loader:</span></span>
<span class="line"><span style="color:#F8F8F2;">            images, labels </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> images.to(device), labels.to(device)</span></span>
<span class="line"><span style="color:#F8F8F2;">            optimizer.zero_grad()</span></span>
<span class="line"><span style="color:#F8F8F2;">            outputs </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> model(images)</span></span>
<span class="line"><span style="color:#F8F8F2;">            loss </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> criterion(outputs, labels)</span></span>
<span class="line"><span style="color:#F8F8F2;">            loss.backward()</span></span>
<span class="line"><span style="color:#F8F8F2;">            optimizer.step()</span></span>
<span class="line"><span style="color:#F8F8F2;">            running_loss </span><span style="color:#F92672;">+=</span><span style="color:#F8F8F2;"> loss.item()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF;">        print</span><span style="color:#F8F8F2;">(</span><span style="color:#66D9EF;font-style:italic;">f</span><span style="color:#E6DB74;">&quot;Epoch </span><span style="color:#AE81FF;">{</span><span style="color:#F8F8F2;">epoch </span><span style="color:#F92672;">+</span><span style="color:#AE81FF;"> 1}</span><span style="color:#E6DB74;">, Loss: </span><span style="color:#AE81FF;">{</span><span style="color:#F8F8F2;">running_loss </span><span style="color:#F92672;">/</span><span style="color:#66D9EF;"> len</span><span style="color:#F8F8F2;">(train_loader)</span><span style="color:#66D9EF;font-style:italic;">:.4f</span><span style="color:#AE81FF;">}</span><span style="color:#E6DB74;">&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;">    # 测试准确率</span></span>
<span class="line"><span style="color:#F8F8F2;">    model.eval()</span></span>
<span class="line"><span style="color:#F8F8F2;">    correct </span><span style="color:#F92672;">=</span><span style="color:#AE81FF;"> 0</span></span>
<span class="line"><span style="color:#F8F8F2;">    total </span><span style="color:#F92672;">=</span><span style="color:#AE81FF;"> 0</span></span>
<span class="line"><span style="color:#F92672;">    with</span><span style="color:#F8F8F2;"> torch.no_grad():</span></span>
<span class="line"><span style="color:#F92672;">        for</span><span style="color:#F8F8F2;"> images, labels </span><span style="color:#F92672;">in</span><span style="color:#F8F8F2;"> test_loader:</span></span>
<span class="line"><span style="color:#F8F8F2;">            images, labels </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> images.to(device), labels.to(device)</span></span>
<span class="line"><span style="color:#F8F8F2;">            outputs </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> model(images)</span></span>
<span class="line"><span style="color:#F8F8F2;">            _, predicted </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.max(outputs, </span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">            total </span><span style="color:#F92672;">+=</span><span style="color:#F8F8F2;"> labels.size(</span><span style="color:#AE81FF;">0</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">            correct </span><span style="color:#F92672;">+=</span><span style="color:#F8F8F2;"> (predicted </span><span style="color:#F92672;">==</span><span style="color:#F8F8F2;"> labels).sum().item()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">    accuracy </span><span style="color:#F92672;">=</span><span style="color:#AE81FF;"> 100</span><span style="color:#F92672;"> *</span><span style="color:#F8F8F2;"> correct </span><span style="color:#F92672;">/</span><span style="color:#F8F8F2;"> total</span></span>
<span class="line"><span style="color:#66D9EF;">    print</span><span style="color:#F8F8F2;">(</span><span style="color:#66D9EF;font-style:italic;">f</span><span style="color:#E6DB74;">&quot;Test Accuracy: </span><span style="color:#AE81FF;">{</span><span style="color:#F8F8F2;">accuracy</span><span style="color:#66D9EF;font-style:italic;">:.2f</span><span style="color:#AE81FF;">}</span><span style="color:#E6DB74;">%&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F92672;">    return</span><span style="color:#F8F8F2;"> accuracy</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 3. 载入 MNIST 数据集 ---------------------</span></span>
<span class="line"><span style="color:#F8F8F2;">mnist_data_path </span><span style="color:#F92672;">=</span><span style="color:#E6DB74;"> &quot;D:/603/pythonProject/data/MNIST/&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">transform </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> transforms.Compose([</span></span>
<span class="line"><span style="color:#F8F8F2;">    transforms.Grayscale(),</span></span>
<span class="line"><span style="color:#F8F8F2;">    transforms.ToTensor(),</span></span>
<span class="line"><span style="color:#F8F8F2;">    transforms.Normalize((</span><span style="color:#AE81FF;">0.5</span><span style="color:#F8F8F2;">,), (</span><span style="color:#AE81FF;">0.5</span><span style="color:#F8F8F2;">,))</span></span>
<span class="line"><span style="color:#F8F8F2;">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># 加载训练和测试数据</span></span>
<span class="line"><span style="color:#F8F8F2;">trainset </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torchvision.datasets.MNIST(</span><span style="color:#FD971F;font-style:italic;">root</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">mnist_data_path, </span><span style="color:#FD971F;font-style:italic;">train</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">download</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">False</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">transform</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">transform)</span></span>
<span class="line"><span style="color:#F8F8F2;">testset </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torchvision.datasets.MNIST(</span><span style="color:#FD971F;font-style:italic;">root</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">mnist_data_path, </span><span style="color:#FD971F;font-style:italic;">train</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">False</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">download</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">False</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">transform</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">transform)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">train_loader </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.utils.data.DataLoader(trainset, </span><span style="color:#FD971F;font-style:italic;">batch_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">64</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">shuffle</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">test_loader </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.utils.data.DataLoader(testset, </span><span style="color:#FD971F;font-style:italic;">batch_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">64</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">shuffle</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">False</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 4. 运行实验（比较不同 LeNet 结构） ---------------------</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># 1. 标准 LeNet（最大池化，默认参数）</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#E6DB74;">&quot;</span><span style="color:#AE81FF;">\\n</span><span style="color:#E6DB74;">Training Standard LeNet...&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">standard_model </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> LeNet(</span><span style="color:#FD971F;font-style:italic;">use_maxpool</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">standard_acc </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> train_model(standard_model, train_loader, test_loader)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># 2. 更大的卷积通道数（8, 32）+ 不同卷积核大小（3, 5）</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#E6DB74;">&quot;</span><span style="color:#AE81FF;">\\n</span><span style="color:#E6DB74;">Training LeNet with Larger Convolution Channels and Different Kernel Sizes...&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">large_conv_model </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> LeNet(</span><span style="color:#FD971F;font-style:italic;">use_maxpool</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">conv_channels</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">(</span><span style="color:#AE81FF;">8</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">32</span><span style="color:#F8F8F2;">), </span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">(</span><span style="color:#AE81FF;">3</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">))</span></span>
<span class="line"><span style="color:#F8F8F2;">large_conv_acc </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> train_model(large_conv_model, train_loader, test_loader)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># 3. 使用 Sigmoid 代替 ReLU</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#E6DB74;">&quot;</span><span style="color:#AE81FF;">\\n</span><span style="color:#E6DB74;">Training LeNet with Sigmoid Activation...&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">sigmoid_model </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> LeNet(</span><span style="color:#FD971F;font-style:italic;">use_maxpool</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">activation</span><span style="color:#F92672;">=</span><span style="color:#E6DB74;">&quot;sigmoid&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">sigmoid_acc </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> train_model(sigmoid_model, train_loader, test_loader)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># 4. 修改全连接层尺寸（150, 100）</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#E6DB74;">&quot;</span><span style="color:#AE81FF;">\\n</span><span style="color:#E6DB74;">Training LeNet with Modified Fully Connected Layers...&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">fc_modified_model </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> LeNet(</span><span style="color:#FD971F;font-style:italic;">use_maxpool</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">fc_sizes</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">(</span><span style="color:#AE81FF;">150</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">100</span><span style="color:#F8F8F2;">))</span></span>
<span class="line"><span style="color:#F8F8F2;">fc_modified_acc </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> train_model(fc_modified_model, train_loader, test_loader)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># 5. 训练更长时间（20 epochs）+ 更大学习率（0.005）</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#E6DB74;">&quot;</span><span style="color:#AE81FF;">\\n</span><span style="color:#E6DB74;">Training LeNet with More Training Epochs and Higher Learning Rate...&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">long_training_model </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> LeNet(</span><span style="color:#FD971F;font-style:italic;">use_maxpool</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">True</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">long_training_acc </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> train_model(long_training_model, train_loader, test_loader, </span><span style="color:#FD971F;font-style:italic;">epochs</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">20</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">learning_rate</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">0.005</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 5. 结果比较 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#E6DB74;">&quot;</span><span style="color:#AE81FF;">\\n</span><span style="color:#E6DB74;">========== Model Comparison ==========&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#66D9EF;font-style:italic;">f</span><span style="color:#E6DB74;">&quot;Standard LeNet: </span><span style="color:#AE81FF;">{</span><span style="color:#F8F8F2;">standard_acc</span><span style="color:#66D9EF;font-style:italic;">:.2f</span><span style="color:#AE81FF;">}</span><span style="color:#E6DB74;">%&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#66D9EF;font-style:italic;">f</span><span style="color:#E6DB74;">&quot;Larger Conv Channels: </span><span style="color:#AE81FF;">{</span><span style="color:#F8F8F2;">large_conv_acc</span><span style="color:#66D9EF;font-style:italic;">:.2f</span><span style="color:#AE81FF;">}</span><span style="color:#E6DB74;">%&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#66D9EF;font-style:italic;">f</span><span style="color:#E6DB74;">&quot;Sigmoid Activation: </span><span style="color:#AE81FF;">{</span><span style="color:#F8F8F2;">sigmoid_acc</span><span style="color:#66D9EF;font-style:italic;">:.2f</span><span style="color:#AE81FF;">}</span><span style="color:#E6DB74;">%&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#66D9EF;font-style:italic;">f</span><span style="color:#E6DB74;">&quot;Modified FC Layers: </span><span style="color:#AE81FF;">{</span><span style="color:#F8F8F2;">fc_modified_acc</span><span style="color:#66D9EF;font-style:italic;">:.2f</span><span style="color:#AE81FF;">}</span><span style="color:#E6DB74;">%&quot;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#66D9EF;">print</span><span style="color:#F8F8F2;">(</span><span style="color:#66D9EF;font-style:italic;">f</span><span style="color:#E6DB74;">&quot;Longer Training &amp; Higher LR: </span><span style="color:#AE81FF;">{</span><span style="color:#F8F8F2;">long_training_acc</span><span style="color:#66D9EF;font-style:italic;">:.2f</span><span style="color:#AE81FF;">}</span><span style="color:#E6DB74;">%&quot;</span><span style="color:#F8F8F2;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div><div class="collapsed-lines"></div></div><h4 id="结果" tabindex="-1"><a class="header-anchor" href="#结果"><span>结果</span></a></h4><div class="language-python line-numbers-mode has-collapsed-lines collapsed" data-highlighter="shiki" data-ext="python" style="--vp-collapsed-lines:15;background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#F8F8F2;">D:\\</span><span style="color:#F44747;">603\\pythonProject\\.venv\\Scripts\\python.exe D:\\603\\pythonProject\\.venv\\LeNet.py </span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">Training Standard LeNet</span><span style="color:#AE81FF;">...</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.2498</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0694</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">3</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0505</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">4</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0404</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0309</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">6</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0263</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">7</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0221</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">8</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0194</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">9</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0164</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">10</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0140</span></span>
<span class="line"><span style="color:#F8F8F2;">Test Accuracy: </span><span style="color:#AE81FF;">98.79</span><span style="color:#F92672;">%</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">Training LeNet </span><span style="color:#F92672;">with</span><span style="color:#F8F8F2;"> Larger Convolution Channels </span><span style="color:#F92672;">and</span><span style="color:#F8F8F2;"> Different Kernel Sizes</span><span style="color:#AE81FF;">...</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.2332</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0612</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">3</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0432</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">4</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0327</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0270</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">6</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0238</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">7</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0179</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">8</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0137</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">9</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0141</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">10</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0104</span></span>
<span class="line"><span style="color:#F8F8F2;">Test Accuracy: </span><span style="color:#AE81FF;">98.98</span><span style="color:#F92672;">%</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">Training LeNet </span><span style="color:#F92672;">with</span><span style="color:#F8F8F2;"> Sigmoid Activation</span><span style="color:#AE81FF;">...</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.8909</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.1432</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">3</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0985</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">4</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0792</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0673</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">6</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0592</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">7</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0526</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">8</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0461</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">9</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0412</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">10</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0379</span></span>
<span class="line"><span style="color:#F8F8F2;">Test Accuracy: </span><span style="color:#AE81FF;">98.22</span><span style="color:#F92672;">%</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">Training LeNet </span><span style="color:#F92672;">with</span><span style="color:#F8F8F2;"> Modified Fully Connected Layers</span><span style="color:#AE81FF;">...</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.2323</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0645</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">3</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0456</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">4</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0353</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0287</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">6</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0228</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">7</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0212</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">8</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0166</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">9</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0146</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">10</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0119</span></span>
<span class="line"><span style="color:#F8F8F2;">Test Accuracy: </span><span style="color:#AE81FF;">98.90</span><span style="color:#F92672;">%</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">Training LeNet </span><span style="color:#F92672;">with</span><span style="color:#F8F8F2;"> More Training Epochs </span><span style="color:#F92672;">and</span><span style="color:#F8F8F2;"> Higher Learning Rate</span><span style="color:#AE81FF;">...</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.1462</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0636</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">3</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0501</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">4</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0449</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0424</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">6</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0407</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">7</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0350</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">8</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0343</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">9</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0365</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">10</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0310</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">11</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0315</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">12</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0309</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">13</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0263</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">14</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0320</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">15</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0279</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">16</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0212</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">17</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0274</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">18</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0247</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">19</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0282</span></span>
<span class="line"><span style="color:#F8F8F2;">Epoch </span><span style="color:#AE81FF;">20</span><span style="color:#F8F8F2;">, Loss: </span><span style="color:#AE81FF;">0.0287</span></span>
<span class="line"><span style="color:#F8F8F2;">Test Accuracy: </span><span style="color:#AE81FF;">98.37</span><span style="color:#F92672;">%</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F92672;">==========</span><span style="color:#F8F8F2;"> Model Comparison </span><span style="color:#F92672;">==========</span></span>
<span class="line"><span style="color:#F8F8F2;">Standard LeNet: </span><span style="color:#AE81FF;">98.79</span><span style="color:#F92672;">%</span></span>
<span class="line"><span style="color:#F8F8F2;">Larger Conv Channels: </span><span style="color:#AE81FF;">98.98</span><span style="color:#F92672;">%</span></span>
<span class="line"><span style="color:#F8F8F2;">Sigmoid Activation: </span><span style="color:#AE81FF;">98.22</span><span style="color:#F92672;">%</span></span>
<span class="line"><span style="color:#F8F8F2;">Modified </span><span style="color:#AE81FF;">FC</span><span style="color:#F8F8F2;"> Layers: </span><span style="color:#AE81FF;">98.90</span><span style="color:#F92672;">%</span></span>
<span class="line"><span style="color:#F8F8F2;">Longer Training </span><span style="color:#F92672;">&amp;</span><span style="color:#F8F8F2;"> Higher </span><span style="color:#AE81FF;">LR</span><span style="color:#F8F8F2;">: </span><span style="color:#AE81FF;">98.37</span><span style="color:#F92672;">%</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">进程已结束，退出代码为 </span><span style="color:#AE81FF;">0</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div><div class="collapsed-lines"></div></div><h3 id="task-03" tabindex="-1"><a class="header-anchor" href="#task-03"><span>Task 03</span></a></h3><h4 id="代码-2" tabindex="-1"><a class="header-anchor" href="#代码-2"><span>代码</span></a></h4><div class="language-python line-numbers-mode has-collapsed-lines collapsed" data-highlighter="shiki" data-ext="python" style="--vp-collapsed-lines:15;background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torch</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torch.nn </span><span style="color:#F92672;">as</span><span style="color:#F8F8F2;"> nn</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torchvision.transforms </span><span style="color:#F92672;">as</span><span style="color:#F8F8F2;"> transforms</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> torchvision</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> matplotlib.pyplot </span><span style="color:#F92672;">as</span><span style="color:#F8F8F2;"> plt</span></span>
<span class="line"><span style="color:#F92672;">import</span><span style="color:#F8F8F2;"> numpy </span><span style="color:#F92672;">as</span><span style="color:#F8F8F2;"> np</span></span>
<span class="line"><span style="color:#F92672;">from</span><span style="color:#AE81FF;"> PIL</span><span style="color:#F92672;"> import</span><span style="color:#F8F8F2;"> Image</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 1. 定义 LeNet 网络 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">class</span><span> </span><span style="color:#A6E22E;text-decoration:underline;">LeNet</span><span style="color:#F8F8F2;">(</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline;">nn</span><span style="color:#F8F8F2;">.</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline;">Module</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">    def</span><span style="color:#66D9EF;"> __init__</span><span style="color:#F8F8F2;">(</span><span style="color:#FD971F;font-style:italic;">self</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">        super</span><span style="color:#F8F8F2;">(LeNet, </span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">).</span><span style="color:#66D9EF;">__init__</span><span style="color:#F8F8F2;">()</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.conv1 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Conv2d(</span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">6</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">padding</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.pool </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.MaxPool2d(</span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">stride</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">2</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#FD971F;">        self</span><span style="color:#F8F8F2;">.conv2 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> nn.Conv2d(</span><span style="color:#AE81FF;">6</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">16</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">kernel_size</span><span style="color:#F92672;">=</span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">    def</span><span style="color:#A6E22E;"> forward</span><span style="color:#F8F8F2;">(</span><span style="color:#FD971F;font-style:italic;">self</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">x</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#F8F8F2;">        x1 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.relu(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.conv1(x))  </span><span style="color:#88846F;"># 第一层激活值</span></span>
<span class="line"><span style="color:#F8F8F2;">        x1_pooled </span><span style="color:#F92672;">=</span><span style="color:#FD971F;"> self</span><span style="color:#F8F8F2;">.pool(x1)</span></span>
<span class="line"><span style="color:#F8F8F2;">        x2 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> torch.relu(</span><span style="color:#FD971F;">self</span><span style="color:#F8F8F2;">.conv2(x1_pooled))  </span><span style="color:#88846F;"># 第二层激活值</span></span>
<span class="line"><span style="color:#F8F8F2;">        x2_pooled </span><span style="color:#F92672;">=</span><span style="color:#FD971F;"> self</span><span style="color:#F8F8F2;">.pool(x2)</span></span>
<span class="line"><span style="color:#F92672;">        return</span><span style="color:#F8F8F2;"> x1, x2</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 2. 载入并预处理图片 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">def</span><span style="color:#A6E22E;"> load_image</span><span style="color:#F8F8F2;">(</span><span style="color:#FD971F;font-style:italic;">image_path</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#F8F8F2;">    transform </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> transforms.Compose([</span></span>
<span class="line"><span style="color:#F8F8F2;">        transforms.Grayscale(),</span></span>
<span class="line"><span style="color:#F8F8F2;">        transforms.Resize((</span><span style="color:#AE81FF;">28</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">28</span><span style="color:#F8F8F2;">)),</span></span>
<span class="line"><span style="color:#F8F8F2;">        transforms.ToTensor(),</span></span>
<span class="line"><span style="color:#F8F8F2;">        transforms.Normalize((</span><span style="color:#AE81FF;">0.5</span><span style="color:#F8F8F2;">,), (</span><span style="color:#AE81FF;">0.5</span><span style="color:#F8F8F2;">,))</span></span>
<span class="line"><span style="color:#F8F8F2;">    ])</span></span>
<span class="line"><span style="color:#F8F8F2;">    image </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> Image.open(image_path)</span></span>
<span class="line"><span style="color:#F8F8F2;">    image </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> transform(image).unsqueeze(</span><span style="color:#AE81FF;">0</span><span style="color:#F8F8F2;">)  </span><span style="color:#88846F;"># 增加 batch 维度</span></span>
<span class="line"><span style="color:#F92672;">    return</span><span style="color:#F8F8F2;"> image</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 3. 可视化激活值 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic;">def</span><span style="color:#A6E22E;"> visualize_activations</span><span style="color:#F8F8F2;">(</span><span style="color:#FD971F;font-style:italic;">activations</span><span style="color:#F8F8F2;">, </span><span style="color:#FD971F;font-style:italic;">layer_name</span><span style="color:#F8F8F2;">):</span></span>
<span class="line"><span style="color:#F8F8F2;">    activations </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> activations.detach().cpu().numpy()</span></span>
<span class="line"><span style="color:#F8F8F2;">    num_filters </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> activations.shape[</span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">]</span></span>
<span class="line"><span style="color:#F8F8F2;">    fig, axes </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> plt.subplots(</span><span style="color:#AE81FF;">1</span><span style="color:#F8F8F2;">, num_filters, </span><span style="color:#FD971F;font-style:italic;">figsize</span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;">(</span><span style="color:#AE81FF;">15</span><span style="color:#F8F8F2;">, </span><span style="color:#AE81FF;">5</span><span style="color:#F8F8F2;">))</span></span>
<span class="line"><span style="color:#F92672;">    for</span><span style="color:#F8F8F2;"> i </span><span style="color:#F92672;">in</span><span style="color:#66D9EF;"> range</span><span style="color:#F8F8F2;">(num_filters):</span></span>
<span class="line"><span style="color:#F8F8F2;">        axes[i].imshow(activations[</span><span style="color:#AE81FF;">0</span><span style="color:#F8F8F2;">, i], </span><span style="color:#FD971F;font-style:italic;">cmap</span><span style="color:#F92672;">=</span><span style="color:#E6DB74;">&#39;gray&#39;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">        axes[i].axis(</span><span style="color:#E6DB74;">&#39;off&#39;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">    plt.suptitle(</span><span style="color:#66D9EF;font-style:italic;">f</span><span style="color:#E6DB74;">&#39;Activations of </span><span style="color:#AE81FF;">{</span><span style="color:#F8F8F2;">layer_name</span><span style="color:#AE81FF;">}</span><span style="color:#E6DB74;">&#39;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">    plt.show()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F;"># --------------------- 4. 运行模型并可视化 ---------------------</span></span>
<span class="line"><span style="color:#F8F8F2;">image_path </span><span style="color:#F92672;">=</span><span style="color:#E6DB74;"> &quot;D:\\pythonProject\\.venv\\Scripts\\images.jpg&quot;</span><span style="color:#88846F;">  # 使用上传的图片</span></span>
<span class="line"><span style="color:#F8F8F2;">image </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> load_image(image_path)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">model </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> LeNet()</span></span>
<span class="line"><span style="color:#F8F8F2;">model.eval()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F92672;">with</span><span style="color:#F8F8F2;"> torch.no_grad():</span></span>
<span class="line"><span style="color:#F8F8F2;">    act1, act2 </span><span style="color:#F92672;">=</span><span style="color:#F8F8F2;"> model(image)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2;">visualize_activations(act1, </span><span style="color:#E6DB74;">&#39;First Conv Layer&#39;</span><span style="color:#F8F8F2;">)</span></span>
<span class="line"><span style="color:#F8F8F2;">visualize_activations(act2, </span><span style="color:#E6DB74;">&#39;Second Conv Layer&#39;</span><span style="color:#F8F8F2;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div><div class="collapsed-lines"></div></div><figure><img src="`+o+'" alt="image-20250320005059601" tabindex="0" loading="lazy"><figcaption>image-20250320005059601</figcaption></figure><h4 id="结果-1" tabindex="-1"><a class="header-anchor" href="#结果-1"><span>结果</span></a></h4><figure><img src="'+e+'" alt="image-20250320005023673" tabindex="0" loading="lazy"><figcaption>image-20250320005023673</figcaption></figure>',19)]))}const y=n(F,[["render",c]]),d=JSON.parse('{"path":"/zh/DeepThinking/cnn.html","title":"早停调参","lang":"zh-CN","frontmatter":{"title":"早停调参","icon":"alias","date":"2025-03-18T15:52:11.000Z","author":"XiaoXianYue","isOriginal":true,"category":["大三下","神经网络与深度学习"],"tag":["大三下","神经网络与深度学习"],"sticky":false,"star":false,"article":true,"timeline":true,"image":false,"navbar":true,"sidebarIcon":true,"headerDepth":5,"lastUpdated":true,"editLink":false,"backToTop":true,"toc":true,"description":"Task 01 替换平均池化（AvgPool）为最大池化（MaxPool），并输出结果。 代码 运行结果 最大池化确实比平均池化的正确率提高了一点点。 Task 02 改变卷积窗口大小 修改输出通道数 更改激活函数（ReLU） 调整卷积层和全连接层的数量 修改学习率和训练轮数（epochs） 代码 结果 Task 03 代码 image-2025032...","head":[["meta",{"property":"og:url","content":"https://bougiemoonintaurus/zh/DeepThinking/cnn.html"}],["meta",{"property":"og:site_name","content":"奶酪奶酪"}],["meta",{"property":"og:title","content":"早停调参"}],["meta",{"property":"og:description","content":"Task 01 替换平均池化（AvgPool）为最大池化（MaxPool），并输出结果。 代码 运行结果 最大池化确实比平均池化的正确率提高了一点点。 Task 02 改变卷积窗口大小 修改输出通道数 更改激活函数（ReLU） 调整卷积层和全连接层的数量 修改学习率和训练轮数（epochs） 代码 结果 Task 03 代码 image-2025032..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-03-19T17:01:16.000Z"}],["meta",{"property":"article:author","content":"XiaoXianYue"}],["meta",{"property":"article:tag","content":"大三下"}],["meta",{"property":"article:tag","content":"神经网络与深度学习"}],["meta",{"property":"article:published_time","content":"2025-03-18T15:52:11.000Z"}],["meta",{"property":"article:modified_time","content":"2025-03-19T17:01:16.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"早停调参\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-03-18T15:52:11.000Z\\",\\"dateModified\\":\\"2025-03-19T17:01:16.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"XiaoXianYue\\"}]}"]]},"git":{"createdTime":1742403676000,"updatedTime":1742403676000,"contributors":[{"name":"Xiaoxianyue","username":"Xiaoxianyue","email":"2310219843@qq.com","commits":1,"url":"https://github.com/Xiaoxianyue"}]},"readingTime":{"minutes":6.27,"words":1881},"filePathRelative":"zh/DeepThinking/cnn.md","localizedDate":"2025年3月18日","excerpt":"<h3>Task 01</h3>\\n<blockquote>\\n<p>替换平均池化（AvgPool）为最大池化（MaxPool），并输出结果。</p>\\n</blockquote>\\n<h4>代码</h4>\\n<div class=\\"language-python line-numbers-mode has-collapsed-lines collapsed\\" data-highlighter=\\"shiki\\" data-ext=\\"python\\" style=\\"--vp-collapsed-lines:15;background-color:#272822;color:#F8F8F2\\"><pre class=\\"shiki monokai vp-code\\"><code><span class=\\"line\\"><span style=\\"color:#F92672\\">import</span><span style=\\"color:#F8F8F2\\"> torch</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F92672\\">import</span><span style=\\"color:#F8F8F2\\"> torch.nn </span><span style=\\"color:#F92672\\">as</span><span style=\\"color:#F8F8F2\\"> nn</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F92672\\">import</span><span style=\\"color:#F8F8F2\\"> torch.optim </span><span style=\\"color:#F92672\\">as</span><span style=\\"color:#F8F8F2\\"> optim</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F92672\\">import</span><span style=\\"color:#F8F8F2\\"> torchvision</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F92672\\">import</span><span style=\\"color:#F8F8F2\\"> torchvision.transforms </span><span style=\\"color:#F92672\\">as</span><span style=\\"color:#F8F8F2\\"> transforms</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#88846F\\"># --------------------- 1. 定义 LeNet 网络 ---------------------</span></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF;font-style:italic\\">class</span><span> </span><span style=\\"color:#A6E22E;text-decoration:underline\\">LeNet</span><span style=\\"color:#F8F8F2\\">(</span><span style=\\"color:#A6E22E;font-style:italic;text-decoration:underline\\">nn</span><span style=\\"color:#F8F8F2\\">.</span><span style=\\"color:#A6E22E;font-style:italic;text-decoration:underline\\">Module</span><span style=\\"color:#F8F8F2\\">):</span></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF;font-style:italic\\">    def</span><span style=\\"color:#66D9EF\\"> __init__</span><span style=\\"color:#F8F8F2\\">(</span><span style=\\"color:#FD971F;font-style:italic\\">self</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">use_maxpool</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">True</span><span style=\\"color:#F8F8F2\\">):</span></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF;font-style:italic\\">        super</span><span style=\\"color:#F8F8F2\\">(LeNet, </span><span style=\\"color:#FD971F\\">self</span><span style=\\"color:#F8F8F2\\">).</span><span style=\\"color:#66D9EF\\">__init__</span><span style=\\"color:#F8F8F2\\">()</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#88846F\\">        # 卷积层</span></span>\\n<span class=\\"line\\"><span style=\\"color:#FD971F\\">        self</span><span style=\\"color:#F8F8F2\\">.conv1 </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> nn.Conv2d(</span><span style=\\"color:#AE81FF\\">1</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#AE81FF\\">6</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">kernel_size</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">5</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">padding</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">2</span><span style=\\"color:#F8F8F2\\">)  </span><span style=\\"color:#88846F\\"># 28x28 -&gt; 28x28</span></span>\\n<span class=\\"line\\"><span style=\\"color:#FD971F\\">        self</span><span style=\\"color:#F8F8F2\\">.conv2 </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> nn.Conv2d(</span><span style=\\"color:#AE81FF\\">6</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#AE81FF\\">16</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">kernel_size</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">5</span><span style=\\"color:#F8F8F2\\">)  </span><span style=\\"color:#88846F\\"># 14x14 -&gt; 10x10</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#88846F\\">        # 选择池化方式（默认使用 MaxPool）</span></span>\\n<span class=\\"line\\"><span style=\\"color:#FD971F\\">        self</span><span style=\\"color:#F8F8F2\\">.pool </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> nn.MaxPool2d(</span><span style=\\"color:#FD971F;font-style:italic\\">kernel_size</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">2</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">stride</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">2</span><span style=\\"color:#F8F8F2\\">) </span><span style=\\"color:#F92672\\">if</span><span style=\\"color:#F8F8F2\\"> use_maxpool </span><span style=\\"color:#F92672\\">else</span><span style=\\"color:#F8F8F2\\"> nn.AvgPool2d(</span><span style=\\"color:#FD971F;font-style:italic\\">kernel_size</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">2</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">stride</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">2</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#88846F\\">        # 全连接层</span></span>\\n<span class=\\"line\\"><span style=\\"color:#FD971F\\">        self</span><span style=\\"color:#F8F8F2\\">.fc1 </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> nn.Linear(</span><span style=\\"color:#AE81FF\\">16</span><span style=\\"color:#F92672\\"> *</span><span style=\\"color:#AE81FF\\"> 5</span><span style=\\"color:#F92672\\"> *</span><span style=\\"color:#AE81FF\\"> 5</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#AE81FF\\">120</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#FD971F\\">        self</span><span style=\\"color:#F8F8F2\\">.fc2 </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> nn.Linear(</span><span style=\\"color:#AE81FF\\">120</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#AE81FF\\">84</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#FD971F\\">        self</span><span style=\\"color:#F8F8F2\\">.fc3 </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> nn.Linear(</span><span style=\\"color:#AE81FF\\">84</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#AE81FF\\">10</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF;font-style:italic\\">    def</span><span style=\\"color:#A6E22E\\"> forward</span><span style=\\"color:#F8F8F2\\">(</span><span style=\\"color:#FD971F;font-style:italic\\">self</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">x</span><span style=\\"color:#F8F8F2\\">):</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">        x </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#FD971F\\"> self</span><span style=\\"color:#F8F8F2\\">.pool(torch.relu(</span><span style=\\"color:#FD971F\\">self</span><span style=\\"color:#F8F8F2\\">.conv1(x)))  </span><span style=\\"color:#88846F\\"># 第一层卷积 + ReLU + 池化</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">        x </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#FD971F\\"> self</span><span style=\\"color:#F8F8F2\\">.pool(torch.relu(</span><span style=\\"color:#FD971F\\">self</span><span style=\\"color:#F8F8F2\\">.conv2(x)))  </span><span style=\\"color:#88846F\\"># 第二层卷积 + ReLU + 池化</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">        x </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> torch.flatten(x, </span><span style=\\"color:#AE81FF\\">1</span><span style=\\"color:#F8F8F2\\">)  </span><span style=\\"color:#88846F\\"># 展平</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">        x </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> torch.relu(</span><span style=\\"color:#FD971F\\">self</span><span style=\\"color:#F8F8F2\\">.fc1(x))</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">        x </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> torch.relu(</span><span style=\\"color:#FD971F\\">self</span><span style=\\"color:#F8F8F2\\">.fc2(x))</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">        x </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#FD971F\\"> self</span><span style=\\"color:#F8F8F2\\">.fc3(x)  </span><span style=\\"color:#88846F\\"># 最终输出 10 维</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F92672\\">        return</span><span style=\\"color:#F8F8F2\\"> x</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#88846F\\"># --------------------- 2. 载入 MNIST 数据集 ---------------------</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">mnist_data_path </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#E6DB74\\"> \\"D:/603/pythonProject/data/MNIST/\\"</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">transform </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> transforms.Compose([</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">    transforms.Grayscale(),</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">    transforms.ToTensor(),</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">    transforms.Normalize((</span><span style=\\"color:#AE81FF\\">0.5</span><span style=\\"color:#F8F8F2\\">,), (</span><span style=\\"color:#AE81FF\\">0.5</span><span style=\\"color:#F8F8F2\\">,))  </span><span style=\\"color:#88846F\\"># 归一化到 [-1, 1]</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">])</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#88846F\\"># 加载训练和测试数据</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">trainset </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> torchvision.datasets.MNIST(</span><span style=\\"color:#FD971F;font-style:italic\\">root</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\">mnist_data_path, </span><span style=\\"color:#FD971F;font-style:italic\\">train</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">True</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">download</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">False</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">transform</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\">transform)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">testset </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> torchvision.datasets.MNIST(</span><span style=\\"color:#FD971F;font-style:italic\\">root</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\">mnist_data_path, </span><span style=\\"color:#FD971F;font-style:italic\\">train</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">False</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">download</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">False</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">transform</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\">transform)</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">train_loader </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> torch.utils.data.DataLoader(trainset, </span><span style=\\"color:#FD971F;font-style:italic\\">batch_size</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">64</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">shuffle</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">True</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">test_loader </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> torch.utils.data.DataLoader(testset, </span><span style=\\"color:#FD971F;font-style:italic\\">batch_size</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">64</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">shuffle</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">False</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#88846F\\"># --------------------- 3. 训练模型 ---------------------</span></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF;font-style:italic\\">def</span><span style=\\"color:#A6E22E\\"> train_model</span><span style=\\"color:#F8F8F2\\">(</span><span style=\\"color:#FD971F;font-style:italic\\">model</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">train_loader</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">epochs</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">5</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">learning_rate</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">0.001</span><span style=\\"color:#F8F8F2\\">):</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">    device </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> torch.device(</span><span style=\\"color:#E6DB74\\">\\"cuda\\"</span><span style=\\"color:#F92672\\"> if</span><span style=\\"color:#F8F8F2\\"> torch.cuda.is_available() </span><span style=\\"color:#F92672\\">else</span><span style=\\"color:#E6DB74\\"> \\"cpu\\"</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">    model.to(device)</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">    criterion </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> nn.CrossEntropyLoss()</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">    optimizer </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> optim.Adam(model.parameters(), </span><span style=\\"color:#FD971F;font-style:italic\\">lr</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\">learning_rate)</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#F92672\\">    for</span><span style=\\"color:#F8F8F2\\"> epoch </span><span style=\\"color:#F92672\\">in</span><span style=\\"color:#66D9EF\\"> range</span><span style=\\"color:#F8F8F2\\">(epochs):</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">        model.train()</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">        running_loss </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\"> 0.0</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F92672\\">        for</span><span style=\\"color:#F8F8F2\\"> images, labels </span><span style=\\"color:#F92672\\">in</span><span style=\\"color:#F8F8F2\\"> train_loader:</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            images, labels </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> images.to(device), labels.to(device)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            optimizer.zero_grad()</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            outputs </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> model(images)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            loss </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> criterion(outputs, labels)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            loss.backward()</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            optimizer.step()</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            running_loss </span><span style=\\"color:#F92672\\">+=</span><span style=\\"color:#F8F8F2\\"> loss.item()</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF\\">        print</span><span style=\\"color:#F8F8F2\\">(</span><span style=\\"color:#66D9EF;font-style:italic\\">f</span><span style=\\"color:#E6DB74\\">\\"Epoch </span><span style=\\"color:#AE81FF\\">{</span><span style=\\"color:#F8F8F2\\">epoch </span><span style=\\"color:#F92672\\">+</span><span style=\\"color:#AE81FF\\"> 1}</span><span style=\\"color:#E6DB74\\">, Loss: </span><span style=\\"color:#AE81FF\\">{</span><span style=\\"color:#F8F8F2\\">running_loss </span><span style=\\"color:#F92672\\">/</span><span style=\\"color:#66D9EF\\"> len</span><span style=\\"color:#F8F8F2\\">(train_loader)</span><span style=\\"color:#66D9EF;font-style:italic\\">:.4f</span><span style=\\"color:#AE81FF\\">}</span><span style=\\"color:#E6DB74\\">\\"</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#88846F\\"># --------------------- 4. 评估模型 ---------------------</span></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF;font-style:italic\\">def</span><span style=\\"color:#A6E22E\\"> evaluate_model</span><span style=\\"color:#F8F8F2\\">(</span><span style=\\"color:#FD971F;font-style:italic\\">model</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">test_loader</span><span style=\\"color:#F8F8F2\\">):</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">    device </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> torch.device(</span><span style=\\"color:#E6DB74\\">\\"cuda\\"</span><span style=\\"color:#F92672\\"> if</span><span style=\\"color:#F8F8F2\\"> torch.cuda.is_available() </span><span style=\\"color:#F92672\\">else</span><span style=\\"color:#E6DB74\\"> \\"cpu\\"</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">    model.to(device)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">    model.eval()</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">    correct, total </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\"> 0</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#AE81FF\\">0</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F92672\\">    with</span><span style=\\"color:#F8F8F2\\"> torch.no_grad():</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F92672\\">        for</span><span style=\\"color:#F8F8F2\\"> images, labels </span><span style=\\"color:#F92672\\">in</span><span style=\\"color:#F8F8F2\\"> test_loader:</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            images, labels </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> images.to(device), labels.to(device)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            outputs </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> model(images)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            _, predicted </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> torch.max(outputs, </span><span style=\\"color:#AE81FF\\">1</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            total </span><span style=\\"color:#F92672\\">+=</span><span style=\\"color:#F8F8F2\\"> labels.size(</span><span style=\\"color:#AE81FF\\">0</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">            correct </span><span style=\\"color:#F92672\\">+=</span><span style=\\"color:#F8F8F2\\"> (predicted </span><span style=\\"color:#F92672\\">==</span><span style=\\"color:#F8F8F2\\"> labels).sum().item()</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF\\">    print</span><span style=\\"color:#F8F8F2\\">(</span><span style=\\"color:#66D9EF;font-style:italic\\">f</span><span style=\\"color:#E6DB74\\">\\"Test Accuracy: </span><span style=\\"color:#AE81FF\\">{100</span><span style=\\"color:#F92672\\"> *</span><span style=\\"color:#F8F8F2\\"> correct </span><span style=\\"color:#F92672\\">/</span><span style=\\"color:#F8F8F2\\"> total</span><span style=\\"color:#66D9EF;font-style:italic\\">:.2f</span><span style=\\"color:#AE81FF\\">}</span><span style=\\"color:#E6DB74\\">%\\"</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#88846F\\"># --------------------- 5. 运行实验 ---------------------</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#88846F\\"># 训练并评估使用平均池化的 LeNet</span></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF\\">print</span><span style=\\"color:#F8F8F2\\">(</span><span style=\\"color:#E6DB74\\">\\"</span><span style=\\"color:#AE81FF\\">\\\\n</span><span style=\\"color:#E6DB74\\">Training LeNet with Average Pooling...\\"</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">lenet_avg </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> LeNet(</span><span style=\\"color:#FD971F;font-style:italic\\">use_maxpool</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">False</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">train_model(lenet_avg, train_loader, </span><span style=\\"color:#FD971F;font-style:italic\\">epochs</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">5</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">learning_rate</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">0.001</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF\\">print</span><span style=\\"color:#F8F8F2\\">(</span><span style=\\"color:#E6DB74\\">\\"</span><span style=\\"color:#AE81FF\\">\\\\n</span><span style=\\"color:#E6DB74\\">Evaluating LeNet with Average Pooling...\\"</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">evaluate_model(lenet_avg, test_loader)</span></span>\\n<span class=\\"line\\"></span>\\n<span class=\\"line\\"><span style=\\"color:#88846F\\"># 训练并评估使用最大池化的 LeNet</span></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF\\">print</span><span style=\\"color:#F8F8F2\\">(</span><span style=\\"color:#E6DB74\\">\\"</span><span style=\\"color:#AE81FF\\">\\\\n</span><span style=\\"color:#E6DB74\\">Training LeNet with Max Pooling...\\"</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">lenet_max </span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#F8F8F2\\"> LeNet(</span><span style=\\"color:#FD971F;font-style:italic\\">use_maxpool</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">True</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">train_model(lenet_max, train_loader, </span><span style=\\"color:#FD971F;font-style:italic\\">epochs</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">5</span><span style=\\"color:#F8F8F2\\">, </span><span style=\\"color:#FD971F;font-style:italic\\">learning_rate</span><span style=\\"color:#F92672\\">=</span><span style=\\"color:#AE81FF\\">0.001</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#66D9EF\\">print</span><span style=\\"color:#F8F8F2\\">(</span><span style=\\"color:#E6DB74\\">\\"</span><span style=\\"color:#AE81FF\\">\\\\n</span><span style=\\"color:#E6DB74\\">Evaluating LeNet with Max Pooling...\\"</span><span style=\\"color:#F8F8F2\\">)</span></span>\\n<span class=\\"line\\"><span style=\\"color:#F8F8F2\\">evaluate_model(lenet_max, test_loader)</span></span></code></pre>\\n<div class=\\"line-numbers\\" aria-hidden=\\"true\\" style=\\"counter-reset:line-number 0\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div><div class=\\"collapsed-lines\\"></div></div>","autoDesc":true}');export{y as comp,d as data};
