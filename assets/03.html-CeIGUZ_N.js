import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,b as a,o as n}from"./app-84lBMjzT.js";const o="/assets/image-20250318103415700-Cdr_NCr5.png",r="/assets/image-20250318104245806-0r2g5PW4.png",l={};function s(c,e){return n(),i("div",null,e[0]||(e[0]=[a('<h2 id="卷积" tabindex="-1"><a class="header-anchor" href="#卷积"><span>卷积</span></a></h2><h3 id="计算过程" tabindex="-1"><a class="header-anchor" href="#计算过程"><span>计算过程</span></a></h3><img src="'+o+'" alt="image-20250318103415700" style="zoom:50%;"><ul><li>The weight matrix for the convolution, which is the white square in the middle of the figure，but in regular calculation, there is a bias</li></ul><h3 id="padding-classification" tabindex="-1"><a class="header-anchor" href="#padding-classification"><span>Padding-classification</span></a></h3><figure><img src="'+r+'" alt="image-20250318104245806" tabindex="0" loading="lazy"><figcaption>image-20250318104245806</figcaption></figure><ul><li>That is to say, the size of the convolutional kernel need to fit the convolution area.</li></ul><h3 id="padding-application" tabindex="-1"><a class="header-anchor" href="#padding-application"><span>Padding-Application：</span></a></h3><p>图中展示了如何使用不同的填充方法影响卷积结果：</p><ul><li><strong>原始图像大小</strong>：一个 10x10 的图像。</li><li><strong>卷积核</strong>：5x5 的卷积核应用于原始图像时，输出的图像尺寸变为 <strong>6x6</strong>，比原始图像要小。</li><li><strong>Valid Padding（有效填充）</strong>：表示在卷积操作中不添加任何额外的像素，结果图像比原始图像小。这种填充方式在早期的卷积神经网络（如 LeNet）中广泛采用。</li><li>A result that is smaller than the original image, early convolutional networks such as LeNet <mark>adopted this structure</mark>.</li></ul><h3 id="padding-function" tabindex="-1"><a class="header-anchor" href="#padding-function"><span>Padding-Function：</span></a></h3><p>图中还展示了两种常见的填充方法：</p><ul><li><strong>Full Padding（全填充）</strong>：这种方法通过在图像周围填充更多的零，使得卷积核可以完全覆盖图像的每个像素，包括边缘像素。结果是图像尺寸不会变小，反而可能会变大。</li><li><strong>Same Padding（相同填充）</strong>：这种方法填充图像的零使得卷积操作后，输出图像的尺寸与原始图像相同。通过填充边缘，使得卷积核的中心可以处理图像的所有像素，包括边缘和角落的像素。</li><li>To solve the problem: For the convolution operation of the image, <mark>the most marginal pixel generally cannot be processed</mark>, so the center of the convolution kernel cannot.</li></ul>',13)]))}const p=t(l,[["render",s]]),u=JSON.parse('{"path":"/zh/DeepThinking/03.html","title":"CNN:Basic components and LeNet","lang":"zh-CN","frontmatter":{"title":"CNN:Basic components and LeNet","icon":"alias","date":"2025-03-18T10:26:43.000Z","author":"XiaoXianYue","isOriginal":true,"category":["大三下","神经网络与深度学习"],"tag":["大三下","神经网络与深度学习"],"sticky":false,"star":false,"article":true,"timeline":true,"image":false,"navbar":true,"sidebarIcon":true,"headerDepth":5,"lastUpdated":true,"editLink":false,"backToTop":true,"toc":true,"description":"卷积 计算过程 image-20250318103415700 The weight matrix for the convolution, which is the white square in the middle of the figure，but in regular calculation, there is a bias Padding-...","head":[["meta",{"property":"og:url","content":"https://bougiemoonintaurus/zh/DeepThinking/03.html"}],["meta",{"property":"og:site_name","content":"奶酪奶酪"}],["meta",{"property":"og:title","content":"CNN:Basic components and LeNet"}],["meta",{"property":"og:description","content":"卷积 计算过程 image-20250318103415700 The weight matrix for the convolution, which is the white square in the middle of the figure，but in regular calculation, there is a bias Padding-..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-03-19T17:01:16.000Z"}],["meta",{"property":"article:author","content":"XiaoXianYue"}],["meta",{"property":"article:tag","content":"大三下"}],["meta",{"property":"article:tag","content":"神经网络与深度学习"}],["meta",{"property":"article:published_time","content":"2025-03-18T10:26:43.000Z"}],["meta",{"property":"article:modified_time","content":"2025-03-19T17:01:16.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"CNN:Basic components and LeNet\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-03-18T10:26:43.000Z\\",\\"dateModified\\":\\"2025-03-19T17:01:16.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"XiaoXianYue\\"}]}"]]},"git":{"createdTime":1742403676000,"updatedTime":1742403676000,"contributors":[{"name":"Xiaoxianyue","username":"Xiaoxianyue","email":"2310219843@qq.com","commits":1,"url":"https://github.com/Xiaoxianyue"}]},"readingTime":{"minutes":1.53,"words":458},"filePathRelative":"zh/DeepThinking/03.md","localizedDate":"2025年3月18日","excerpt":"<h2>卷积</h2>\\n<h3>计算过程</h3>\\n\\n<ul>\\n<li>The weight matrix for the convolution, which is the white square in the middle of the figure，but in regular calculation, there is a bias</li>\\n</ul>\\n<h3>Padding-classification</h3>\\n<figure><figcaption>image-20250318104245806</figcaption></figure>\\n<ul>\\n<li>That is to say, the size of the convolutional kernel need to fit the convolution area.</li>\\n</ul>","autoDesc":true}');export{p as comp,u as data};
