import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,b as a,o as n}from"./app-Cr94KhCm.js";const t="/assets/image-20250227112630712-ntuCWzmU.png",l="/assets/image-20250227114657752-DgkgCNvU.png",i="/assets/image-20250227115041539-DvqG7vLN.png",r={};function d(c,e){return n(),o("div",null,e[0]||(e[0]=[a('<h2 id="_1-百度" tabindex="-1"><a class="header-anchor" href="#_1-百度"><span>1. 百度</span></a></h2><img src="'+t+`" alt="image-20250227112630712" style="zoom:50%;"><h3 id="_1-1-说明协议内容" tabindex="-1"><a class="header-anchor" href="#_1-1-说明协议内容"><span>1.1 说明协议内容</span></a></h3><h4 id="_1-user-agent-指令" tabindex="-1"><a class="header-anchor" href="#_1-user-agent-指令"><span><strong>(1) User-agent 指令</strong></span></a></h4><ul><li><code>User-agent</code> 指定哪些爬虫适用该规则。</li><li>百度的 <code>robots.txt</code> 适用于 <strong>多个爬虫</strong>，包括： <ul><li><code>Baiduspider</code>（百度爬虫）</li><li><code>Googlebot</code>（Google 爬虫）</li><li><code>MSNBot</code>（微软必应爬虫）</li><li><code>YoudaoBot</code>（有道爬虫）</li><li><code>Sogou inst spider</code>（搜狗爬虫）</li><li><code>JikeSpider</code>（即刻搜索爬虫）</li><li><code>Soospider</code>（搜搜爬虫）</li><li><code>Yisouspider</code>（易搜爬虫）</li><li><code>EasouSpider</code>（宜搜爬虫）</li></ul></li></ul><hr><h4 id="_2-disallow-指令" tabindex="-1"><a class="header-anchor" href="#_2-disallow-指令"><span><strong>(2) Disallow 指令</strong></span></a></h4><ul><li><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span>  Disallow</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>用于 禁止爬虫访问某些路径，例如：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#A6E22E;">Disallow:</span><span style="color:#E6DB74;"> /baidu</span></span>
<span class="line"><span style="color:#A6E22E;">Disallow:</span><span style="color:#E6DB74;"> /s?</span></span>
<span class="line"><span style="color:#A6E22E;">Disallow:</span><span style="color:#E6DB74;"> /shifen/</span></span>
<span class="line"><span style="color:#A6E22E;">Disallow:</span><span style="color:#E6DB74;"> /homepage/</span></span>
<span class="line"><span style="color:#A6E22E;">Disallow:</span><span style="color:#E6DB74;"> /cpro</span></span>
<span class="line"><span style="color:#A6E22E;">Disallow:</span><span style="color:#E6DB74;"> /ulink?</span></span>
<span class="line"><span style="color:#A6E22E;">Disallow:</span><span style="color:#E6DB74;"> /link?</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><strong><code>Disallow: /baidu</code></strong><br> → <strong>禁止爬虫访问 <code>/baidu</code> 目录</strong></li><li><strong><code>Disallow: /s?</code></strong><br> → <strong>禁止爬虫访问 <code>/s?</code> 相关页面，通常是搜索结果页</strong></li><li><strong><code>Disallow: /shifen/</code></strong><br> → <strong>禁止爬虫访问 <code>/shifen/</code> 目录，可能是百度的某个产品</strong></li><li><strong><code>Disallow: /homepage/</code></strong><br> → <strong>禁止爬虫访问 <code>/homepage/</code> 目录</strong></li><li><strong><code>Disallow: /cpro</code></strong><br> → <strong>可能与百度广告系统相关，禁止爬取</strong></li><li><strong><code>Disallow: /ulink?</code> 和 <code>Disallow: /link?</code></strong><br> → <strong>禁止爬虫访问链接重定向、超链接处理相关的 URL</strong></li></ul></li></ul><hr><h4 id="_3-通用规则" tabindex="-1"><a class="header-anchor" href="#_3-通用规则"><span><strong>(3) 通用规则</strong></span></a></h4><div class="language-makefile line-numbers-mode" data-highlighter="shiki" data-ext="makefile" style="background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#A6E22E;">User-agent</span><span style="color:#F8F8F2;">: </span><span style="color:#AE81FF;">*</span></span>
<span class="line"><span style="color:#A6E22E;">Disallow</span><span style="color:#F8F8F2;">: /</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><code>User-agent: *</code> 适用于 <strong>所有爬虫</strong>（通配符 <code>*</code> 代表所有爬虫）。</li><li><code>Disallow: /</code> 表示 <strong>禁止所有爬虫访问整个网站</strong>。</li></ul><h3 id="_1-2-url" tabindex="-1"><a class="header-anchor" href="#_1-2-url"><span>1.2 URL</span></a></h3><p>对于 <code>http://baidu.com/robots.txt</code>，可以分解为：</p><ol><li><strong>协议（Scheme）：<code>http://</code></strong><ul><li>这里的 <strong><code>http</code>（超文本传输协议，Hypertext Transfer Protocol）</strong> 表示浏览器或爬虫访问百度服务器时使用的通信协议。</li><li>如果是 <code>https://</code>，则表示使用 <strong>安全超文本传输协议（HTTPS）</strong>，支持加密传输。</li></ul></li><li><strong>域名（Domain）：<code>baidu.com</code></strong><ul><li>这是百度网站的主域名。</li><li>域名是一个 <strong>可读的地址</strong>，用于定位互联网上的服务器，最终会解析为一个 <strong>IP 地址</strong>。</li></ul></li><li><strong>路径（Path）：<code>/robots.txt</code></strong><ul><li><code>robots.txt</code> 是一个标准文件，用于控制搜索引擎爬虫的访问权限。</li><li><code>robots.txt</code> 放置在网站的根目录，搜索引擎会在访问网站时首先检查这个文件，以确定可以抓取哪些内容。</li></ul></li></ol><h2 id="_2-淘宝" tabindex="-1"><a class="header-anchor" href="#_2-淘宝"><span>2. 淘宝</span></a></h2><figure><img src="`+l+`" alt="image-20250227114657752" tabindex="0" loading="lazy"><figcaption>image-20250227114657752</figcaption></figure><h3 id="_2-1-说明协议内容" tabindex="-1"><a class="header-anchor" href="#_2-1-说明协议内容"><span>2.1 说明协议内容</span></a></h3><h4 id="_1-user-agent" tabindex="-1"><a class="header-anchor" href="#_1-user-agent"><span><strong>1. <code>User-agent: \\*</code></strong></span></a></h4><ul><li><strong><code>User-agent</code> 代表搜索引擎爬虫的名称</strong>。</li><li><strong><code>\\*</code>（星号）表示适用于所有爬虫</strong>，包括 Googlebot、Baiduspider、Sogou Spider 等。</li></ul><hr><h4 id="_2-allow-list" tabindex="-1"><a class="header-anchor" href="#_2-allow-list"><span><strong>2. <code>Allow: /list/</code></strong></span></a></h4><ul><li><p><strong><code>Allow</code> 指令表示允许爬虫抓取某个路径</strong>。</p></li><li><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span>  /list/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>代表所有以</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span>/list/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>开头的 URL 都可以被爬取，例如：</p><div class="language-arduino line-numbers-mode" data-highlighter="shiki" data-ext="arduino" style="background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#F8F8F2;">https:</span><span style="color:#F92672;">//</span><span style="color:#F8F8F2;">www.example.com</span><span style="color:#F92672;">/</span><span style="color:#66D9EF;font-style:italic;">list</span><span style="color:#F92672;">/</span></span>
<span class="line"><span style="color:#F8F8F2;">https:</span><span style="color:#F92672;">//</span><span style="color:#F8F8F2;">www.example.com</span><span style="color:#F92672;">/</span><span style="color:#66D9EF;font-style:italic;">list</span><span style="color:#F92672;">/</span><span style="color:#F8F8F2;">category1</span></span>
<span class="line"><span style="color:#F8F8F2;">https:</span><span style="color:#F92672;">//</span><span style="color:#F8F8F2;">www.example.com</span><span style="color:#F92672;">/</span><span style="color:#66D9EF;font-style:italic;">list</span><span style="color:#F92672;">/</span><span style="color:#F8F8F2;">products</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>这意味着爬虫可以索引该网站的 <strong>商品列表、分类页面或目录页</strong>。</p></li></ul><hr><h4 id="_3-disallow" tabindex="-1"><a class="header-anchor" href="#_3-disallow"><span><strong>3. <code>Disallow: /\\*?\\*</code></strong></span></a></h4><ul><li><p><strong><code>Disallow</code> 指令表示禁止爬虫抓取某些路径</strong>。</p></li><li><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span>  /*?*</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>的意思是：</p><ul><li><code>*</code> 代表 <strong>通配符</strong>，匹配 <strong>任意字符</strong>。</li><li><code>?</code> 代表 <strong>URL 中的查询参数</strong>（通常用于搜索、筛选、分页等）。</li><li><code>/*?*</code> 表示 <strong>任何包含 <code>?</code> 的 URL 都禁止被爬取</strong>。</li></ul></li></ul><h5 id="示例-禁止爬取的-url" tabindex="-1"><a class="header-anchor" href="#示例-禁止爬取的-url"><span><strong>示例：禁止爬取的 URL</strong></span></a></h5><p>以下 URL 都会被 <strong>禁止爬取</strong>，因为它们包含 <code>?</code>：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="background-color:#272822;color:#F8F8F2;"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#A6E22E;">https://www.example.com/search?q</span><span style="color:#E6DB74;">=product</span></span>
<span class="line"><span style="color:#A6E22E;">https://www.example.com/list?page</span><span style="color:#E6DB74;">=2</span></span>
<span class="line"><span style="color:#A6E22E;">https://www.example.com/product?id</span><span style="color:#E6DB74;">=12345</span></span>
<span class="line"><span style="color:#A6E22E;">https://www.example.com/list/?sort</span><span style="color:#E6DB74;">=price</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这表明 <strong>网站不希望爬虫抓取动态查询页面（如搜索结果、分页等），可能是为了避免爬取重复内容，减少服务器压力</strong>。</p><h3 id="_2-2-url" tabindex="-1"><a class="header-anchor" href="#_2-2-url"><span>2.2 URL</span></a></h3><table><thead><tr><th>组成部分</th><th>具体内容</th><th>说明</th></tr></thead><tbody><tr><td><strong>协议（Scheme）</strong></td><td><code>https://</code></td><td>采用 <strong>HTTPS</strong>，表示超文本传输安全协议，比 HTTP 更安全</td></tr><tr><td><strong>子域名（Subdomain）</strong></td><td><code>www</code></td><td>代表 <strong>淘宝的网页服务</strong>，可省略（<code>taobao.com</code> 也能访问）</td></tr><tr><td><strong>主域名（Domain）</strong></td><td><code>taobao</code></td><td><strong>淘宝的核心域名</strong>，代表阿里巴巴旗下的电商平台</td></tr><tr><td><strong>顶级域名（TLD）</strong></td><td><code>.com</code></td><td><strong>国际通用顶级域名（gTLD）</strong>，适用于商业网站</td></tr><tr><td><strong>路径（Path）</strong></td><td><code>/robots.txt</code></td><td><strong>指定访问的资源</strong>，此处是 <code>robots.txt</code> 文件，用于爬虫管理</td></tr><tr><td><strong>端口（Port）</strong></td><td><code>443（默认）</code></td><td>HTTPS 的默认端口（如果是 HTTP，则默认端口是 80）</td></tr></tbody></table><h2 id="_3-拼多多" tabindex="-1"><a class="header-anchor" href="#_3-拼多多"><span>3. 拼多多</span></a></h2><figure><img src="`+i+'" alt="image-20250227115041539" tabindex="0" loading="lazy"><figcaption>image-20250227115041539</figcaption></figure><h3 id="_3-1-说明协议内容" tabindex="-1"><a class="header-anchor" href="#_3-1-说明协议内容"><span>3.1 说明协议内容</span></a></h3><p><strong><code>User-agent: Baiduspider-image</code></strong></p><ul><li><code>User-agent</code> 代表 <strong>指定的搜索引擎爬虫</strong>。</li><li><code>Baiduspider-image</code> 是 <strong>百度图片爬虫</strong>，专门用于抓取和索引图片资源，以便在百度图片（<a href="https://image.baidu.com" target="_blank" rel="noopener noreferrer">image.baidu.com</a>）中展示。</li><li>这条规则只针对 <strong>百度图片爬虫</strong>，而不是百度的普通网页爬虫（<code>Baiduspider</code>）。</li></ul><p><strong><code>Disallow: /</code></strong></p><ul><li><code>Disallow</code> 用于 <strong>禁止爬虫访问特定路径</strong>。</li><li><code>/</code> 代表 <strong>整个网站</strong>，即 <strong>禁止 Baiduspider-image 爬取网站的任何内容</strong>。</li></ul>',39)]))}const h=s(r,[["render",d]]),u=JSON.parse('{"path":"/zh/Big_Data/s_ass.html","title":"大数据小作业 01","lang":"zh-CN","frontmatter":{"title":"大数据小作业 01","icon":"alias","date":"2025-02-27T11:24:21.000Z","author":"XiaoXianYue","isOriginal":true,"category":["大三下","大数据"],"tag":["大三下","大数据"],"sticky":false,"star":false,"article":true,"timeline":true,"image":false,"navbar":true,"sidebarIcon":true,"headerDepth":5,"lastUpdated":true,"editLink":false,"backToTop":true,"toc":true,"description":"1. 百度 image-20250227112630712 1.1 说明协议内容 (1) User-agent 指令 User-agent 指定哪些爬虫适用该规则。 百度的 robots.txt 适用于 多个爬虫，包括： Baiduspider（百度爬虫） Googlebot（Google 爬虫） MSNBot（微软必应爬虫） YoudaoBot（有道...","head":[["meta",{"property":"og:url","content":"https://bougiemoonintaurus/zh/Big_Data/s_ass.html"}],["meta",{"property":"og:site_name","content":"奶酪奶酪"}],["meta",{"property":"og:title","content":"大数据小作业 01"}],["meta",{"property":"og:description","content":"1. 百度 image-20250227112630712 1.1 说明协议内容 (1) User-agent 指令 User-agent 指定哪些爬虫适用该规则。 百度的 robots.txt 适用于 多个爬虫，包括： Baiduspider（百度爬虫） Googlebot（Google 爬虫） MSNBot（微软必应爬虫） YoudaoBot（有道..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-03-19T17:01:16.000Z"}],["meta",{"property":"article:author","content":"XiaoXianYue"}],["meta",{"property":"article:tag","content":"大三下"}],["meta",{"property":"article:tag","content":"大数据"}],["meta",{"property":"article:published_time","content":"2025-02-27T11:24:21.000Z"}],["meta",{"property":"article:modified_time","content":"2025-03-19T17:01:16.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"大数据小作业 01\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-02-27T11:24:21.000Z\\",\\"dateModified\\":\\"2025-03-19T17:01:16.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"XiaoXianYue\\"}]}"]]},"git":{"createdTime":1740882999000,"updatedTime":1742403676000,"contributors":[{"name":"Xiaoxianyue","username":"Xiaoxianyue","email":"2310219843@qq.com","commits":2,"url":"https://github.com/Xiaoxianyue"}]},"readingTime":{"minutes":3.65,"words":1095},"filePathRelative":"zh/Big_Data/s_ass.md","localizedDate":"2025年2月27日","excerpt":"<h2>1. 百度</h2>\\n\\n<h3>1.1 说明协议内容</h3>\\n<h4><strong>(1) User-agent 指令</strong></h4>\\n<ul>\\n<li><code>User-agent</code> 指定哪些爬虫适用该规则。</li>\\n<li>百度的 <code>robots.txt</code> 适用于 <strong>多个爬虫</strong>，包括：\\n<ul>\\n<li><code>Baiduspider</code>（百度爬虫）</li>\\n<li><code>Googlebot</code>（Google 爬虫）</li>\\n<li><code>MSNBot</code>（微软必应爬虫）</li>\\n<li><code>YoudaoBot</code>（有道爬虫）</li>\\n<li><code>Sogou inst spider</code>（搜狗爬虫）</li>\\n<li><code>JikeSpider</code>（即刻搜索爬虫）</li>\\n<li><code>Soospider</code>（搜搜爬虫）</li>\\n<li><code>Yisouspider</code>（易搜爬虫）</li>\\n<li><code>EasouSpider</code>（宜搜爬虫）</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}');export{h as comp,u as data};
