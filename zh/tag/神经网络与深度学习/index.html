<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.20" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.74" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://bougiemoonintaurus/zh/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><meta property="og:site_name" content="CHEESE"><meta property="og:title" content="标签: 神经网络与深度学习"><meta property="og:type" content="website"><meta property="og:locale" content="en-US"><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebPage","name":"标签: 神经网络与深度学习"}</script><title>标签: 神经网络与深度学习 | 奶酪奶酪</title><meta name="description" content="CS我跟你爆了">
    <link rel="preload" href="/assets/style-D3YEg4E9.css" as="style"><link rel="stylesheet" href="/assets/style-D3YEg4E9.css">
    <link rel="modulepreload" href="/assets/app-Cc7WVUoo.js"><link rel="modulepreload" href="/assets/index.html-CJSJtnto.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-C7EWwZfE.js" as="script"><link rel="prefetch" href="/assets/bolg.html-BejPReMs.js" as="script"><link rel="prefetch" href="/assets/intro.html-JdONDv30.js" as="script"><link rel="prefetch" href="/assets/MQTT.html-BzRfDsu5.js" as="script"><link rel="prefetch" href="/assets/index.html-rfyr8YRl.js" as="script"><link rel="prefetch" href="/assets/depp.html-aN71QZNb.js" as="script"><link rel="prefetch" href="/assets/intro.html-R3ifjzwf.js" as="script"><link rel="prefetch" href="/assets/Assessed_work.html-DvPhuNuK.js" as="script"><link rel="prefetch" href="/assets/Report.html-BTn0ODoY.js" as="script"><link rel="prefetch" href="/assets/Week01_ass.html-D5GrB24g.js" as="script"><link rel="prefetch" href="/assets/Week02.html-xtgiWU4N.js" as="script"><link rel="prefetch" href="/assets/Week0203.html-BjxkTyyJ.js" as="script"><link rel="prefetch" href="/assets/Week02_ass.html-B6q5gHge.js" as="script"><link rel="prefetch" href="/assets/Week03.html-DNydoPn8.js" as="script"><link rel="prefetch" href="/assets/Week04.html-DjXXRq6w.js" as="script"><link rel="prefetch" href="/assets/Week0405.html-DjKiv6ZR.js" as="script"><link rel="prefetch" href="/assets/Week05.html-BJzfNl9Y.js" as="script"><link rel="prefetch" href="/assets/Week06.html-BOuwsdOJ.js" as="script"><link rel="prefetch" href="/assets/Week0607.html-CIUsnQjD.js" as="script"><link rel="prefetch" href="/assets/Week07.html-BxdIIO-9.js" as="script"><link rel="prefetch" href="/assets/Week08.html-7jsr_hmP.js" as="script"><link rel="prefetch" href="/assets/Week080910.html-CYK5VKkv.js" as="script"><link rel="prefetch" href="/assets/Week09.html-WzAvWJxi.js" as="script"><link rel="prefetch" href="/assets/Week0910.html-DvSOlLSn.js" as="script"><link rel="prefetch" href="/assets/Week10.html-jboqdfF4.js" as="script"><link rel="prefetch" href="/assets/mistakebook.html-CtguVIYT.js" as="script"><link rel="prefetch" href="/assets/summary.html-9_pHwZXJ.js" as="script"><link rel="prefetch" href="/assets/notes.html-CS3vQm28.js" as="script"><link rel="prefetch" href="/assets/s_ass.html-DBcVuStQ.js" as="script"><link rel="prefetch" href="/assets/s_ass01.html-v_Qbc4Ay.js" as="script"><link rel="prefetch" href="/assets/s_ass02.html-DEYQKA_l.js" as="script"><link rel="prefetch" href="/assets/s_ass03.html-DjCUgQDG.js" as="script"><link rel="prefetch" href="/assets/s_ass04.html-CD_M16J4.js" as="script"><link rel="prefetch" href="/assets/s_ass05.html-DALrGPYw.js" as="script"><link rel="prefetch" href="/assets/s_ass06.html-CKLjPo3D.js" as="script"><link rel="prefetch" href="/assets/s_ass07.html-D7P3NTHx.js" as="script"><link rel="prefetch" href="/assets/s_ass08.html-CrkIL_RX.js" as="script"><link rel="prefetch" href="/assets/s_ass09.html-BuphBFMl.js" as="script"><link rel="prefetch" href="/assets/s_ass10.html-ByQV3r7Z.js" as="script"><link rel="prefetch" href="/assets/s_ass11.html-BLNLkL3e.js" as="script"><link rel="prefetch" href="/assets/s_ass12.html-CWSPHbqf.js" as="script"><link rel="prefetch" href="/assets/CS_Class_01.html-CdHUXiI0.js" as="script"><link rel="prefetch" href="/assets/CS_Class_02.html-D_xdiWM1.js" as="script"><link rel="prefetch" href="/assets/CS_Method.html-C0jSmFlQ.js" as="script"><link rel="prefetch" href="/assets/CS_array_string.html-C-nD-K0O.js" as="script"><link rel="prefetch" href="/assets/CS_basic_conception.html-BaM6hztp.js" as="script"><link rel="prefetch" href="/assets/CS_condition_loop.html-CAL0RzMW.js" as="script"><link rel="prefetch" href="/assets/CS_delegate.html-DUyw_Fas.js" as="script"><link rel="prefetch" href="/assets/1.html-BXFCWamj.js" as="script"><link rel="prefetch" href="/assets/2.html-lfGKgUk9.js" as="script"><link rel="prefetch" href="/assets/3.html-DeX-s3qN.js" as="script"><link rel="prefetch" href="/assets/4.html-C-IDRZlQ.js" as="script"><link rel="prefetch" href="/assets/01.html-CI1cSqDf.js" as="script"><link rel="prefetch" href="/assets/02.html-COHFSWzU.js" as="script"><link rel="prefetch" href="/assets/03.html-DVLWNOEU.js" as="script"><link rel="prefetch" href="/assets/04.html-uWp1ifTf.js" as="script"><link rel="prefetch" href="/assets/05.html-hfhJHlJC.js" as="script"><link rel="prefetch" href="/assets/DS_review.html-DbfYOOhS.js" as="script"><link rel="prefetch" href="/assets/01.html-M9qgc9vr.js" as="script"><link rel="prefetch" href="/assets/02.html-B2xwdQ3Y.js" as="script"><link rel="prefetch" href="/assets/03.html-D8muHqb2.js" as="script"><link rel="prefetch" href="/assets/cnn.html-DXVaHoJJ.js" as="script"><link rel="prefetch" href="/assets/dp_api.html-B51eKEhT.js" as="script"><link rel="prefetch" href="/assets/early_stop.html-DusG8ZA4.js" as="script"><link rel="prefetch" href="/assets/mlp_exe.html-fzxSk-dc.js" as="script"><link rel="prefetch" href="/assets/Daily_assignment.html-Oq2kvf3V.js" as="script"><link rel="prefetch" href="/assets/Week01.html-f084vK8c.js" as="script"><link rel="prefetch" href="/assets/Week02.html-m3LjW5NR.js" as="script"><link rel="prefetch" href="/assets/Week03.html-BSfEJwwe.js" as="script"><link rel="prefetch" href="/assets/Week04.html-Du02T2u-.js" as="script"><link rel="prefetch" href="/assets/Week05.html-C1klDZSV.js" as="script"><link rel="prefetch" href="/assets/final_report.html-4b2DLLX5.js" as="script"><link rel="prefetch" href="/assets/assignment.html-DdlcsC2D.js" as="script"><link rel="prefetch" href="/assets/ch02.html-C6fjOx37.js" as="script"><link rel="prefetch" href="/assets/ch03.html-BS9Nd1g-.js" as="script"><link rel="prefetch" href="/assets/ch04.html-IR6u5SkR.js" as="script"><link rel="prefetch" href="/assets/ch05.html-cQa8NPu5.js" as="script"><link rel="prefetch" href="/assets/ch06.html-B9hhBPal.js" as="script"><link rel="prefetch" href="/assets/ch07.html-CIMiwEfC.js" as="script"><link rel="prefetch" href="/assets/ch08.html-BvMbpiRf.js" as="script"><link rel="prefetch" href="/assets/ch09.html-CBQzaP3W.js" as="script"><link rel="prefetch" href="/assets/ch10.html-CQMIAG40.js" as="script"><link rel="prefetch" href="/assets/ch11.html-B943TPNg.js" as="script"><link rel="prefetch" href="/assets/ch12.html-D6cbyYLh.js" as="script"><link rel="prefetch" href="/assets/enreport.html-BUUdmiwW.js" as="script"><link rel="prefetch" href="/assets/re_ve.html-Bwd6hPH5.js" as="script"><link rel="prefetch" href="/assets/report.html-D8IZ3sDM.js" as="script"><link rel="prefetch" href="/assets/sum.html-By9c3JHJ.js" as="script"><link rel="prefetch" href="/assets/01.html-Cz_-l0gn.js" as="script"><link rel="prefetch" href="/assets/02.html-B2M51cn_.js" as="script"><link rel="prefetch" href="/assets/03.html-DAoYqeBY.js" as="script"><link rel="prefetch" href="/assets/04.html-D-DdJ8W1.js" as="script"><link rel="prefetch" href="/assets/exercise.html-CM5vqye9.js" as="script"><link rel="prefetch" href="/assets/question02.html-DSghc34X.js" as="script"><link rel="prefetch" href="/assets/task.html-DD5oqn0C.js" as="script"><link rel="prefetch" href="/assets/A_L.html-B5KJvNGm.js" as="script"><link rel="prefetch" href="/assets/Coventry_Class_01.html-9dmKFitk.js" as="script"><link rel="prefetch" href="/assets/Coventry_Class_02.html-BYVcSV6e.js" as="script"><link rel="prefetch" href="/assets/Coventry_Method.html-BxP49K8E.js" as="script"><link rel="prefetch" href="/assets/Delegates_and_Events.html-CCH0ZFD4.js" as="script"><link rel="prefetch" href="/assets/Generics.html-BlH8swzh.js" as="script"><link rel="prefetch" href="/assets/Inheritance.html-CsFRhNlh.js" as="script"><link rel="prefetch" href="/assets/Interfaces.html-C_1Sw_v4.js" as="script"><link rel="prefetch" href="/assets/review.html-Re1EDM2w.js" as="script"><link rel="prefetch" href="/assets/Agile_01.html-CsR5OdjP.js" as="script"><link rel="prefetch" href="/assets/Agile_02.html-Cbr-GyBY.js" as="script"><link rel="prefetch" href="/assets/Data_modelling.html-BLaM6yfc.js" as="script"><link rel="prefetch" href="/assets/Ethics.html-BzAl2_BV.js" as="script"><link rel="prefetch" href="/assets/Gof.html-Bbli9HVx.js" as="script"><link rel="prefetch" href="/assets/Gof_02.html-QFYj7VSU.js" as="script"><link rel="prefetch" href="/assets/OO_conception.html-CnH8muTF.js" as="script"><link rel="prefetch" href="/assets/OO_principle.html-t7XmGJ7q.js" as="script"><link rel="prefetch" href="/assets/Software_Design.html-Dgdkf9Qg.js" as="script"><link rel="prefetch" href="/assets/Software_Testing.html-C6V2dL9A.js" as="script"><link rel="prefetch" href="/assets/TOEFL_speaking1.html-V2NsV_Yl.js" as="script"><link rel="prefetch" href="/assets/TOEFL_speaking2.html-CQyvXYO_.js" as="script"><link rel="prefetch" href="/assets/TOEFL_speaking3.html-MUMLmabZ.js" as="script"><link rel="prefetch" href="/assets/TOEFL_speaking4.html-DETGr4yt.js" as="script"><link rel="prefetch" href="/assets/TOEFL_writing.html-BObA96gR.js" as="script"><link rel="prefetch" href="/assets/accumulation.html-CuBwERrd.js" as="script"><link rel="prefetch" href="/assets/ad_wr.html-__tWFJH4.js" as="script"><link rel="prefetch" href="/assets/assi_dairy.html-hwCG58Jd.js" as="script"><link rel="prefetch" href="/assets/listen_class.html-if3rqOHf.js" as="script"><link rel="prefetch" href="/assets/logical_chain.html-j47c5THg.js" as="script"><link rel="prefetch" href="/assets/question.html-_LXsM_6s.js" as="script"><link rel="prefetch" href="/assets/reading.html-DEKBGj_M.js" as="script"><link rel="prefetch" href="/assets/reading01.html-9_qJtzpK.js" as="script"><link rel="prefetch" href="/assets/reading02.html-D5FHZU42.js" as="script"><link rel="prefetch" href="/assets/spclass.html-BoHbrSA2.js" as="script"><link rel="prefetch" href="/assets/spk_mtrl.html-BN1oYZRo.js" as="script"><link rel="prefetch" href="/assets/translation_training.html-DMfKd3ge.js" as="script"><link rel="prefetch" href="/assets/wr_class.html-ZBigIxBB.js" as="script"><link rel="prefetch" href="/assets/wr_mistake.html-DdNb_IBH.js" as="script"><link rel="prefetch" href="/assets/Aricultural_Bank_of_China.html-nXpbYm0C.js" as="script"><link rel="prefetch" href="/assets/istarshine.html-ZCSD6ygX.js" as="script"><link rel="prefetch" href="/assets/istarshine01.html-Bhjphn11.js" as="script"><link rel="prefetch" href="/assets/Data-type.html-DxZ46J3D.js" as="script"><link rel="prefetch" href="/assets/Dictionary.html-qU9y1smV.js" as="script"><link rel="prefetch" href="/assets/Document.html-DlLqk_Bs.js" as="script"><link rel="prefetch" href="/assets/For.html-B8GK-qHc.js" as="script"><link rel="prefetch" href="/assets/Homework1.html-DNgFkzAT.js" as="script"><link rel="prefetch" href="/assets/If_Homework.html-Bug57XQP.js" as="script"><link rel="prefetch" href="/assets/List.html-VwGcdKch.js" as="script"><link rel="prefetch" href="/assets/List_Homework.html-bBTpWg4P.js" as="script"><link rel="prefetch" href="/assets/Numeric.html-DCVoiQtN.js" as="script"><link rel="prefetch" href="/assets/Set.html-BrLzZGm5.js" as="script"><link rel="prefetch" href="/assets/String.html-BFAoA-Vi.js" as="script"><link rel="prefetch" href="/assets/String_Homework.html-Vmyl20Ad.js" as="script"><link rel="prefetch" href="/assets/Variable.html-C2dfbl8o.js" as="script"><link rel="prefetch" href="/assets/While.html-BmIdk9ej.js" as="script"><link rel="prefetch" href="/assets/bool.html-eNh7X17P.js" as="script"><link rel="prefetch" href="/assets/function.html-BO8ZWR05.js" as="script"><link rel="prefetch" href="/assets/if.html-BXlXu3JB.js" as="script"><link rel="prefetch" href="/assets/recursion.html-MAVO5Ej1.js" as="script"><link rel="prefetch" href="/assets/tuple.html-Brp9YH3v.js" as="script"><link rel="prefetch" href="/assets/404.html-CCPNkaXn.js" as="script"><link rel="prefetch" href="/assets/index.html-9pC_zTeB.js" as="script"><link rel="prefetch" href="/assets/index.html-DKxA6z52.js" as="script"><link rel="prefetch" href="/assets/index.html-DHCHWJuT.js" as="script"><link rel="prefetch" href="/assets/index.html-BvwP0h_A.js" as="script"><link rel="prefetch" href="/assets/index.html-sQIrS6YM.js" as="script"><link rel="prefetch" href="/assets/index.html-BYBovtWz.js" as="script"><link rel="prefetch" href="/assets/index.html-DZCz4T49.js" as="script"><link rel="prefetch" href="/assets/index.html-jTGKsTAx.js" as="script"><link rel="prefetch" href="/assets/index.html-Hqj25omX.js" as="script"><link rel="prefetch" href="/assets/index.html-Bh_YOIPq.js" as="script"><link rel="prefetch" href="/assets/index.html-BBFapXlQ.js" as="script"><link rel="prefetch" href="/assets/index.html-CREkFa3q.js" as="script"><link rel="prefetch" href="/assets/index.html-c1_kmK2k.js" as="script"><link rel="prefetch" href="/assets/index.html-B59fsqvr.js" as="script"><link rel="prefetch" href="/assets/index.html-qd1PjqI9.js" as="script"><link rel="prefetch" href="/assets/index.html-BtkDBgg5.js" as="script"><link rel="prefetch" href="/assets/index.html-Cg66ApwQ.js" as="script"><link rel="prefetch" href="/assets/index.html-DDKOpbjr.js" as="script"><link rel="prefetch" href="/assets/index.html-Cdf8ZDXg.js" as="script"><link rel="prefetch" href="/assets/index.html-DadJxEuU.js" as="script"><link rel="prefetch" href="/assets/index.html-COs05ju4.js" as="script"><link rel="prefetch" href="/assets/index.html-Cq0f1EWi.js" as="script"><link rel="prefetch" href="/assets/index.html-BIJcZsdb.js" as="script"><link rel="prefetch" href="/assets/index.html-CedNceX2.js" as="script"><link rel="prefetch" href="/assets/index.html-CrTSI2gj.js" as="script"><link rel="prefetch" href="/assets/index.html-B2-wYywE.js" as="script"><link rel="prefetch" href="/assets/index.html-DyNRhR46.js" as="script"><link rel="prefetch" href="/assets/index.html-BHKTAInY.js" as="script"><link rel="prefetch" href="/assets/index.html-CWHQYCfF.js" as="script"><link rel="prefetch" href="/assets/index.html-BwtsKttS.js" as="script"><link rel="prefetch" href="/assets/index.html-SABSiNVR.js" as="script"><link rel="prefetch" href="/assets/index.html-CqB2udl-.js" as="script"><link rel="prefetch" href="/assets/index.html-BvXdGDfO.js" as="script"><link rel="prefetch" href="/assets/index.html-CYMpZUUA.js" as="script"><link rel="prefetch" href="/assets/index.html-7ggnehWu.js" as="script"><link rel="prefetch" href="/assets/index.html-CdkF54fh.js" as="script"><link rel="prefetch" href="/assets/index.html-CJnjUd6j.js" as="script"><link rel="prefetch" href="/assets/index.html-KWWeX0oh.js" as="script"><link rel="prefetch" href="/assets/index.html-bWCg3z4A.js" as="script"><link rel="prefetch" href="/assets/index.html-DfiyQmuf.js" as="script"><link rel="prefetch" href="/assets/index.html-ty-ggqfw.js" as="script"><link rel="prefetch" href="/assets/index.html-CtO-tulG.js" as="script"><link rel="prefetch" href="/assets/index.html-BmRJOcq5.js" as="script"><link rel="prefetch" href="/assets/index.html-7q9Gqthw.js" as="script"><link rel="prefetch" href="/assets/index.html-rwo36xPF.js" as="script"><link rel="prefetch" href="/assets/index.html-IzOBk07N.js" as="script"><link rel="prefetch" href="/assets/index.html-CP0VV1M1.js" as="script"><link rel="prefetch" href="/assets/index.html-CLvfkf28.js" as="script"><link rel="prefetch" href="/assets/index.html-w0NMn3SD.js" as="script"><link rel="prefetch" href="/assets/index.html-DGVE7_Gx.js" as="script"><link rel="prefetch" href="/assets/index.html-Dz5cZnzy.js" as="script"><link rel="prefetch" href="/assets/index.html-DMU2lBwt.js" as="script"><link rel="prefetch" href="/assets/index.html-mob4Ie7l.js" as="script"><link rel="prefetch" href="/assets/index.html-DIlviy5z.js" as="script"><link rel="prefetch" href="/assets/index.html-BLJBOM-Z.js" as="script"><link rel="prefetch" href="/assets/index.html-BWWwFxFd.js" as="script"><link rel="prefetch" href="/assets/index.html-DMZ-fEnX.js" as="script"><link rel="prefetch" href="/assets/index.html-Cw5EmR7w.js" as="script"><link rel="prefetch" href="/assets/index.html-D8p623hb.js" as="script"><link rel="prefetch" href="/assets/index.html-Bwpdhxqu.js" as="script"><link rel="prefetch" href="/assets/index.html-CJ95Ox2K.js" as="script"><link rel="prefetch" href="/assets/index.html-ClHxLfi7.js" as="script"><link rel="prefetch" href="/assets/index.html-m34uqxrL.js" as="script"><link rel="prefetch" href="/assets/index.html-DjPzi_qA.js" as="script"><link rel="prefetch" href="/assets/index.html-RYDlHQYG.js" as="script"><link rel="prefetch" href="/assets/index.html-DIeWHsx9.js" as="script"><link rel="prefetch" href="/assets/index.html-ClkgMYW_.js" as="script"><link rel="prefetch" href="/assets/index.html-Bk2LBlcl.js" as="script"><link rel="prefetch" href="/assets/index.html-DNLEAqZF.js" as="script"><link rel="prefetch" href="/assets/index.html-CN2X_ePo.js" as="script"><link rel="prefetch" href="/assets/index.html-NOF_9_Uw.js" as="script"><link rel="prefetch" href="/assets/index.html-DM8CoWxH.js" as="script"><link rel="prefetch" href="/assets/index.html-CcTCz1Kd.js" as="script"><link rel="prefetch" href="/assets/index.html-DY7Rwe5_.js" as="script"><link rel="prefetch" href="/assets/index.html-BPs9qp29.js" as="script"><link rel="prefetch" href="/assets/index.html-CPiNeYfN.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-DXWKOczD.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container no-sidebar external-link-icon" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/zh/" aria-label="带我回家"><img class="vp-nav-logo" src="/logo.jpg" alt><!----><span class="vp-site-name hide-in-pad">奶酪奶酪</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/zh/" aria-label="MMoon" iconsizing="height"><!--[--><i class="vp-icon iconfont icon-home" sizing="height"></i><!--]-->MMoon<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/#" aria-label="学校科目" iconsizing="height"><!--[--><i class="vp-icon iconfont icon-style" sizing="height"></i><!--]-->学校科目<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="编程语言"><!--[--><i class="vp-icon iconfont icon-editor" sizing="height"></i>编程语言<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Python</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/" aria-label="课堂笔记" iconsizing="both"><!---->课堂笔记<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">c#</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/#" aria-label="oop" iconsizing="both"><!--[--><i class="vp-icon iconfont icon-xxx" sizing="both"></i><!--]-->oop<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="小猫" iconsizing="height"><!--[--><i class="vp-icon iconfont icon-github" sizing="height"></i><!--]-->小猫<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="选择语言"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/" aria-label="English" iconsizing="both"><!---->English<!----></a></li><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/zh/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" aria-label="简体中文" iconsizing="both"><!---->简体中文<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/Xiaoxianyue/Xiaoxianyue.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><form class="search-box" role="search"><input type="search" placeholder="搜索" autocomplete="off" spellcheck="false" value><!----></form><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/" aria-label="MMoon" iconsizing="both"><!--[--><i class="vp-icon iconfont icon-home" sizing="both"></i><!--]-->MMoon<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/depp.html" aria-label="/zh/depp.html" iconsizing="both"><!---->/zh/depp.html<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Advanced Algorithms</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Big Data</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">CS</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Data Analysis</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Data Structure</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Deep Thinking</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Diary</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Internship</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Java Homework</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Machine Learning</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/MQTT.html" aria-label="MQTT" iconsizing="both"><!--[--><i class="vp-icon iconfont icon-alias" sizing="both"></i><!--]-->MQTT<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">NLP</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">OOP</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Python1v1</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Software Design</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">TOEFL</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/intro.html" aria-label="介绍页" iconsizing="both"><!--[--><i class="vp-icon iconfont icon-circle-info" sizing="both"></i><!--]-->介绍页<!----></a></li></ul><!----></aside><!--[--><div class="vp-page vp-blog"><div class="blog-page-wrapper"><main id="main-content" class="vp-blog-main"><ul class="vp-tag-list"><li class="vp-tag-item"><a class="route-link vp-tag color8" href="/zh/tag/%E5%A4%A7%E4%B8%89%E4%B8%8A/">大三上<span class="vp-tag-count">40</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color5" href="/zh/tag/%E5%A4%A7%E4%BA%8C%E4%B8%8B/">大二下<span class="vp-tag-count">39</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color0" href="/zh/tag/%E5%A4%A7%E4%B8%89%E4%B8%8B/">大三下<span class="vp-tag-count">27</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color2" href="/zh/tag/%E6%89%98%E7%A6%8F%E5%AD%A6%E4%B9%A0/">托福学习<span class="vp-tag-count">19</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color1" href="/zh/tag/%E9%AB%98%E7%BA%A7%E7%AE%97%E6%B3%95%E8%AF%BE%E4%BB%B6/">高级算法课件<span class="vp-tag-count">16</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color0" href="/zh/tag/c_/">C#<span class="vp-tag-count">16</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color1" href="/zh/tag/%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/">课堂笔记<span class="vp-tag-count">15</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color0" href="/zh/tag/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据<span class="vp-tag-count">13</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color8" href="/zh/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E4%BB%B6%E6%A2%B3%E7%90%86/">机器学习课件梳理<span class="vp-tag-count">13</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color6" href="/zh/tag/python/">Python<span class="vp-tag-count">10</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color7" href="/zh/tag/%E6%96%B0%E4%B8%9C%E6%96%B9%E6%89%98%E7%A6%8F%E7%AC%94%E8%AE%B0/">新东方托福笔记<span class="vp-tag-count">9</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color2" href="/zh/tag/nlp/">NLP<span class="vp-tag-count">7</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color5" href="/zh/tag/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构<span class="vp-tag-count">6</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color4 active" href="/zh/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">神经网络与深度学习<span class="vp-tag-count">6</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color0" href="/zh/tag/%E8%AE%BA%E6%96%87/">论文<span class="vp-tag-count">5</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color8" href="/zh/tag/java/">Java<span class="vp-tag-count">5</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color7" href="/zh/tag/%E5%A4%9A%E5%85%83%E7%BB%9F%E8%AE%A1%E4%B8%8E%E6%95%B0%E5%AD%97%E5%88%86%E6%9E%90/">多元统计与数字分析<span class="vp-tag-count">4</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color7" href="/zh/tag/%E8%AF%BE%E5%90%8E%E5%9B%9E%E9%A1%BE_%E7%BB%83%E4%B9%A0/">课后回顾&amp;练习<span class="vp-tag-count">4</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color3" href="/zh/tag/%E9%AB%98%E7%BA%A7%E7%AE%97%E6%B3%95%E5%A4%A7%E4%BD%9C%E4%B8%9A/">高级算法大作业<span class="vp-tag-count">2</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color5" href="/zh/tag/%E9%AB%98%E7%BA%A7%E7%AE%97%E6%B3%95%E4%BD%9C%E4%B8%9A/">高级算法作业<span class="vp-tag-count">2</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color0" href="/zh/tag/%E6%99%BA%E6%85%A7%E6%98%9F%E5%85%89%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AE%B0/">智慧星光实习笔记<span class="vp-tag-count">2</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color0" href="/zh/tag/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">大模型与深度学习<span class="vp-tag-count">1</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color5" href="/zh/tag/%E6%97%A5%E8%AE%B0/">日记<span class="vp-tag-count">1</span></a></li><li class="vp-tag-item"><a class="route-link vp-tag color3" href="/zh/tag/%E4%B8%AD%E5%9B%BD%E5%86%9C%E4%B8%9A%E9%93%B6%E8%A1%8C%E5%AE%9E%E4%B9%A0%E7%AC%94%E8%AE%B0/">中国农业银行实习笔记<span class="vp-tag-count">1</span></a></li></ul><div id="article-list" class="vp-article-list" role="feed"><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/zh/DeepThinking/cnn.html"><header class="vp-article-title"><!----><!----><span property="headline">卷积神经网络</span></header></a><div class="vp-article-excerpt"><h3>Task 01</h3>
<blockquote>
<p>替换平均池化（AvgPool）为最大池化（MaxPool），并输出结果。</p>
</blockquote>
<h4>代码</h4>
<div class="language-python line-numbers-mode has-collapsed-lines collapsed" data-highlighter="shiki" data-ext="python" style="--vp-collapsed-lines:15;background-color:#272822;color:#F8F8F2"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> torch</span></span>
<span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> torch.nn </span><span style="color:#F92672">as</span><span style="color:#F8F8F2"> nn</span></span>
<span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> torch.optim </span><span style="color:#F92672">as</span><span style="color:#F8F8F2"> optim</span></span>
<span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> torchvision</span></span>
<span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> torchvision.transforms </span><span style="color:#F92672">as</span><span style="color:#F8F8F2"> transforms</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># --------------------- 1. 定义 LeNet 网络 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">class</span><span> </span><span style="color:#A6E22E;text-decoration:underline">LeNet</span><span style="color:#F8F8F2">(</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline">nn</span><span style="color:#F8F8F2">.</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline">Module</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">    def</span><span style="color:#66D9EF"> __init__</span><span style="color:#F8F8F2">(</span><span style="color:#FD971F;font-style:italic">self</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">use_maxpool</span><span style="color:#F92672">=</span><span style="color:#AE81FF">True</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">        super</span><span style="color:#F8F8F2">(LeNet, </span><span style="color:#FD971F">self</span><span style="color:#F8F8F2">).</span><span style="color:#66D9EF">__init__</span><span style="color:#F8F8F2">()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F">        # 卷积层</span></span>
<span class="line"><span style="color:#FD971F">        self</span><span style="color:#F8F8F2">.conv1 </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> nn.Conv2d(</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">6</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">kernel_size</span><span style="color:#F92672">=</span><span style="color:#AE81FF">5</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">padding</span><span style="color:#F92672">=</span><span style="color:#AE81FF">2</span><span style="color:#F8F8F2">)  </span><span style="color:#88846F"># 28x28 -&gt; 28x28</span></span>
<span class="line"><span style="color:#FD971F">        self</span><span style="color:#F8F8F2">.conv2 </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> nn.Conv2d(</span><span style="color:#AE81FF">6</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">16</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">kernel_size</span><span style="color:#F92672">=</span><span style="color:#AE81FF">5</span><span style="color:#F8F8F2">)  </span><span style="color:#88846F"># 14x14 -&gt; 10x10</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F">        # 选择池化方式（默认使用 MaxPool）</span></span>
<span class="line"><span style="color:#FD971F">        self</span><span style="color:#F8F8F2">.pool </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> nn.MaxPool2d(</span><span style="color:#FD971F;font-style:italic">kernel_size</span><span style="color:#F92672">=</span><span style="color:#AE81FF">2</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">stride</span><span style="color:#F92672">=</span><span style="color:#AE81FF">2</span><span style="color:#F8F8F2">) </span><span style="color:#F92672">if</span><span style="color:#F8F8F2"> use_maxpool </span><span style="color:#F92672">else</span><span style="color:#F8F8F2"> nn.AvgPool2d(</span><span style="color:#FD971F;font-style:italic">kernel_size</span><span style="color:#F92672">=</span><span style="color:#AE81FF">2</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">stride</span><span style="color:#F92672">=</span><span style="color:#AE81FF">2</span><span style="color:#F8F8F2">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F">        # 全连接层</span></span>
<span class="line"><span style="color:#FD971F">        self</span><span style="color:#F8F8F2">.fc1 </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> nn.Linear(</span><span style="color:#AE81FF">16</span><span style="color:#F92672"> *</span><span style="color:#AE81FF"> 5</span><span style="color:#F92672"> *</span><span style="color:#AE81FF"> 5</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">120</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#FD971F">        self</span><span style="color:#F8F8F2">.fc2 </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> nn.Linear(</span><span style="color:#AE81FF">120</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">84</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#FD971F">        self</span><span style="color:#F8F8F2">.fc3 </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> nn.Linear(</span><span style="color:#AE81FF">84</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">10</span><span style="color:#F8F8F2">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">    def</span><span style="color:#A6E22E"> forward</span><span style="color:#F8F8F2">(</span><span style="color:#FD971F;font-style:italic">self</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">x</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#F8F8F2">        x </span><span style="color:#F92672">=</span><span style="color:#FD971F"> self</span><span style="color:#F8F8F2">.pool(torch.relu(</span><span style="color:#FD971F">self</span><span style="color:#F8F8F2">.conv1(x)))  </span><span style="color:#88846F"># 第一层卷积 + ReLU + 池化</span></span>
<span class="line"><span style="color:#F8F8F2">        x </span><span style="color:#F92672">=</span><span style="color:#FD971F"> self</span><span style="color:#F8F8F2">.pool(torch.relu(</span><span style="color:#FD971F">self</span><span style="color:#F8F8F2">.conv2(x)))  </span><span style="color:#88846F"># 第二层卷积 + ReLU + 池化</span></span>
<span class="line"><span style="color:#F8F8F2">        x </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.flatten(x, </span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">)  </span><span style="color:#88846F"># 展平</span></span>
<span class="line"><span style="color:#F8F8F2">        x </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.relu(</span><span style="color:#FD971F">self</span><span style="color:#F8F8F2">.fc1(x))</span></span>
<span class="line"><span style="color:#F8F8F2">        x </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.relu(</span><span style="color:#FD971F">self</span><span style="color:#F8F8F2">.fc2(x))</span></span>
<span class="line"><span style="color:#F8F8F2">        x </span><span style="color:#F92672">=</span><span style="color:#FD971F"> self</span><span style="color:#F8F8F2">.fc3(x)  </span><span style="color:#88846F"># 最终输出 10 维</span></span>
<span class="line"><span style="color:#F92672">        return</span><span style="color:#F8F8F2"> x</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># --------------------- 2. 载入 MNIST 数据集 ---------------------</span></span>
<span class="line"><span style="color:#F8F8F2">mnist_data_path </span><span style="color:#F92672">=</span><span style="color:#E6DB74"> "D:/603/pythonProject/data/MNIST/"</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">transform </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> transforms.Compose([</span></span>
<span class="line"><span style="color:#F8F8F2">    transforms.Grayscale(),</span></span>
<span class="line"><span style="color:#F8F8F2">    transforms.ToTensor(),</span></span>
<span class="line"><span style="color:#F8F8F2">    transforms.Normalize((</span><span style="color:#AE81FF">0.5</span><span style="color:#F8F8F2">,), (</span><span style="color:#AE81FF">0.5</span><span style="color:#F8F8F2">,))  </span><span style="color:#88846F"># 归一化到 [-1, 1]</span></span>
<span class="line"><span style="color:#F8F8F2">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># 加载训练和测试数据</span></span>
<span class="line"><span style="color:#F8F8F2">trainset </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torchvision.datasets.MNIST(</span><span style="color:#FD971F;font-style:italic">root</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">mnist_data_path, </span><span style="color:#FD971F;font-style:italic">train</span><span style="color:#F92672">=</span><span style="color:#AE81FF">True</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">download</span><span style="color:#F92672">=</span><span style="color:#AE81FF">False</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">transform</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">transform)</span></span>
<span class="line"><span style="color:#F8F8F2">testset </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torchvision.datasets.MNIST(</span><span style="color:#FD971F;font-style:italic">root</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">mnist_data_path, </span><span style="color:#FD971F;font-style:italic">train</span><span style="color:#F92672">=</span><span style="color:#AE81FF">False</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">download</span><span style="color:#F92672">=</span><span style="color:#AE81FF">False</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">transform</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">transform)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">train_loader </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.utils.data.DataLoader(trainset, </span><span style="color:#FD971F;font-style:italic">batch_size</span><span style="color:#F92672">=</span><span style="color:#AE81FF">64</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">shuffle</span><span style="color:#F92672">=</span><span style="color:#AE81FF">True</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">test_loader </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.utils.data.DataLoader(testset, </span><span style="color:#FD971F;font-style:italic">batch_size</span><span style="color:#F92672">=</span><span style="color:#AE81FF">64</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">shuffle</span><span style="color:#F92672">=</span><span style="color:#AE81FF">False</span><span style="color:#F8F8F2">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># --------------------- 3. 训练模型 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">def</span><span style="color:#A6E22E"> train_model</span><span style="color:#F8F8F2">(</span><span style="color:#FD971F;font-style:italic">model</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">train_loader</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">epochs</span><span style="color:#F92672">=</span><span style="color:#AE81FF">5</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">learning_rate</span><span style="color:#F92672">=</span><span style="color:#AE81FF">0.001</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#F8F8F2">    device </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.device(</span><span style="color:#E6DB74">"cuda"</span><span style="color:#F92672"> if</span><span style="color:#F8F8F2"> torch.cuda.is_available() </span><span style="color:#F92672">else</span><span style="color:#E6DB74"> "cpu"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">    model.to(device)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">    criterion </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> nn.CrossEntropyLoss()</span></span>
<span class="line"><span style="color:#F8F8F2">    optimizer </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> optim.Adam(model.parameters(), </span><span style="color:#FD971F;font-style:italic">lr</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">learning_rate)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F92672">    for</span><span style="color:#F8F8F2"> epoch </span><span style="color:#F92672">in</span><span style="color:#66D9EF"> range</span><span style="color:#F8F8F2">(epochs):</span></span>
<span class="line"><span style="color:#F8F8F2">        model.train()</span></span>
<span class="line"><span style="color:#F8F8F2">        running_loss </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 0.0</span></span>
<span class="line"><span style="color:#F92672">        for</span><span style="color:#F8F8F2"> images, labels </span><span style="color:#F92672">in</span><span style="color:#F8F8F2"> train_loader:</span></span>
<span class="line"><span style="color:#F8F8F2">            images, labels </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> images.to(device), labels.to(device)</span></span>
<span class="line"><span style="color:#F8F8F2">            optimizer.zero_grad()</span></span>
<span class="line"><span style="color:#F8F8F2">            outputs </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> model(images)</span></span>
<span class="line"><span style="color:#F8F8F2">            loss </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> criterion(outputs, labels)</span></span>
<span class="line"><span style="color:#F8F8F2">            loss.backward()</span></span>
<span class="line"><span style="color:#F8F8F2">            optimizer.step()</span></span>
<span class="line"><span style="color:#F8F8F2">            running_loss </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> loss.item()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF">        print</span><span style="color:#F8F8F2">(</span><span style="color:#66D9EF;font-style:italic">f</span><span style="color:#E6DB74">"Epoch </span><span style="color:#AE81FF">{</span><span style="color:#F8F8F2">epoch </span><span style="color:#F92672">+</span><span style="color:#AE81FF"> 1}</span><span style="color:#E6DB74">, Loss: </span><span style="color:#AE81FF">{</span><span style="color:#F8F8F2">running_loss </span><span style="color:#F92672">/</span><span style="color:#66D9EF"> len</span><span style="color:#F8F8F2">(train_loader)</span><span style="color:#66D9EF;font-style:italic">:.4f</span><span style="color:#AE81FF">}</span><span style="color:#E6DB74">"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># --------------------- 4. 评估模型 ---------------------</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">def</span><span style="color:#A6E22E"> evaluate_model</span><span style="color:#F8F8F2">(</span><span style="color:#FD971F;font-style:italic">model</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">test_loader</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#F8F8F2">    device </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.device(</span><span style="color:#E6DB74">"cuda"</span><span style="color:#F92672"> if</span><span style="color:#F8F8F2"> torch.cuda.is_available() </span><span style="color:#F92672">else</span><span style="color:#E6DB74"> "cpu"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">    model.to(device)</span></span>
<span class="line"><span style="color:#F8F8F2">    model.eval()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">    correct, total </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 0</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">0</span></span>
<span class="line"><span style="color:#F92672">    with</span><span style="color:#F8F8F2"> torch.no_grad():</span></span>
<span class="line"><span style="color:#F92672">        for</span><span style="color:#F8F8F2"> images, labels </span><span style="color:#F92672">in</span><span style="color:#F8F8F2"> test_loader:</span></span>
<span class="line"><span style="color:#F8F8F2">            images, labels </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> images.to(device), labels.to(device)</span></span>
<span class="line"><span style="color:#F8F8F2">            outputs </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> model(images)</span></span>
<span class="line"><span style="color:#F8F8F2">            _, predicted </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.max(outputs, </span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">            total </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> labels.size(</span><span style="color:#AE81FF">0</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">            correct </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> (predicted </span><span style="color:#F92672">==</span><span style="color:#F8F8F2"> labels).sum().item()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF">    print</span><span style="color:#F8F8F2">(</span><span style="color:#66D9EF;font-style:italic">f</span><span style="color:#E6DB74">"Test Accuracy: </span><span style="color:#AE81FF">{100</span><span style="color:#F92672"> *</span><span style="color:#F8F8F2"> correct </span><span style="color:#F92672">/</span><span style="color:#F8F8F2"> total</span><span style="color:#66D9EF;font-style:italic">:.2f</span><span style="color:#AE81FF">}</span><span style="color:#E6DB74">%"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># --------------------- 5. 运行实验 ---------------------</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># 训练并评估使用平均池化的 LeNet</span></span>
<span class="line"><span style="color:#66D9EF">print</span><span style="color:#F8F8F2">(</span><span style="color:#E6DB74">"</span><span style="color:#AE81FF">\n</span><span style="color:#E6DB74">Training LeNet with Average Pooling..."</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">lenet_avg </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> LeNet(</span><span style="color:#FD971F;font-style:italic">use_maxpool</span><span style="color:#F92672">=</span><span style="color:#AE81FF">False</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">train_model(lenet_avg, train_loader, </span><span style="color:#FD971F;font-style:italic">epochs</span><span style="color:#F92672">=</span><span style="color:#AE81FF">5</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">learning_rate</span><span style="color:#F92672">=</span><span style="color:#AE81FF">0.001</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#66D9EF">print</span><span style="color:#F8F8F2">(</span><span style="color:#E6DB74">"</span><span style="color:#AE81FF">\n</span><span style="color:#E6DB74">Evaluating LeNet with Average Pooling..."</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">evaluate_model(lenet_avg, test_loader)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># 训练并评估使用最大池化的 LeNet</span></span>
<span class="line"><span style="color:#66D9EF">print</span><span style="color:#F8F8F2">(</span><span style="color:#E6DB74">"</span><span style="color:#AE81FF">\n</span><span style="color:#E6DB74">Training LeNet with Max Pooling..."</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">lenet_max </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> LeNet(</span><span style="color:#FD971F;font-style:italic">use_maxpool</span><span style="color:#F92672">=</span><span style="color:#AE81FF">True</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">train_model(lenet_max, train_loader, </span><span style="color:#FD971F;font-style:italic">epochs</span><span style="color:#F92672">=</span><span style="color:#AE81FF">5</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">learning_rate</span><span style="color:#F92672">=</span><span style="color:#AE81FF">0.001</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#66D9EF">print</span><span style="color:#F8F8F2">(</span><span style="color:#E6DB74">"</span><span style="color:#AE81FF">\n</span><span style="color:#E6DB74">Evaluating LeNet with Max Pooling..."</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">evaluate_model(lenet_max, test_loader)</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div><div class="collapsed-lines"></div></div></div><hr class="vp-article-hr"><!----></article></div><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/zh/DeepThinking/03.html"><header class="vp-article-title"><!----><!----><span property="headline">CNN:Basic components and LeNet</span></header></a><div class="vp-article-excerpt"><h2>卷积</h2>
<h3>计算过程</h3>

<ul>
<li>The weight matrix for the convolution, which is the white square in the middle of the figure，but in regular calculation, there is a bias</li>
</ul>
<h3>Padding-classification</h3>
<figure><figcaption>image-20250318104245806</figcaption></figure>
<ul>
<li>That is to say, the size of the convolutional kernel need to fit the convolution area.</li>
</ul></div><hr class="vp-article-hr"><!----></article></div><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/zh/DeepThinking/early_stop.html"><header class="vp-article-title"><!----><!----><span property="headline">早停调参</span></header></a><div class="vp-article-excerpt"><h2>Task 01</h2>
<blockquote>
<p>According to the referenced code related to weight decay, plot the functions of the training loss and the test loss with respect to λ</p>
</blockquote>
<h3>代码</h3>
<div class="language-python line-numbers-mode has-collapsed-lines collapsed" data-highlighter="shiki" data-ext="python" style="--vp-collapsed-lines:15;background-color:#272822;color:#F8F8F2"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> torch</span></span>
<span class="line"><span style="color:#F92672">from</span><span style="color:#F8F8F2"> torch </span><span style="color:#F92672">import</span><span style="color:#F8F8F2"> nn</span></span>
<span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> torchvision</span></span>
<span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> torchvision.transforms </span><span style="color:#F92672">as</span><span style="color:#F8F8F2"> transforms</span></span>
<span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> matplotlib.pyplot </span><span style="color:#F92672">as</span><span style="color:#F8F8F2"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># 设定超参数</span></span>
<span class="line"><span style="color:#F8F8F2">batch_size </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 256</span></span>
<span class="line"><span style="color:#F8F8F2">num_inputs, num_outputs </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 784</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">10</span></span>
<span class="line"><span style="color:#F8F8F2">num_hiddens </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 128</span></span>
<span class="line"><span style="color:#F8F8F2">num_layers </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 2</span></span>
<span class="line"><span style="color:#F8F8F2">learning_rate </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 0.1</span></span>
<span class="line"><span style="color:#F8F8F2">num_epochs </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 10</span></span>
<span class="line"><span style="color:#F8F8F2">lambda_values </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> [</span><span style="color:#AE81FF">0</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">0.0001</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">0.001</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">0.01</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">0.1</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">]  </span><span style="color:#88846F"># 不同的权重衰减系数 λ</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># 预处理 FashionMNIST 数据集</span></span>
<span class="line"><span style="color:#F8F8F2">transform </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> transforms.Compose([transforms.ToTensor()])</span></span>
<span class="line"><span style="color:#F8F8F2">train_dataset </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torchvision.datasets.FashionMNIST(</span><span style="color:#FD971F;font-style:italic">root</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"./data"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">train</span><span style="color:#F92672">=</span><span style="color:#AE81FF">True</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">transform</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">transform, </span><span style="color:#FD971F;font-style:italic">download</span><span style="color:#F92672">=</span><span style="color:#AE81FF">True</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">test_dataset </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torchvision.datasets.FashionMNIST(</span><span style="color:#FD971F;font-style:italic">root</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"./data"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">train</span><span style="color:#F92672">=</span><span style="color:#AE81FF">False</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">transform</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">transform, </span><span style="color:#FD971F;font-style:italic">download</span><span style="color:#F92672">=</span><span style="color:#AE81FF">True</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">train_loader </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.utils.data.DataLoader(train_dataset, </span><span style="color:#FD971F;font-style:italic">batch_size</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">batch_size, </span><span style="color:#FD971F;font-style:italic">shuffle</span><span style="color:#F92672">=</span><span style="color:#AE81FF">True</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">test_loader </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.utils.data.DataLoader(test_dataset, </span><span style="color:#FD971F;font-style:italic">batch_size</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">batch_size, </span><span style="color:#FD971F;font-style:italic">shuffle</span><span style="color:#F92672">=</span><span style="color:#AE81FF">False</span><span style="color:#F8F8F2">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># 定义 MLP 网络</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">class</span><span> </span><span style="color:#A6E22E;text-decoration:underline">MLP</span><span style="color:#F8F8F2">(</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline">nn</span><span style="color:#F8F8F2">.</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline">Module</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">    def</span><span style="color:#66D9EF"> __init__</span><span style="color:#F8F8F2">(</span><span style="color:#FD971F;font-style:italic">self</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">num_inputs</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">num_hiddens</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">num_outputs</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">num_layers</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">        super</span><span style="color:#F8F8F2">(</span><span style="color:#AE81FF">MLP</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F">self</span><span style="color:#F8F8F2">).</span><span style="color:#66D9EF">__init__</span><span style="color:#F8F8F2">()</span></span>
<span class="line"><span style="color:#F8F8F2">        layers </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> []</span></span>
<span class="line"><span style="color:#F8F8F2">        layers.append(nn.Linear(num_inputs, num_hiddens))</span></span>
<span class="line"><span style="color:#F8F8F2">        layers.append(nn.ReLU())</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F92672">        for</span><span style="color:#F8F8F2"> _ </span><span style="color:#F92672">in</span><span style="color:#66D9EF"> range</span><span style="color:#F8F8F2">(num_layers </span><span style="color:#F92672">-</span><span style="color:#AE81FF"> 1</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#F8F8F2">            layers.append(nn.Linear(num_hiddens, num_hiddens))</span></span>
<span class="line"><span style="color:#F8F8F2">            layers.append(nn.ReLU())</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">        layers.append(nn.Linear(num_hiddens, num_outputs))</span></span>
<span class="line"><span style="color:#FD971F">        self</span><span style="color:#F8F8F2">.net </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> nn.Sequential(</span><span style="color:#F92672">*</span><span style="color:#F8F8F2">layers)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">    def</span><span style="color:#A6E22E"> forward</span><span style="color:#F8F8F2">(</span><span style="color:#FD971F;font-style:italic">self</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">X</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#F92672">        return</span><span style="color:#FD971F"> self</span><span style="color:#F8F8F2">.net(X.view(</span><span style="color:#F92672">-</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">, num_inputs))  </span><span style="color:#88846F"># 展平输入</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># 训练函数，接收不同的 weight_decay 参数</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">def</span><span style="color:#A6E22E"> train_with_weight_decay</span><span style="color:#F8F8F2">(</span><span style="color:#FD971F;font-style:italic">lambda_values</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#F8F8F2">    train_losses, val_losses </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> [], []</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F92672">    for</span><span style="color:#F8F8F2"> weight_decay </span><span style="color:#F92672">in</span><span style="color:#F8F8F2"> lambda_values:</span></span>
<span class="line"><span style="color:#F8F8F2">        net </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> MLP(num_inputs, num_hiddens, num_outputs, num_layers)</span></span>
<span class="line"><span style="color:#F8F8F2">        loss </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> nn.CrossEntropyLoss()</span></span>
<span class="line"><span style="color:#F8F8F2">        optimizer </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.optim.SGD(net.parameters(), </span><span style="color:#FD971F;font-style:italic">lr</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">learning_rate, </span><span style="color:#FD971F;font-style:italic">weight_decay</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">weight_decay)  </span><span style="color:#88846F"># 添加权重衰减</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">        train_loss, val_loss </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> [], []</span></span>
<span class="line"><span style="color:#F92672">        for</span><span style="color:#F8F8F2"> epoch </span><span style="color:#F92672">in</span><span style="color:#66D9EF"> range</span><span style="color:#F8F8F2">(num_epochs):</span></span>
<span class="line"><span style="color:#F8F8F2">            net.train()</span></span>
<span class="line"><span style="color:#F8F8F2">            total_loss, total_samples </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 0</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">0</span></span>
<span class="line"><span style="color:#F92672">            for</span><span style="color:#F8F8F2"> X, y </span><span style="color:#F92672">in</span><span style="color:#F8F8F2"> train_loader:</span></span>
<span class="line"><span style="color:#F8F8F2">                y_hat </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> net(X)</span></span>
<span class="line"><span style="color:#F8F8F2">                l </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> loss(y_hat, y)</span></span>
<span class="line"><span style="color:#F8F8F2">                optimizer.zero_grad()</span></span>
<span class="line"><span style="color:#F8F8F2">                l.backward()</span></span>
<span class="line"><span style="color:#F8F8F2">                optimizer.step()</span></span>
<span class="line"><span style="color:#F8F8F2">                total_loss </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> l.item() </span><span style="color:#F92672">*</span><span style="color:#F8F8F2"> y.size(</span><span style="color:#AE81FF">0</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">                total_samples </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> y.size(</span><span style="color:#AE81FF">0</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">            train_loss.append(total_loss </span><span style="color:#F92672">/</span><span style="color:#F8F8F2"> total_samples)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">            net.eval()</span></span>
<span class="line"><span style="color:#F8F8F2">            total, test_loss </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 0</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">0</span></span>
<span class="line"><span style="color:#F92672">            with</span><span style="color:#F8F8F2"> torch.no_grad():</span></span>
<span class="line"><span style="color:#F92672">                for</span><span style="color:#F8F8F2"> X, y </span><span style="color:#F92672">in</span><span style="color:#F8F8F2"> test_loader:</span></span>
<span class="line"><span style="color:#F8F8F2">                    y_hat </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> net(X)</span></span>
<span class="line"><span style="color:#F8F8F2">                    test_loss </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> loss(y_hat, y).item() </span><span style="color:#F92672">*</span><span style="color:#F8F8F2"> y.size(</span><span style="color:#AE81FF">0</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">                    total </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> y.size(</span><span style="color:#AE81FF">0</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">            val_loss.append(test_loss </span><span style="color:#F92672">/</span><span style="color:#F8F8F2"> total)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">        train_losses.append(train_loss[</span><span style="color:#F92672">-</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">])</span></span>
<span class="line"><span style="color:#F8F8F2">        val_losses.append(val_loss[</span><span style="color:#F92672">-</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF">        print</span><span style="color:#F8F8F2">(</span><span style="color:#66D9EF;font-style:italic">f</span><span style="color:#E6DB74">"λ=</span><span style="color:#AE81FF">{</span><span style="color:#F8F8F2">weight_decay</span><span style="color:#66D9EF;font-style:italic">:.5f</span><span style="color:#AE81FF">}</span><span style="color:#E6DB74">, Final Train Loss=</span><span style="color:#AE81FF">{</span><span style="color:#F8F8F2">train_loss[</span><span style="color:#F92672">-</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">]</span><span style="color:#66D9EF;font-style:italic">:.4f</span><span style="color:#AE81FF">}</span><span style="color:#E6DB74">, Final Val Loss=</span><span style="color:#AE81FF">{</span><span style="color:#F8F8F2">val_loss[</span><span style="color:#F92672">-</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">]</span><span style="color:#66D9EF;font-style:italic">:.4f</span><span style="color:#AE81FF">}</span><span style="color:#E6DB74">"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F92672">    return</span><span style="color:#F8F8F2"> train_losses, val_losses</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># 训练并记录不同 λ 对损失的影响</span></span>
<span class="line"><span style="color:#F8F8F2">train_losses, val_losses </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> train_with_weight_decay(lambda_values)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># 绘制 λ vs 训练损失 / 测试损失曲线</span></span>
<span class="line"><span style="color:#F8F8F2">plt.figure(</span><span style="color:#FD971F;font-style:italic">figsize</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">(</span><span style="color:#AE81FF">8</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">5</span><span style="color:#F8F8F2">))</span></span>
<span class="line"><span style="color:#F8F8F2">plt.plot(lambda_values, train_losses, </span><span style="color:#FD971F;font-style:italic">marker</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"o"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">label</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"Train Loss"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">color</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"blue"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">plt.plot(lambda_values, val_losses, </span><span style="color:#FD971F;font-style:italic">marker</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"s"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">label</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"Test Loss"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">color</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"orange"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">linestyle</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"dashed"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">plt.xlabel(</span><span style="color:#E6DB74">"Weight Decay (λ)"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">plt.ylabel(</span><span style="color:#E6DB74">"Loss"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">plt.xscale(</span><span style="color:#E6DB74">"log"</span><span style="color:#F8F8F2">)  </span><span style="color:#88846F"># 采用对数刻度更清晰</span></span>
<span class="line"><span style="color:#F8F8F2">plt.legend()</span></span>
<span class="line"><span style="color:#F8F8F2">plt.title(</span><span style="color:#E6DB74">"Effect of Weight Decay (λ) on Loss"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">plt.show()</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div><div class="collapsed-lines"></div></div></div><hr class="vp-article-hr"><!----></article></div><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/zh/DeepThinking/mlp_exe.html"><header class="vp-article-title"><!----><!----><span property="headline">实现多层感知机</span></header></a><div class="vp-article-excerpt"><h3>代码</h3>
<div class="language-python line-numbers-mode has-collapsed-lines collapsed" data-highlighter="shiki" data-ext="python" style="--vp-collapsed-lines:15;background-color:#272822;color:#F8F8F2"><pre class="shiki monokai vp-code"><code><span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> torch</span></span>
<span class="line"><span style="color:#F92672">from</span><span style="color:#F8F8F2"> torch </span><span style="color:#F92672">import</span><span style="color:#F8F8F2"> nn</span></span>
<span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> torchvision</span></span>
<span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> torchvision.transforms </span><span style="color:#F92672">as</span><span style="color:#F8F8F2"> transforms</span></span>
<span class="line"><span style="color:#F92672">import</span><span style="color:#F8F8F2"> matplotlib.pyplot </span><span style="color:#F92672">as</span><span style="color:#F8F8F2"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">batch_size </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 256</span></span>
<span class="line"><span style="color:#F8F8F2">num_inputs, num_outputs </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 784</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">10</span><span style="color:#F8F8F2">  </span></span>
<span class="line"><span style="color:#F8F8F2">num_hiddens </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 128</span><span style="color:#F8F8F2">  </span></span>
<span class="line"><span style="color:#F8F8F2">num_layers </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 2</span><span style="color:#F8F8F2"> </span></span>
<span class="line"><span style="color:#F8F8F2">learning_rate </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 0.1</span><span style="color:#F8F8F2">  </span></span>
<span class="line"><span style="color:#F8F8F2">num_epochs </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 10</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">transform </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> transforms.Compose([transforms.ToTensor()])</span></span>
<span class="line"><span style="color:#F8F8F2">train_dataset </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torchvision.datasets.FashionMNIST(</span><span style="color:#FD971F;font-style:italic">root</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"./data"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">train</span><span style="color:#F92672">=</span><span style="color:#AE81FF">True</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">transform</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">transform, </span><span style="color:#FD971F;font-style:italic">download</span><span style="color:#F92672">=</span><span style="color:#AE81FF">False</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">test_dataset </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torchvision.datasets.FashionMNIST(</span><span style="color:#FD971F;font-style:italic">root</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"./data"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">train</span><span style="color:#F92672">=</span><span style="color:#AE81FF">False</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">transform</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">transform, </span><span style="color:#FD971F;font-style:italic">download</span><span style="color:#F92672">=</span><span style="color:#AE81FF">False</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">train_loader </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.utils.data.DataLoader(train_dataset, </span><span style="color:#FD971F;font-style:italic">batch_size</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">batch_size, </span><span style="color:#FD971F;font-style:italic">shuffle</span><span style="color:#F92672">=</span><span style="color:#AE81FF">True</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">test_loader </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.utils.data.DataLoader(test_dataset, </span><span style="color:#FD971F;font-style:italic">batch_size</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">batch_size, </span><span style="color:#FD971F;font-style:italic">shuffle</span><span style="color:#F92672">=</span><span style="color:#AE81FF">False</span><span style="color:#F8F8F2">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">class</span><span> </span><span style="color:#A6E22E;text-decoration:underline">MLP</span><span style="color:#F8F8F2">(</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline">nn</span><span style="color:#F8F8F2">.</span><span style="color:#A6E22E;font-style:italic;text-decoration:underline">Module</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">    def</span><span style="color:#66D9EF"> __init__</span><span style="color:#F8F8F2">(</span><span style="color:#FD971F;font-style:italic">self</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">num_inputs</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">num_hiddens</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">num_outputs</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">num_layers</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">        super</span><span style="color:#F8F8F2">(</span><span style="color:#AE81FF">MLP</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F">self</span><span style="color:#F8F8F2">).</span><span style="color:#66D9EF">__init__</span><span style="color:#F8F8F2">()</span></span>
<span class="line"><span style="color:#F8F8F2">        layers </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> []</span></span>
<span class="line"><span style="color:#F8F8F2">        layers.append(nn.Linear(num_inputs, num_hiddens))</span></span>
<span class="line"><span style="color:#F8F8F2">        layers.append(nn.ReLU())</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F92672">        for</span><span style="color:#F8F8F2"> _ </span><span style="color:#F92672">in</span><span style="color:#66D9EF"> range</span><span style="color:#F8F8F2">(num_layers </span><span style="color:#F92672">-</span><span style="color:#AE81FF"> 1</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#F8F8F2">            layers.append(nn.Linear(num_hiddens, num_hiddens))</span></span>
<span class="line"><span style="color:#F8F8F2">            layers.append(nn.ReLU())</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">        layers.append(nn.Linear(num_hiddens, num_outputs))</span></span>
<span class="line"><span style="color:#FD971F">        self</span><span style="color:#F8F8F2">.net </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> nn.Sequential(</span><span style="color:#F92672">*</span><span style="color:#F8F8F2">layers)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">    def</span><span style="color:#A6E22E"> forward</span><span style="color:#F8F8F2">(</span><span style="color:#FD971F;font-style:italic">self</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">X</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#F92672">        return</span><span style="color:#FD971F"> self</span><span style="color:#F8F8F2">.net(X.view(</span><span style="color:#F92672">-</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">, num_inputs))  </span><span style="color:#88846F"># 展平输入</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">net </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> MLP(num_inputs, num_hiddens, num_outputs, num_layers)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">loss </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> nn.CrossEntropyLoss()</span></span>
<span class="line"><span style="color:#F8F8F2">optimizer </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> torch.optim.SGD(net.parameters(), </span><span style="color:#FD971F;font-style:italic">lr</span><span style="color:#F92672">=</span><span style="color:#F8F8F2">learning_rate)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">def</span><span style="color:#A6E22E"> train</span><span style="color:#F8F8F2">(</span><span style="color:#FD971F;font-style:italic">net</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">train_loader</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">test_loader</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">loss</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">num_epochs</span><span style="color:#F8F8F2">):</span></span>
<span class="line"><span style="color:#F8F8F2">    train_loss, val_loss, val_acc </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> [], [], []</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F92672">    for</span><span style="color:#F8F8F2"> epoch </span><span style="color:#F92672">in</span><span style="color:#66D9EF"> range</span><span style="color:#F8F8F2">(num_epochs):</span></span>
<span class="line"><span style="color:#F8F8F2">        net.train()</span></span>
<span class="line"><span style="color:#F8F8F2">        total_loss, total_samples </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 0</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">0</span></span>
<span class="line"><span style="color:#F92672">        for</span><span style="color:#F8F8F2"> X, y </span><span style="color:#F92672">in</span><span style="color:#F8F8F2"> train_loader:</span></span>
<span class="line"><span style="color:#F8F8F2">            y_hat </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> net(X)</span></span>
<span class="line"><span style="color:#F8F8F2">            l </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> loss(y_hat, y)</span></span>
<span class="line"><span style="color:#F8F8F2">            optimizer.zero_grad()</span></span>
<span class="line"><span style="color:#F8F8F2">            l.backward()</span></span>
<span class="line"><span style="color:#F8F8F2">            optimizer.step()</span></span>
<span class="line"><span style="color:#F8F8F2">            total_loss </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> l.item() </span><span style="color:#F92672">*</span><span style="color:#F8F8F2"> y.size(</span><span style="color:#AE81FF">0</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">            total_samples </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> y.size(</span><span style="color:#AE81FF">0</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">        train_loss.append(total_loss </span><span style="color:#F92672">/</span><span style="color:#F8F8F2"> total_samples)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">        net.eval()</span></span>
<span class="line"><span style="color:#F8F8F2">        correct, total, test_loss </span><span style="color:#F92672">=</span><span style="color:#AE81FF"> 0</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">0</span><span style="color:#F8F8F2">, </span><span style="color:#AE81FF">0</span></span>
<span class="line"><span style="color:#F92672">        with</span><span style="color:#F8F8F2"> torch.no_grad():</span></span>
<span class="line"><span style="color:#F92672">            for</span><span style="color:#F8F8F2"> X, y </span><span style="color:#F92672">in</span><span style="color:#F8F8F2"> test_loader:</span></span>
<span class="line"><span style="color:#F8F8F2">                y_hat </span><span style="color:#F92672">=</span><span style="color:#F8F8F2"> net(X)</span></span>
<span class="line"><span style="color:#F8F8F2">                test_loss </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> loss(y_hat, y).item() </span><span style="color:#F92672">*</span><span style="color:#F8F8F2"> y.size(</span><span style="color:#AE81FF">0</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">                correct </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> (y_hat.argmax(</span><span style="color:#FD971F;font-style:italic">dim</span><span style="color:#F92672">=</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">) </span><span style="color:#F92672">==</span><span style="color:#F8F8F2"> y).sum().item()</span></span>
<span class="line"><span style="color:#F8F8F2">                total </span><span style="color:#F92672">+=</span><span style="color:#F8F8F2"> y.size(</span><span style="color:#AE81FF">0</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">        val_loss.append(test_loss </span><span style="color:#F92672">/</span><span style="color:#F8F8F2"> total)</span></span>
<span class="line"><span style="color:#F8F8F2">        val_acc.append(correct </span><span style="color:#F92672">/</span><span style="color:#F8F8F2"> total)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#66D9EF">        print</span><span style="color:#F8F8F2">(</span></span>
<span class="line"><span style="color:#66D9EF;font-style:italic">            f</span><span style="color:#E6DB74">"Epoch </span><span style="color:#AE81FF">{</span><span style="color:#F8F8F2">epoch </span><span style="color:#F92672">+</span><span style="color:#AE81FF"> 1}</span><span style="color:#E6DB74">: train_loss=</span><span style="color:#AE81FF">{</span><span style="color:#F8F8F2">train_loss[</span><span style="color:#F92672">-</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">]</span><span style="color:#66D9EF;font-style:italic">:.4f</span><span style="color:#AE81FF">}</span><span style="color:#E6DB74">, val_loss=</span><span style="color:#AE81FF">{</span><span style="color:#F8F8F2">val_loss[</span><span style="color:#F92672">-</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">]</span><span style="color:#66D9EF;font-style:italic">:.4f</span><span style="color:#AE81FF">}</span><span style="color:#E6DB74">, val_acc=</span><span style="color:#AE81FF">{</span><span style="color:#F8F8F2">val_acc[</span><span style="color:#F92672">-</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">]</span><span style="color:#66D9EF;font-style:italic">:.4f</span><span style="color:#AE81FF">}</span><span style="color:#E6DB74">"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#F8F8F2">    plt.plot(</span><span style="color:#66D9EF">range</span><span style="color:#F8F8F2">(</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">, num_epochs </span><span style="color:#F92672">+</span><span style="color:#AE81FF"> 1</span><span style="color:#F8F8F2">), train_loss, </span><span style="color:#FD971F;font-style:italic">label</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"train_loss"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">color</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"blue"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">    plt.plot(</span><span style="color:#66D9EF">range</span><span style="color:#F8F8F2">(</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">, num_epochs </span><span style="color:#F92672">+</span><span style="color:#AE81FF"> 1</span><span style="color:#F8F8F2">), val_loss, </span><span style="color:#FD971F;font-style:italic">label</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"val_loss"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">color</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"orange"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">linestyle</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"dashed"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">    plt.plot(</span><span style="color:#66D9EF">range</span><span style="color:#F8F8F2">(</span><span style="color:#AE81FF">1</span><span style="color:#F8F8F2">, num_epochs </span><span style="color:#F92672">+</span><span style="color:#AE81FF"> 1</span><span style="color:#F8F8F2">), val_acc, </span><span style="color:#FD971F;font-style:italic">label</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"val_acc"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">color</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"green"</span><span style="color:#F8F8F2">, </span><span style="color:#FD971F;font-style:italic">linestyle</span><span style="color:#F92672">=</span><span style="color:#E6DB74">"dashdot"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">    plt.xlabel(</span><span style="color:#E6DB74">"Epoch"</span><span style="color:#F8F8F2">)</span></span>
<span class="line"><span style="color:#F8F8F2">    plt.legend()</span></span>
<span class="line"><span style="color:#F8F8F2">    plt.show()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#88846F"># 训练模型</span></span>
<span class="line"><span style="color:#F8F8F2">train(net, train_loader, test_loader, loss, num_epochs)</span></span></code></pre>
<div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div><div class="collapsed-lines"></div></div></div><hr class="vp-article-hr"><!----></article></div><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/zh/DeepThinking/02.html"><header class="vp-article-title"><!----><!----><span property="headline">Key Components of Deep Learning</span></header></a><div class="vp-article-excerpt"><h2>1. MLP</h2>
<h3>1.1 Structural analysis</h3>
<figure><figcaption>image-20250305103104357</figcaption></figure>
<h4>1.1.1 结构</h4>
<p>该图展示了一个<strong>三层神经网络</strong>（输入层、隐藏层、输出层）。</p>
<p><strong>输入层（Input Layer）</strong>：由  组成，表示输入特征，每个特征作为一个神经元。</p>
<p><strong>隐藏层（Hidden Layer）</strong>：由  组成，表示经过线性变换和激活函数处理后的隐藏表示。</p></div><hr class="vp-article-hr"><!----></article></div><div class="vp-article-wrapper"><article class="vp-article-item" vocab="https://schema.org/" typeof="Article"><!--[--><!--]--><!----><a class="route-link" href="/zh/DeepThinking/01.html"><header class="vp-article-title"><!----><!----><span property="headline">Preceding Conceptual Tech</span></header></a><div class="vp-article-excerpt"><h3>Basics of Machine Learning</h3>
<p><strong>Softmax 回归</strong>：这是一种用于多类分类问题的回归方法，通常用于神经网络的输出层。</p>
<p><strong>Softmax 与深度学习的关系</strong>：Softmax 回归是深度学习中的一个重要组成部分，特别是在处理分类问题时。它与线性回归和单层神经网络有联系，并可以追溯到深度学习的更广泛背景中。</p>

<h4>1. Softmax 回归解决了什么问题？</h4>
<ul>
<li>解决多分类问题。</li>
</ul>
<div class="hint-container important">
<p class="hint-container-title">线性回归在分类问题上的局限性</p>
<p>Linear Regression--&gt;Discrete Classification</p>
<p>Problem: In the process of converting continuous values to discrete values, there is usually an element of experience. If the error is large, it will greatly affect the quality of classification. During the conversion process, it is easy for people to think of setting a threshold. Setting the threshold based on experience will bring a lot of uncertainties, and the quality of classification is also related to the different experiences of different people.</p>
</div></div><hr class="vp-article-hr"><!----></article></div><div class="vp-pagination"></div></div></main><aside class="vp-blog-info-wrapper"><div class="vp-blogger-info" vocab="https://schema.org/" typeof="Person"><div class="vp-blogger" aria-label="个人介绍" data-balloon-pos="down" role="link"><img class="vp-blogger-avatar" src="/logo.jpg" property="image" alt="Blogger Avatar" loading="lazy"><div class="vp-blogger-name" property="name">XiaoXianYue</div><div class="vp-blogger-description">一个前端开发者</div><meta property="url" content="/zh/intro.html"></div><div class="vp-blog-counts"><a class="route-link vp-blog-count" href="/zh/article/"><div class="count">151</div><div>文章</div></a><a class="route-link vp-blog-count" href="/zh/category/"><div class="count">24</div><div>分类</div></a><a class="route-link vp-blog-count" href="/zh/tag/"><div class="count">24</div><div>标签</div></a><a class="route-link vp-blog-count" href="/zh/timeline/"><div class="count">151</div><div>时间轴</div></a></div><div class="vp-social-medias"><a class="vp-social-media" href="https://b23.tv/oR9fNEC" rel="noopener noreferrer" target="_blank" aria-label="BiliBili" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="vp-social-media-icon bilibili-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#1296db"/><path fill="#fff" d="M745.363 177.725a47 47 0 0 1 0 66.3L702.5 286.85h44A141 141 0 0 1 887 427.512v281.25a141 141 0 0 1-141 140.626H277.25A141 141 0 0 1 137 708.763v-281.25a141 141 0 0 1 141-141h43.725l-42.788-42.825a47 47 0 1 1 66.263-66.3l99.45 99.45c2.963 2.962 5.438 6.187 7.425 9.637h120.487c1.988-3.45 4.5-6.75 7.463-9.675l99.413-99.45a47 47 0 0 1 66.3 0zm1.012 203.25h-468.75a47 47 0 0 0-46.763 43.388l-.112 3.525v281.25c0 24.712 19.125 44.962 43.387 46.724l3.488.15h468.75a47 47 0 0 0 46.763-43.387l.112-3.487v-281.25c0-26-21-47-47-46.876zm-375 93.75c26 0 47 21 47 47v47a47 47 0 1 1-93.75 0V521.6c0-26 21-47 47-47zm281.25 0c26 0 47 21 47 47v47a47 47 0 1 1-93.75 0V521.6c0-26 21-47 47-47z"/></svg></a></div></div><div class="vp-blog-infos"><div class="vp-blog-type-switcher"><button type="button" class="vp-blog-type-button"><div class="vp-blog-type-icon-wrapper active" aria-label="文章" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon article-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="article icon" name="article"><path d="M853.333 938.667H170.667A42.667 42.667 0 0 1 128 896V128a42.667 42.667 0 0 1 42.667-42.667h682.666A42.667 42.667 0 0 1 896 128v768a42.667 42.667 0 0 1-42.667 42.667zm-42.666-85.334V170.667H213.333v682.666h597.334zM298.667 256h170.666v170.667H298.667V256zm0 256h426.666v85.333H298.667V512zm0 170.667h426.666V768H298.667v-85.333zm256-384h170.666V384H554.667v-85.333z"></path></svg></div></button><button type="button" class="vp-blog-type-button"><div class="vp-blog-type-icon-wrapper" aria-label="分类" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg></div></button><button type="button" class="vp-blog-type-button"><div class="vp-blog-type-icon-wrapper" aria-label="标签" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg></div></button><button type="button" class="vp-blog-type-button"><div class="vp-blog-type-icon-wrapper" aria-label="时间轴" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timeline-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timeline icon" name="timeline"><path d="M511.997 70.568c-243.797 0-441.429 197.633-441.429 441.435 0 243.797 197.632 441.429 441.43 441.429S953.431 755.8 953.431 512.002c0-243.796-197.637-441.434-441.435-441.434zm150.158 609.093-15.605 15.61c-8.621 8.615-22.596 8.615-31.215 0L472.197 552.126c-4.95-4.944-4.34-14.888-4.34-24.677V247.14c0-12.19 9.882-22.07 22.07-22.07h22.07c12.19 0 22.07 9.882 22.07 22.07v273.218l128.088 128.088c8.62 8.62 8.62 22.595 0 31.215zm0 0"></path></svg></div></button></div><div class="vp-star-article-wrapper"><div class="title"><svg xmlns="http://www.w3.org/2000/svg" class="icon article-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="article icon" name="article"><path d="M853.333 938.667H170.667A42.667 42.667 0 0 1 128 896V128a42.667 42.667 0 0 1 42.667-42.667h682.666A42.667 42.667 0 0 1 896 128v768a42.667 42.667 0 0 1-42.667 42.667zm-42.666-85.334V170.667H213.333v682.666h597.334zM298.667 256h170.666v170.667H298.667V256zm0 256h426.666v85.333H298.667V512zm0 170.667h426.666V768H298.667v-85.333zm256-384h170.666V384H554.667v-85.333z"></path></svg><span class="num">151</span>文章</div><hr><div class="vp-star-article-empty">星标 为空</div></div></div></aside></div></div><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">默认页脚</div><div class="vp-copyright">Copyright © 2025 XiaoXianYue </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-Cc7WVUoo.js" defer></script>
  </body>
</html>
